{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN with Optimizers-Liver Disease Patient Classification .ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iig0a3Sbm2i",
        "outputId": "59512356-3e5d-424d-ed27-997a2f89c155",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        }
      },
      "source": [
        "! pip install tensorflow-gpu"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/99/ac32fd13d56e40d4c3e6150030132519997c0bb1f06f448d970e81b177e5/tensorflow_gpu-2.3.1-cp36-cp36m-manylinux2010_x86_64.whl (320.4MB)\n",
            "\u001b[K     |████████████████████████████████| 320.4MB 47kB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.35.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.10.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.2)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.3.3)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.18.5)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.32.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.12.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.3.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (3.2.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (0.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (50.3.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.7.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.17.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu) (2.0.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu) (1.3.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (2020.6.20)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.2.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (0.4.8)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-2.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLuJ3IyBbzUk",
        "outputId": "d7697d83-1b9a-4b72-d2b2-b3b191013b57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "! pip install keras"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.4.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBH6WN3Db5qw",
        "outputId": "261a6e61-3bd0-4dbe-db28-2ceac00b9e5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "! pip install pandas"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPqXRMj_b5wC",
        "outputId": "b86a1843-86f3-496a-fa18-f93d083e4926",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "print(\"TF version:\", tf.__version__)\n",
        "print(\"Hub version:\", hub.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TF version: 2.3.1\n",
            "Hub version: 0.9.0\n",
            "WARNING:tensorflow:From <ipython-input-4-c62ce35fd0be>:7: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n",
            "GPU is available\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izjchs6sb51O"
      },
      "source": [
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten,Conv2D,MaxPooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "from glob import glob\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgdvwuWPb56c"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "import os\n",
        "import cv2"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBNVQkSVb5_d",
        "outputId": "3f85419e-4fbe-41dd-d2df-6c07777d77aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUPoix_vb6KO"
      },
      "source": [
        "import pandas as pd\n",
        "file=\"/content/drive/My Drive/Colab Notebooks/indian_liver_patient.csv\""
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVqnBFu6hN2c",
        "outputId": "83b07494-efd8-46b2-8bc6-9e6bfc8c8d84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        }
      },
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv(file)\n",
        "df"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Total_Bilirubin</th>\n",
              "      <th>Direct_Bilirubin</th>\n",
              "      <th>Alkaline_Phosphotase</th>\n",
              "      <th>Alamine_Aminotransferase</th>\n",
              "      <th>Aspartate_Aminotransferase</th>\n",
              "      <th>Total_Protiens</th>\n",
              "      <th>Albumin</th>\n",
              "      <th>Albumin_and_Globulin_Ratio</th>\n",
              "      <th>Dataset</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>65</td>\n",
              "      <td>Female</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.1</td>\n",
              "      <td>187</td>\n",
              "      <td>16</td>\n",
              "      <td>18</td>\n",
              "      <td>6.8</td>\n",
              "      <td>3.3</td>\n",
              "      <td>0.90</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>62</td>\n",
              "      <td>Male</td>\n",
              "      <td>10.9</td>\n",
              "      <td>5.5</td>\n",
              "      <td>699</td>\n",
              "      <td>64</td>\n",
              "      <td>100</td>\n",
              "      <td>7.5</td>\n",
              "      <td>3.2</td>\n",
              "      <td>0.74</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>62</td>\n",
              "      <td>Male</td>\n",
              "      <td>7.3</td>\n",
              "      <td>4.1</td>\n",
              "      <td>490</td>\n",
              "      <td>60</td>\n",
              "      <td>68</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3.3</td>\n",
              "      <td>0.89</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>58</td>\n",
              "      <td>Male</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>182</td>\n",
              "      <td>14</td>\n",
              "      <td>20</td>\n",
              "      <td>6.8</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>72</td>\n",
              "      <td>Male</td>\n",
              "      <td>3.9</td>\n",
              "      <td>2.0</td>\n",
              "      <td>195</td>\n",
              "      <td>27</td>\n",
              "      <td>59</td>\n",
              "      <td>7.3</td>\n",
              "      <td>2.4</td>\n",
              "      <td>0.40</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>578</th>\n",
              "      <td>60</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.1</td>\n",
              "      <td>500</td>\n",
              "      <td>20</td>\n",
              "      <td>34</td>\n",
              "      <td>5.9</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.37</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>579</th>\n",
              "      <td>40</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.1</td>\n",
              "      <td>98</td>\n",
              "      <td>35</td>\n",
              "      <td>31</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.10</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>580</th>\n",
              "      <td>52</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.2</td>\n",
              "      <td>245</td>\n",
              "      <td>48</td>\n",
              "      <td>49</td>\n",
              "      <td>6.4</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>581</th>\n",
              "      <td>31</td>\n",
              "      <td>Male</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.5</td>\n",
              "      <td>184</td>\n",
              "      <td>29</td>\n",
              "      <td>32</td>\n",
              "      <td>6.8</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>582</th>\n",
              "      <td>38</td>\n",
              "      <td>Male</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>216</td>\n",
              "      <td>21</td>\n",
              "      <td>24</td>\n",
              "      <td>7.3</td>\n",
              "      <td>4.4</td>\n",
              "      <td>1.50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>583 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Age  Gender  Total_Bilirubin  ...  Albumin  Albumin_and_Globulin_Ratio  Dataset\n",
              "0     65  Female              0.7  ...      3.3                        0.90        1\n",
              "1     62    Male             10.9  ...      3.2                        0.74        1\n",
              "2     62    Male              7.3  ...      3.3                        0.89        1\n",
              "3     58    Male              1.0  ...      3.4                        1.00        1\n",
              "4     72    Male              3.9  ...      2.4                        0.40        1\n",
              "..   ...     ...              ...  ...      ...                         ...      ...\n",
              "578   60    Male              0.5  ...      1.6                        0.37        2\n",
              "579   40    Male              0.6  ...      3.2                        1.10        1\n",
              "580   52    Male              0.8  ...      3.2                        1.00        1\n",
              "581   31    Male              1.3  ...      3.4                        1.00        1\n",
              "582   38    Male              1.0  ...      4.4                        1.50        2\n",
              "\n",
              "[583 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RtuEDIKrI5I",
        "outputId": "dcaf09ed-f07b-405f-f73b-5c4b7faefbe2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(583, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPUrEV8NhCJA",
        "outputId": "281317df-d126-400f-a786-a621d2b380f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Age', 'Gender', 'Total_Bilirubin', 'Direct_Bilirubin',\n",
              "       'Alkaline_Phosphotase', 'Alamine_Aminotransferase',\n",
              "       'Aspartate_Aminotransferase', 'Total_Protiens', 'Albumin',\n",
              "       'Albumin_and_Globulin_Ratio', 'Dataset'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RYxY1cRmtVx",
        "outputId": "312f33d9-eced-4b9b-ce55-ff6078a2dff6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Age                           0\n",
              "Gender                        0\n",
              "Total_Bilirubin               0\n",
              "Direct_Bilirubin              0\n",
              "Alkaline_Phosphotase          0\n",
              "Alamine_Aminotransferase      0\n",
              "Aspartate_Aminotransferase    0\n",
              "Total_Protiens                0\n",
              "Albumin                       0\n",
              "Albumin_and_Globulin_Ratio    4\n",
              "Dataset                       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzX2O-RUhgbV",
        "outputId": "9799c176-4eff-4ce8-b45a-ea848cded0aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "df.nunique()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Age                            72\n",
              "Gender                          2\n",
              "Total_Bilirubin               113\n",
              "Direct_Bilirubin               80\n",
              "Alkaline_Phosphotase          263\n",
              "Alamine_Aminotransferase      152\n",
              "Aspartate_Aminotransferase    177\n",
              "Total_Protiens                 58\n",
              "Albumin                        40\n",
              "Albumin_and_Globulin_Ratio     69\n",
              "Dataset                         2\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OMJbk2ChgrZ",
        "outputId": "71928703-98a3-4003-e6ad-19cc6d0f2556",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Age                             int64\n",
              "Gender                         object\n",
              "Total_Bilirubin               float64\n",
              "Direct_Bilirubin              float64\n",
              "Alkaline_Phosphotase            int64\n",
              "Alamine_Aminotransferase        int64\n",
              "Aspartate_Aminotransferase      int64\n",
              "Total_Protiens                float64\n",
              "Albumin                       float64\n",
              "Albumin_and_Globulin_Ratio    float64\n",
              "Dataset                         int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QI5yOMthggM",
        "outputId": "0673297f-6d4b-4de9-e69d-636a25ffe0c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "sns.heatmap(df.isnull())"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f9c2744d5c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blTb_rpl_i4c"
      },
      "source": [
        "df.dropna(inplace=True)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfjBv7wG_m2g",
        "outputId": "90fec81d-c9b2-477d-d1fe-fba4a6dd62b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Age                           0\n",
              "Gender                        0\n",
              "Total_Bilirubin               0\n",
              "Direct_Bilirubin              0\n",
              "Alkaline_Phosphotase          0\n",
              "Alamine_Aminotransferase      0\n",
              "Aspartate_Aminotransferase    0\n",
              "Total_Protiens                0\n",
              "Albumin                       0\n",
              "Albumin_and_Globulin_Ratio    0\n",
              "Dataset                       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YfoKah7An8j",
        "outputId": "8df69b6f-e7eb-40ea-a35f-ca8ec9944ab0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "df['Dataset'].value_counts()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    414\n",
              "2    165\n",
              "Name: Dataset, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8zY1Mb_BXu3"
      },
      "source": [
        "df['Dataset']=df['Dataset'].replace({2:0})"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djzTAOz5B_KG",
        "outputId": "c63c6f1f-8067-4377-96f5-6546160f7769",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        }
      },
      "source": [
        "df"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Total_Bilirubin</th>\n",
              "      <th>Direct_Bilirubin</th>\n",
              "      <th>Alkaline_Phosphotase</th>\n",
              "      <th>Alamine_Aminotransferase</th>\n",
              "      <th>Aspartate_Aminotransferase</th>\n",
              "      <th>Total_Protiens</th>\n",
              "      <th>Albumin</th>\n",
              "      <th>Albumin_and_Globulin_Ratio</th>\n",
              "      <th>Dataset</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>65</td>\n",
              "      <td>Female</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.1</td>\n",
              "      <td>187</td>\n",
              "      <td>16</td>\n",
              "      <td>18</td>\n",
              "      <td>6.8</td>\n",
              "      <td>3.3</td>\n",
              "      <td>0.90</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>62</td>\n",
              "      <td>Male</td>\n",
              "      <td>10.9</td>\n",
              "      <td>5.5</td>\n",
              "      <td>699</td>\n",
              "      <td>64</td>\n",
              "      <td>100</td>\n",
              "      <td>7.5</td>\n",
              "      <td>3.2</td>\n",
              "      <td>0.74</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>62</td>\n",
              "      <td>Male</td>\n",
              "      <td>7.3</td>\n",
              "      <td>4.1</td>\n",
              "      <td>490</td>\n",
              "      <td>60</td>\n",
              "      <td>68</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3.3</td>\n",
              "      <td>0.89</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>58</td>\n",
              "      <td>Male</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>182</td>\n",
              "      <td>14</td>\n",
              "      <td>20</td>\n",
              "      <td>6.8</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>72</td>\n",
              "      <td>Male</td>\n",
              "      <td>3.9</td>\n",
              "      <td>2.0</td>\n",
              "      <td>195</td>\n",
              "      <td>27</td>\n",
              "      <td>59</td>\n",
              "      <td>7.3</td>\n",
              "      <td>2.4</td>\n",
              "      <td>0.40</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>578</th>\n",
              "      <td>60</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.1</td>\n",
              "      <td>500</td>\n",
              "      <td>20</td>\n",
              "      <td>34</td>\n",
              "      <td>5.9</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>579</th>\n",
              "      <td>40</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.1</td>\n",
              "      <td>98</td>\n",
              "      <td>35</td>\n",
              "      <td>31</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.10</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>580</th>\n",
              "      <td>52</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.2</td>\n",
              "      <td>245</td>\n",
              "      <td>48</td>\n",
              "      <td>49</td>\n",
              "      <td>6.4</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>581</th>\n",
              "      <td>31</td>\n",
              "      <td>Male</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.5</td>\n",
              "      <td>184</td>\n",
              "      <td>29</td>\n",
              "      <td>32</td>\n",
              "      <td>6.8</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>582</th>\n",
              "      <td>38</td>\n",
              "      <td>Male</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>216</td>\n",
              "      <td>21</td>\n",
              "      <td>24</td>\n",
              "      <td>7.3</td>\n",
              "      <td>4.4</td>\n",
              "      <td>1.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>579 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Age  Gender  Total_Bilirubin  ...  Albumin  Albumin_and_Globulin_Ratio  Dataset\n",
              "0     65  Female              0.7  ...      3.3                        0.90        1\n",
              "1     62    Male             10.9  ...      3.2                        0.74        1\n",
              "2     62    Male              7.3  ...      3.3                        0.89        1\n",
              "3     58    Male              1.0  ...      3.4                        1.00        1\n",
              "4     72    Male              3.9  ...      2.4                        0.40        1\n",
              "..   ...     ...              ...  ...      ...                         ...      ...\n",
              "578   60    Male              0.5  ...      1.6                        0.37        0\n",
              "579   40    Male              0.6  ...      3.2                        1.10        1\n",
              "580   52    Male              0.8  ...      3.2                        1.00        1\n",
              "581   31    Male              1.3  ...      3.4                        1.00        1\n",
              "582   38    Male              1.0  ...      4.4                        1.50        0\n",
              "\n",
              "[579 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ci_pLMNrtMi"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder=LabelEncoder()\n",
        "df['Gender']=encoder.fit_transform(df['Gender'])"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyqhY_eG_7vO",
        "outputId": "b84abce8-7ffa-4984-c8f3-cb45864f300e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Age', 'Gender', 'Total_Bilirubin', 'Direct_Bilirubin',\n",
              "       'Alkaline_Phosphotase', 'Alamine_Aminotransferase',\n",
              "       'Aspartate_Aminotransferase', 'Total_Protiens', 'Albumin',\n",
              "       'Albumin_and_Globulin_Ratio', 'Dataset'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4l3O1D2I5xSb"
      },
      "source": [
        "X = df.drop('Dataset',axis='columns')\n",
        "y = df['Dataset']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=10)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4kNtqpmfsmy"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "s=StandardScaler()\n",
        "X_train=s.fit_transform(X_train)\n",
        "X_test=s.transform(X_test)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eu10tJQgftUr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jftbg2kV5xOt",
        "outputId": "c6c383f2-07f8-4aeb-b108-6376fefcb941",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "X_train.shape"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(405, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrYVvTAd9FUY",
        "outputId": "ea8dbe5e-69a1-43a5-9cf7-330a4aa9316a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(174, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JV9vnRf15xLu",
        "outputId": "c8bcfc06-efb8-4c6a-d536-381746f358ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "X_train"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 4.29556611e-01,  5.68796459e-01, -1.03963325e-01, ...,\n",
              "        -4.22216649e-01, -1.76405309e+00, -1.78801700e+00],\n",
              "       [ 1.84345054e+00,  5.68796459e-01, -6.79913926e-02, ...,\n",
              "        -3.12645086e+00, -2.00981900e+00,  1.98713233e-01],\n",
              "       [-7.58933942e-04, -1.75809815e+00, -4.63682646e-01, ...,\n",
              "        -6.92640070e-01, -7.80989450e-01, -7.78367212e-01],\n",
              "       ...,\n",
              "       [-3.08127180e-01,  5.68796459e-01,  4.95009313e+00, ...,\n",
              "         1.29046501e+00, -5.35223539e-01, -1.42975417e+00],\n",
              "       [ 9.21345805e-01,  5.68796459e-01, -2.65837019e-01, ...,\n",
              "        -2.31518059e+00, -1.76405309e+00, -7.78367212e-01],\n",
              "       [-3.08127180e-01,  5.68796459e-01,  2.01838067e+00, ...,\n",
              "        -6.92640070e-01, -1.27252127e+00, -1.42975417e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLUq_l9u5xHC",
        "outputId": "d9b4937d-762e-464c-9803-b832b57928c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(405,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ur5_241-5xBu",
        "outputId": "350a72e1-50d7-4b26-9425-0d23a77214a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "model = Sequential([\n",
        "    Dense(8, input_shape=(10,), activation='relu'),\n",
        "    Dense(5, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_8 (Dense)              (None, 8)                 88        \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 5)                 45        \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 1)                 6         \n",
            "=================================================================\n",
            "Total params: 139\n",
            "Trainable params: 139\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fn8SHtHZ2RDx",
        "outputId": "775b8dc8-f5b6-4211-95a5-6a96c10b965f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.compile(optimizer='Adadelta',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "r=model.fit(X_train, y_train, epochs=500,validation_data=(X_test,y_test))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "13/13 [==============================] - 0s 12ms/step - loss: 0.6886 - accuracy: 0.5506 - val_loss: 0.6602 - val_accuracy: 0.6149\n",
            "Epoch 2/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6886 - accuracy: 0.5506 - val_loss: 0.6602 - val_accuracy: 0.6149\n",
            "Epoch 3/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6886 - accuracy: 0.5506 - val_loss: 0.6602 - val_accuracy: 0.6149\n",
            "Epoch 4/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6886 - accuracy: 0.5531 - val_loss: 0.6602 - val_accuracy: 0.6149\n",
            "Epoch 5/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6886 - accuracy: 0.5531 - val_loss: 0.6601 - val_accuracy: 0.6149\n",
            "Epoch 6/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6886 - accuracy: 0.5531 - val_loss: 0.6601 - val_accuracy: 0.6149\n",
            "Epoch 7/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6885 - accuracy: 0.5531 - val_loss: 0.6601 - val_accuracy: 0.6149\n",
            "Epoch 8/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6885 - accuracy: 0.5531 - val_loss: 0.6601 - val_accuracy: 0.6149\n",
            "Epoch 9/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6885 - accuracy: 0.5531 - val_loss: 0.6601 - val_accuracy: 0.6149\n",
            "Epoch 10/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6885 - accuracy: 0.5531 - val_loss: 0.6601 - val_accuracy: 0.6149\n",
            "Epoch 11/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6885 - accuracy: 0.5531 - val_loss: 0.6601 - val_accuracy: 0.6149\n",
            "Epoch 12/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6885 - accuracy: 0.5531 - val_loss: 0.6600 - val_accuracy: 0.6149\n",
            "Epoch 13/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6885 - accuracy: 0.5531 - val_loss: 0.6600 - val_accuracy: 0.6149\n",
            "Epoch 14/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6884 - accuracy: 0.5531 - val_loss: 0.6600 - val_accuracy: 0.6149\n",
            "Epoch 15/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6884 - accuracy: 0.5531 - val_loss: 0.6600 - val_accuracy: 0.6149\n",
            "Epoch 16/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6884 - accuracy: 0.5531 - val_loss: 0.6600 - val_accuracy: 0.6149\n",
            "Epoch 17/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6884 - accuracy: 0.5531 - val_loss: 0.6600 - val_accuracy: 0.6149\n",
            "Epoch 18/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6884 - accuracy: 0.5531 - val_loss: 0.6600 - val_accuracy: 0.6149\n",
            "Epoch 19/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6884 - accuracy: 0.5531 - val_loss: 0.6600 - val_accuracy: 0.6149\n",
            "Epoch 20/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6884 - accuracy: 0.5531 - val_loss: 0.6599 - val_accuracy: 0.6149\n",
            "Epoch 21/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6884 - accuracy: 0.5531 - val_loss: 0.6599 - val_accuracy: 0.6149\n",
            "Epoch 22/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6883 - accuracy: 0.5531 - val_loss: 0.6599 - val_accuracy: 0.6149\n",
            "Epoch 23/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6883 - accuracy: 0.5531 - val_loss: 0.6599 - val_accuracy: 0.6149\n",
            "Epoch 24/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6883 - accuracy: 0.5531 - val_loss: 0.6599 - val_accuracy: 0.6149\n",
            "Epoch 25/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6883 - accuracy: 0.5531 - val_loss: 0.6599 - val_accuracy: 0.6149\n",
            "Epoch 26/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6883 - accuracy: 0.5531 - val_loss: 0.6599 - val_accuracy: 0.6149\n",
            "Epoch 27/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6883 - accuracy: 0.5531 - val_loss: 0.6599 - val_accuracy: 0.6149\n",
            "Epoch 28/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6883 - accuracy: 0.5531 - val_loss: 0.6599 - val_accuracy: 0.6149\n",
            "Epoch 29/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6883 - accuracy: 0.5531 - val_loss: 0.6598 - val_accuracy: 0.6149\n",
            "Epoch 30/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6882 - accuracy: 0.5531 - val_loss: 0.6598 - val_accuracy: 0.6149\n",
            "Epoch 31/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6882 - accuracy: 0.5531 - val_loss: 0.6598 - val_accuracy: 0.6149\n",
            "Epoch 32/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6882 - accuracy: 0.5531 - val_loss: 0.6598 - val_accuracy: 0.6149\n",
            "Epoch 33/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6882 - accuracy: 0.5531 - val_loss: 0.6598 - val_accuracy: 0.6149\n",
            "Epoch 34/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6882 - accuracy: 0.5531 - val_loss: 0.6598 - val_accuracy: 0.6149\n",
            "Epoch 35/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6882 - accuracy: 0.5531 - val_loss: 0.6598 - val_accuracy: 0.6149\n",
            "Epoch 36/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6882 - accuracy: 0.5531 - val_loss: 0.6598 - val_accuracy: 0.6149\n",
            "Epoch 37/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6882 - accuracy: 0.5531 - val_loss: 0.6597 - val_accuracy: 0.6149\n",
            "Epoch 38/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6881 - accuracy: 0.5531 - val_loss: 0.6597 - val_accuracy: 0.6207\n",
            "Epoch 39/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6881 - accuracy: 0.5531 - val_loss: 0.6597 - val_accuracy: 0.6207\n",
            "Epoch 40/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6881 - accuracy: 0.5531 - val_loss: 0.6597 - val_accuracy: 0.6207\n",
            "Epoch 41/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6881 - accuracy: 0.5531 - val_loss: 0.6597 - val_accuracy: 0.6207\n",
            "Epoch 42/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6881 - accuracy: 0.5531 - val_loss: 0.6597 - val_accuracy: 0.6207\n",
            "Epoch 43/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6881 - accuracy: 0.5531 - val_loss: 0.6597 - val_accuracy: 0.6264\n",
            "Epoch 44/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6881 - accuracy: 0.5531 - val_loss: 0.6597 - val_accuracy: 0.6264\n",
            "Epoch 45/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6881 - accuracy: 0.5531 - val_loss: 0.6596 - val_accuracy: 0.6264\n",
            "Epoch 46/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6880 - accuracy: 0.5556 - val_loss: 0.6596 - val_accuracy: 0.6264\n",
            "Epoch 47/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6880 - accuracy: 0.5556 - val_loss: 0.6596 - val_accuracy: 0.6264\n",
            "Epoch 48/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6880 - accuracy: 0.5556 - val_loss: 0.6596 - val_accuracy: 0.6264\n",
            "Epoch 49/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6880 - accuracy: 0.5556 - val_loss: 0.6596 - val_accuracy: 0.6264\n",
            "Epoch 50/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6880 - accuracy: 0.5556 - val_loss: 0.6596 - val_accuracy: 0.6264\n",
            "Epoch 51/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6880 - accuracy: 0.5556 - val_loss: 0.6596 - val_accuracy: 0.6264\n",
            "Epoch 52/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6880 - accuracy: 0.5556 - val_loss: 0.6596 - val_accuracy: 0.6264\n",
            "Epoch 53/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6880 - accuracy: 0.5556 - val_loss: 0.6596 - val_accuracy: 0.6264\n",
            "Epoch 54/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6879 - accuracy: 0.5556 - val_loss: 0.6595 - val_accuracy: 0.6264\n",
            "Epoch 55/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6879 - accuracy: 0.5556 - val_loss: 0.6595 - val_accuracy: 0.6264\n",
            "Epoch 56/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6879 - accuracy: 0.5556 - val_loss: 0.6595 - val_accuracy: 0.6264\n",
            "Epoch 57/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6879 - accuracy: 0.5556 - val_loss: 0.6595 - val_accuracy: 0.6264\n",
            "Epoch 58/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6879 - accuracy: 0.5556 - val_loss: 0.6595 - val_accuracy: 0.6264\n",
            "Epoch 59/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6879 - accuracy: 0.5556 - val_loss: 0.6595 - val_accuracy: 0.6264\n",
            "Epoch 60/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6879 - accuracy: 0.5580 - val_loss: 0.6595 - val_accuracy: 0.6264\n",
            "Epoch 61/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6879 - accuracy: 0.5580 - val_loss: 0.6595 - val_accuracy: 0.6264\n",
            "Epoch 62/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6878 - accuracy: 0.5580 - val_loss: 0.6594 - val_accuracy: 0.6264\n",
            "Epoch 63/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6878 - accuracy: 0.5580 - val_loss: 0.6594 - val_accuracy: 0.6264\n",
            "Epoch 64/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6878 - accuracy: 0.5580 - val_loss: 0.6594 - val_accuracy: 0.6264\n",
            "Epoch 65/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6878 - accuracy: 0.5580 - val_loss: 0.6594 - val_accuracy: 0.6264\n",
            "Epoch 66/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6878 - accuracy: 0.5580 - val_loss: 0.6594 - val_accuracy: 0.6264\n",
            "Epoch 67/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6878 - accuracy: 0.5580 - val_loss: 0.6594 - val_accuracy: 0.6264\n",
            "Epoch 68/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6878 - accuracy: 0.5580 - val_loss: 0.6594 - val_accuracy: 0.6264\n",
            "Epoch 69/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6878 - accuracy: 0.5580 - val_loss: 0.6594 - val_accuracy: 0.6264\n",
            "Epoch 70/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6877 - accuracy: 0.5580 - val_loss: 0.6594 - val_accuracy: 0.6264\n",
            "Epoch 71/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6877 - accuracy: 0.5580 - val_loss: 0.6593 - val_accuracy: 0.6264\n",
            "Epoch 72/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6877 - accuracy: 0.5580 - val_loss: 0.6593 - val_accuracy: 0.6264\n",
            "Epoch 73/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6877 - accuracy: 0.5580 - val_loss: 0.6593 - val_accuracy: 0.6264\n",
            "Epoch 74/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6877 - accuracy: 0.5580 - val_loss: 0.6593 - val_accuracy: 0.6264\n",
            "Epoch 75/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6877 - accuracy: 0.5580 - val_loss: 0.6593 - val_accuracy: 0.6264\n",
            "Epoch 76/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6877 - accuracy: 0.5580 - val_loss: 0.6593 - val_accuracy: 0.6264\n",
            "Epoch 77/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6877 - accuracy: 0.5580 - val_loss: 0.6593 - val_accuracy: 0.6264\n",
            "Epoch 78/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6876 - accuracy: 0.5580 - val_loss: 0.6593 - val_accuracy: 0.6264\n",
            "Epoch 79/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6876 - accuracy: 0.5580 - val_loss: 0.6593 - val_accuracy: 0.6264\n",
            "Epoch 80/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6876 - accuracy: 0.5580 - val_loss: 0.6592 - val_accuracy: 0.6264\n",
            "Epoch 81/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6876 - accuracy: 0.5580 - val_loss: 0.6592 - val_accuracy: 0.6264\n",
            "Epoch 82/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6876 - accuracy: 0.5580 - val_loss: 0.6592 - val_accuracy: 0.6264\n",
            "Epoch 83/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6876 - accuracy: 0.5580 - val_loss: 0.6592 - val_accuracy: 0.6264\n",
            "Epoch 84/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6876 - accuracy: 0.5580 - val_loss: 0.6592 - val_accuracy: 0.6264\n",
            "Epoch 85/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6876 - accuracy: 0.5580 - val_loss: 0.6592 - val_accuracy: 0.6264\n",
            "Epoch 86/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6875 - accuracy: 0.5580 - val_loss: 0.6592 - val_accuracy: 0.6264\n",
            "Epoch 87/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6875 - accuracy: 0.5580 - val_loss: 0.6592 - val_accuracy: 0.6264\n",
            "Epoch 88/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6875 - accuracy: 0.5580 - val_loss: 0.6591 - val_accuracy: 0.6264\n",
            "Epoch 89/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6875 - accuracy: 0.5580 - val_loss: 0.6591 - val_accuracy: 0.6264\n",
            "Epoch 90/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6875 - accuracy: 0.5605 - val_loss: 0.6591 - val_accuracy: 0.6264\n",
            "Epoch 91/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6875 - accuracy: 0.5605 - val_loss: 0.6591 - val_accuracy: 0.6264\n",
            "Epoch 92/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6875 - accuracy: 0.5605 - val_loss: 0.6591 - val_accuracy: 0.6264\n",
            "Epoch 93/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6875 - accuracy: 0.5605 - val_loss: 0.6591 - val_accuracy: 0.6264\n",
            "Epoch 94/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6875 - accuracy: 0.5605 - val_loss: 0.6591 - val_accuracy: 0.6264\n",
            "Epoch 95/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6874 - accuracy: 0.5605 - val_loss: 0.6591 - val_accuracy: 0.6264\n",
            "Epoch 96/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6874 - accuracy: 0.5605 - val_loss: 0.6591 - val_accuracy: 0.6264\n",
            "Epoch 97/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6874 - accuracy: 0.5605 - val_loss: 0.6590 - val_accuracy: 0.6322\n",
            "Epoch 98/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6874 - accuracy: 0.5605 - val_loss: 0.6590 - val_accuracy: 0.6322\n",
            "Epoch 99/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6874 - accuracy: 0.5605 - val_loss: 0.6590 - val_accuracy: 0.6322\n",
            "Epoch 100/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6874 - accuracy: 0.5605 - val_loss: 0.6590 - val_accuracy: 0.6322\n",
            "Epoch 101/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6874 - accuracy: 0.5605 - val_loss: 0.6590 - val_accuracy: 0.6322\n",
            "Epoch 102/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6874 - accuracy: 0.5605 - val_loss: 0.6590 - val_accuracy: 0.6322\n",
            "Epoch 103/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6873 - accuracy: 0.5605 - val_loss: 0.6590 - val_accuracy: 0.6322\n",
            "Epoch 104/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6873 - accuracy: 0.5605 - val_loss: 0.6590 - val_accuracy: 0.6322\n",
            "Epoch 105/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6873 - accuracy: 0.5605 - val_loss: 0.6590 - val_accuracy: 0.6322\n",
            "Epoch 106/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6873 - accuracy: 0.5605 - val_loss: 0.6589 - val_accuracy: 0.6322\n",
            "Epoch 107/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6873 - accuracy: 0.5630 - val_loss: 0.6589 - val_accuracy: 0.6322\n",
            "Epoch 108/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6873 - accuracy: 0.5654 - val_loss: 0.6589 - val_accuracy: 0.6379\n",
            "Epoch 109/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6873 - accuracy: 0.5654 - val_loss: 0.6589 - val_accuracy: 0.6379\n",
            "Epoch 110/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6873 - accuracy: 0.5654 - val_loss: 0.6589 - val_accuracy: 0.6379\n",
            "Epoch 111/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6872 - accuracy: 0.5654 - val_loss: 0.6589 - val_accuracy: 0.6379\n",
            "Epoch 112/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6872 - accuracy: 0.5654 - val_loss: 0.6589 - val_accuracy: 0.6379\n",
            "Epoch 113/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6872 - accuracy: 0.5654 - val_loss: 0.6589 - val_accuracy: 0.6379\n",
            "Epoch 114/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6872 - accuracy: 0.5654 - val_loss: 0.6589 - val_accuracy: 0.6379\n",
            "Epoch 115/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6872 - accuracy: 0.5654 - val_loss: 0.6588 - val_accuracy: 0.6379\n",
            "Epoch 116/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6872 - accuracy: 0.5654 - val_loss: 0.6588 - val_accuracy: 0.6379\n",
            "Epoch 117/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6872 - accuracy: 0.5654 - val_loss: 0.6588 - val_accuracy: 0.6379\n",
            "Epoch 118/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6872 - accuracy: 0.5654 - val_loss: 0.6588 - val_accuracy: 0.6379\n",
            "Epoch 119/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6871 - accuracy: 0.5654 - val_loss: 0.6588 - val_accuracy: 0.6379\n",
            "Epoch 120/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6871 - accuracy: 0.5654 - val_loss: 0.6588 - val_accuracy: 0.6379\n",
            "Epoch 121/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6871 - accuracy: 0.5654 - val_loss: 0.6588 - val_accuracy: 0.6379\n",
            "Epoch 122/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6871 - accuracy: 0.5654 - val_loss: 0.6588 - val_accuracy: 0.6379\n",
            "Epoch 123/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6871 - accuracy: 0.5654 - val_loss: 0.6587 - val_accuracy: 0.6379\n",
            "Epoch 124/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6871 - accuracy: 0.5654 - val_loss: 0.6587 - val_accuracy: 0.6379\n",
            "Epoch 125/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6871 - accuracy: 0.5654 - val_loss: 0.6587 - val_accuracy: 0.6379\n",
            "Epoch 126/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6871 - accuracy: 0.5654 - val_loss: 0.6587 - val_accuracy: 0.6379\n",
            "Epoch 127/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6870 - accuracy: 0.5654 - val_loss: 0.6587 - val_accuracy: 0.6379\n",
            "Epoch 128/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6870 - accuracy: 0.5654 - val_loss: 0.6587 - val_accuracy: 0.6379\n",
            "Epoch 129/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6870 - accuracy: 0.5654 - val_loss: 0.6587 - val_accuracy: 0.6379\n",
            "Epoch 130/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6870 - accuracy: 0.5654 - val_loss: 0.6587 - val_accuracy: 0.6379\n",
            "Epoch 131/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6870 - accuracy: 0.5654 - val_loss: 0.6587 - val_accuracy: 0.6379\n",
            "Epoch 132/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6870 - accuracy: 0.5654 - val_loss: 0.6586 - val_accuracy: 0.6379\n",
            "Epoch 133/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6870 - accuracy: 0.5654 - val_loss: 0.6586 - val_accuracy: 0.6379\n",
            "Epoch 134/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6870 - accuracy: 0.5654 - val_loss: 0.6586 - val_accuracy: 0.6379\n",
            "Epoch 135/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6869 - accuracy: 0.5654 - val_loss: 0.6586 - val_accuracy: 0.6379\n",
            "Epoch 136/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6869 - accuracy: 0.5654 - val_loss: 0.6586 - val_accuracy: 0.6379\n",
            "Epoch 137/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6869 - accuracy: 0.5654 - val_loss: 0.6586 - val_accuracy: 0.6379\n",
            "Epoch 138/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6869 - accuracy: 0.5654 - val_loss: 0.6586 - val_accuracy: 0.6379\n",
            "Epoch 139/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6869 - accuracy: 0.5654 - val_loss: 0.6586 - val_accuracy: 0.6379\n",
            "Epoch 140/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6869 - accuracy: 0.5654 - val_loss: 0.6586 - val_accuracy: 0.6379\n",
            "Epoch 141/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6869 - accuracy: 0.5654 - val_loss: 0.6585 - val_accuracy: 0.6379\n",
            "Epoch 142/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6869 - accuracy: 0.5654 - val_loss: 0.6585 - val_accuracy: 0.6379\n",
            "Epoch 143/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6869 - accuracy: 0.5654 - val_loss: 0.6585 - val_accuracy: 0.6379\n",
            "Epoch 144/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6868 - accuracy: 0.5654 - val_loss: 0.6585 - val_accuracy: 0.6379\n",
            "Epoch 145/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6868 - accuracy: 0.5654 - val_loss: 0.6585 - val_accuracy: 0.6379\n",
            "Epoch 146/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6868 - accuracy: 0.5654 - val_loss: 0.6585 - val_accuracy: 0.6379\n",
            "Epoch 147/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6868 - accuracy: 0.5654 - val_loss: 0.6585 - val_accuracy: 0.6379\n",
            "Epoch 148/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6868 - accuracy: 0.5654 - val_loss: 0.6585 - val_accuracy: 0.6379\n",
            "Epoch 149/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6868 - accuracy: 0.5654 - val_loss: 0.6585 - val_accuracy: 0.6379\n",
            "Epoch 150/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6868 - accuracy: 0.5654 - val_loss: 0.6584 - val_accuracy: 0.6379\n",
            "Epoch 151/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6868 - accuracy: 0.5654 - val_loss: 0.6584 - val_accuracy: 0.6379\n",
            "Epoch 152/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6867 - accuracy: 0.5654 - val_loss: 0.6584 - val_accuracy: 0.6379\n",
            "Epoch 153/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6867 - accuracy: 0.5654 - val_loss: 0.6584 - val_accuracy: 0.6379\n",
            "Epoch 154/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6867 - accuracy: 0.5679 - val_loss: 0.6584 - val_accuracy: 0.6379\n",
            "Epoch 155/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6867 - accuracy: 0.5679 - val_loss: 0.6584 - val_accuracy: 0.6379\n",
            "Epoch 156/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6867 - accuracy: 0.5679 - val_loss: 0.6584 - val_accuracy: 0.6379\n",
            "Epoch 157/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6867 - accuracy: 0.5704 - val_loss: 0.6584 - val_accuracy: 0.6379\n",
            "Epoch 158/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6867 - accuracy: 0.5704 - val_loss: 0.6583 - val_accuracy: 0.6379\n",
            "Epoch 159/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6867 - accuracy: 0.5704 - val_loss: 0.6583 - val_accuracy: 0.6379\n",
            "Epoch 160/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6866 - accuracy: 0.5728 - val_loss: 0.6583 - val_accuracy: 0.6379\n",
            "Epoch 161/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6866 - accuracy: 0.5728 - val_loss: 0.6583 - val_accuracy: 0.6379\n",
            "Epoch 162/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6866 - accuracy: 0.5728 - val_loss: 0.6583 - val_accuracy: 0.6379\n",
            "Epoch 163/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6866 - accuracy: 0.5728 - val_loss: 0.6583 - val_accuracy: 0.6379\n",
            "Epoch 164/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6866 - accuracy: 0.5728 - val_loss: 0.6583 - val_accuracy: 0.6379\n",
            "Epoch 165/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6866 - accuracy: 0.5728 - val_loss: 0.6583 - val_accuracy: 0.6379\n",
            "Epoch 166/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6866 - accuracy: 0.5728 - val_loss: 0.6583 - val_accuracy: 0.6379\n",
            "Epoch 167/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6866 - accuracy: 0.5728 - val_loss: 0.6582 - val_accuracy: 0.6379\n",
            "Epoch 168/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6865 - accuracy: 0.5728 - val_loss: 0.6582 - val_accuracy: 0.6379\n",
            "Epoch 169/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6865 - accuracy: 0.5728 - val_loss: 0.6582 - val_accuracy: 0.6379\n",
            "Epoch 170/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6865 - accuracy: 0.5728 - val_loss: 0.6582 - val_accuracy: 0.6379\n",
            "Epoch 171/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6865 - accuracy: 0.5728 - val_loss: 0.6582 - val_accuracy: 0.6379\n",
            "Epoch 172/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6865 - accuracy: 0.5728 - val_loss: 0.6582 - val_accuracy: 0.6379\n",
            "Epoch 173/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6865 - accuracy: 0.5728 - val_loss: 0.6582 - val_accuracy: 0.6379\n",
            "Epoch 174/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6865 - accuracy: 0.5728 - val_loss: 0.6582 - val_accuracy: 0.6379\n",
            "Epoch 175/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6865 - accuracy: 0.5728 - val_loss: 0.6582 - val_accuracy: 0.6379\n",
            "Epoch 176/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6865 - accuracy: 0.5728 - val_loss: 0.6581 - val_accuracy: 0.6379\n",
            "Epoch 177/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6864 - accuracy: 0.5728 - val_loss: 0.6581 - val_accuracy: 0.6379\n",
            "Epoch 178/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6864 - accuracy: 0.5728 - val_loss: 0.6581 - val_accuracy: 0.6379\n",
            "Epoch 179/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6864 - accuracy: 0.5728 - val_loss: 0.6581 - val_accuracy: 0.6379\n",
            "Epoch 180/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6864 - accuracy: 0.5728 - val_loss: 0.6581 - val_accuracy: 0.6379\n",
            "Epoch 181/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6864 - accuracy: 0.5728 - val_loss: 0.6581 - val_accuracy: 0.6379\n",
            "Epoch 182/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6864 - accuracy: 0.5728 - val_loss: 0.6581 - val_accuracy: 0.6379\n",
            "Epoch 183/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6864 - accuracy: 0.5753 - val_loss: 0.6581 - val_accuracy: 0.6379\n",
            "Epoch 184/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6864 - accuracy: 0.5753 - val_loss: 0.6581 - val_accuracy: 0.6379\n",
            "Epoch 185/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6863 - accuracy: 0.5753 - val_loss: 0.6580 - val_accuracy: 0.6379\n",
            "Epoch 186/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6863 - accuracy: 0.5753 - val_loss: 0.6580 - val_accuracy: 0.6379\n",
            "Epoch 187/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6863 - accuracy: 0.5753 - val_loss: 0.6580 - val_accuracy: 0.6379\n",
            "Epoch 188/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6863 - accuracy: 0.5753 - val_loss: 0.6580 - val_accuracy: 0.6379\n",
            "Epoch 189/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6863 - accuracy: 0.5753 - val_loss: 0.6580 - val_accuracy: 0.6379\n",
            "Epoch 190/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6863 - accuracy: 0.5753 - val_loss: 0.6580 - val_accuracy: 0.6379\n",
            "Epoch 191/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6863 - accuracy: 0.5753 - val_loss: 0.6580 - val_accuracy: 0.6379\n",
            "Epoch 192/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6863 - accuracy: 0.5753 - val_loss: 0.6580 - val_accuracy: 0.6379\n",
            "Epoch 193/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6862 - accuracy: 0.5753 - val_loss: 0.6580 - val_accuracy: 0.6379\n",
            "Epoch 194/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6862 - accuracy: 0.5753 - val_loss: 0.6579 - val_accuracy: 0.6379\n",
            "Epoch 195/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6862 - accuracy: 0.5753 - val_loss: 0.6579 - val_accuracy: 0.6379\n",
            "Epoch 196/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6862 - accuracy: 0.5753 - val_loss: 0.6579 - val_accuracy: 0.6379\n",
            "Epoch 197/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6862 - accuracy: 0.5753 - val_loss: 0.6579 - val_accuracy: 0.6379\n",
            "Epoch 198/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6862 - accuracy: 0.5753 - val_loss: 0.6579 - val_accuracy: 0.6379\n",
            "Epoch 199/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6862 - accuracy: 0.5753 - val_loss: 0.6579 - val_accuracy: 0.6379\n",
            "Epoch 200/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6862 - accuracy: 0.5753 - val_loss: 0.6579 - val_accuracy: 0.6379\n",
            "Epoch 201/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6862 - accuracy: 0.5753 - val_loss: 0.6579 - val_accuracy: 0.6379\n",
            "Epoch 202/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6861 - accuracy: 0.5753 - val_loss: 0.6579 - val_accuracy: 0.6379\n",
            "Epoch 203/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6861 - accuracy: 0.5753 - val_loss: 0.6578 - val_accuracy: 0.6379\n",
            "Epoch 204/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6861 - accuracy: 0.5753 - val_loss: 0.6578 - val_accuracy: 0.6379\n",
            "Epoch 205/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6861 - accuracy: 0.5753 - val_loss: 0.6578 - val_accuracy: 0.6437\n",
            "Epoch 206/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6861 - accuracy: 0.5778 - val_loss: 0.6578 - val_accuracy: 0.6437\n",
            "Epoch 207/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6861 - accuracy: 0.5778 - val_loss: 0.6578 - val_accuracy: 0.6437\n",
            "Epoch 208/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6861 - accuracy: 0.5778 - val_loss: 0.6578 - val_accuracy: 0.6437\n",
            "Epoch 209/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6861 - accuracy: 0.5778 - val_loss: 0.6578 - val_accuracy: 0.6437\n",
            "Epoch 210/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6860 - accuracy: 0.5778 - val_loss: 0.6578 - val_accuracy: 0.6437\n",
            "Epoch 211/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6860 - accuracy: 0.5778 - val_loss: 0.6577 - val_accuracy: 0.6437\n",
            "Epoch 212/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6860 - accuracy: 0.5778 - val_loss: 0.6577 - val_accuracy: 0.6437\n",
            "Epoch 213/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6860 - accuracy: 0.5778 - val_loss: 0.6577 - val_accuracy: 0.6437\n",
            "Epoch 214/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6860 - accuracy: 0.5778 - val_loss: 0.6577 - val_accuracy: 0.6437\n",
            "Epoch 215/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6860 - accuracy: 0.5778 - val_loss: 0.6577 - val_accuracy: 0.6437\n",
            "Epoch 216/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6860 - accuracy: 0.5778 - val_loss: 0.6577 - val_accuracy: 0.6437\n",
            "Epoch 217/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6860 - accuracy: 0.5778 - val_loss: 0.6577 - val_accuracy: 0.6437\n",
            "Epoch 218/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6859 - accuracy: 0.5778 - val_loss: 0.6577 - val_accuracy: 0.6437\n",
            "Epoch 219/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6859 - accuracy: 0.5778 - val_loss: 0.6577 - val_accuracy: 0.6437\n",
            "Epoch 220/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6859 - accuracy: 0.5778 - val_loss: 0.6577 - val_accuracy: 0.6437\n",
            "Epoch 221/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6859 - accuracy: 0.5778 - val_loss: 0.6576 - val_accuracy: 0.6437\n",
            "Epoch 222/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6859 - accuracy: 0.5778 - val_loss: 0.6576 - val_accuracy: 0.6437\n",
            "Epoch 223/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6859 - accuracy: 0.5778 - val_loss: 0.6576 - val_accuracy: 0.6437\n",
            "Epoch 224/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6859 - accuracy: 0.5778 - val_loss: 0.6576 - val_accuracy: 0.6437\n",
            "Epoch 225/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6859 - accuracy: 0.5778 - val_loss: 0.6576 - val_accuracy: 0.6437\n",
            "Epoch 226/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6859 - accuracy: 0.5778 - val_loss: 0.6576 - val_accuracy: 0.6437\n",
            "Epoch 227/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6858 - accuracy: 0.5778 - val_loss: 0.6576 - val_accuracy: 0.6437\n",
            "Epoch 228/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6858 - accuracy: 0.5778 - val_loss: 0.6576 - val_accuracy: 0.6437\n",
            "Epoch 229/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6858 - accuracy: 0.5778 - val_loss: 0.6576 - val_accuracy: 0.6437\n",
            "Epoch 230/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6858 - accuracy: 0.5778 - val_loss: 0.6575 - val_accuracy: 0.6437\n",
            "Epoch 231/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6858 - accuracy: 0.5778 - val_loss: 0.6575 - val_accuracy: 0.6437\n",
            "Epoch 232/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6858 - accuracy: 0.5778 - val_loss: 0.6575 - val_accuracy: 0.6437\n",
            "Epoch 233/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6858 - accuracy: 0.5778 - val_loss: 0.6575 - val_accuracy: 0.6437\n",
            "Epoch 234/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6858 - accuracy: 0.5778 - val_loss: 0.6575 - val_accuracy: 0.6437\n",
            "Epoch 235/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6857 - accuracy: 0.5778 - val_loss: 0.6575 - val_accuracy: 0.6437\n",
            "Epoch 236/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6857 - accuracy: 0.5778 - val_loss: 0.6575 - val_accuracy: 0.6437\n",
            "Epoch 237/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6857 - accuracy: 0.5778 - val_loss: 0.6575 - val_accuracy: 0.6437\n",
            "Epoch 238/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6857 - accuracy: 0.5778 - val_loss: 0.6575 - val_accuracy: 0.6437\n",
            "Epoch 239/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6857 - accuracy: 0.5778 - val_loss: 0.6574 - val_accuracy: 0.6437\n",
            "Epoch 240/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6857 - accuracy: 0.5778 - val_loss: 0.6574 - val_accuracy: 0.6437\n",
            "Epoch 241/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6857 - accuracy: 0.5778 - val_loss: 0.6574 - val_accuracy: 0.6437\n",
            "Epoch 242/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6857 - accuracy: 0.5778 - val_loss: 0.6574 - val_accuracy: 0.6437\n",
            "Epoch 243/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6857 - accuracy: 0.5778 - val_loss: 0.6574 - val_accuracy: 0.6437\n",
            "Epoch 244/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6856 - accuracy: 0.5778 - val_loss: 0.6574 - val_accuracy: 0.6437\n",
            "Epoch 245/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6856 - accuracy: 0.5778 - val_loss: 0.6574 - val_accuracy: 0.6437\n",
            "Epoch 246/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6856 - accuracy: 0.5778 - val_loss: 0.6574 - val_accuracy: 0.6437\n",
            "Epoch 247/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6856 - accuracy: 0.5778 - val_loss: 0.6574 - val_accuracy: 0.6437\n",
            "Epoch 248/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6856 - accuracy: 0.5778 - val_loss: 0.6573 - val_accuracy: 0.6437\n",
            "Epoch 249/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6856 - accuracy: 0.5778 - val_loss: 0.6573 - val_accuracy: 0.6437\n",
            "Epoch 250/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6856 - accuracy: 0.5778 - val_loss: 0.6573 - val_accuracy: 0.6437\n",
            "Epoch 251/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6856 - accuracy: 0.5778 - val_loss: 0.6573 - val_accuracy: 0.6437\n",
            "Epoch 252/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6856 - accuracy: 0.5778 - val_loss: 0.6573 - val_accuracy: 0.6437\n",
            "Epoch 253/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6855 - accuracy: 0.5778 - val_loss: 0.6573 - val_accuracy: 0.6437\n",
            "Epoch 254/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6855 - accuracy: 0.5778 - val_loss: 0.6573 - val_accuracy: 0.6437\n",
            "Epoch 255/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6855 - accuracy: 0.5778 - val_loss: 0.6573 - val_accuracy: 0.6437\n",
            "Epoch 256/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6855 - accuracy: 0.5778 - val_loss: 0.6573 - val_accuracy: 0.6437\n",
            "Epoch 257/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6855 - accuracy: 0.5778 - val_loss: 0.6572 - val_accuracy: 0.6437\n",
            "Epoch 258/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6855 - accuracy: 0.5778 - val_loss: 0.6572 - val_accuracy: 0.6437\n",
            "Epoch 259/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6855 - accuracy: 0.5778 - val_loss: 0.6572 - val_accuracy: 0.6437\n",
            "Epoch 260/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6855 - accuracy: 0.5778 - val_loss: 0.6572 - val_accuracy: 0.6437\n",
            "Epoch 261/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6854 - accuracy: 0.5778 - val_loss: 0.6572 - val_accuracy: 0.6437\n",
            "Epoch 262/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6854 - accuracy: 0.5778 - val_loss: 0.6572 - val_accuracy: 0.6437\n",
            "Epoch 263/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6854 - accuracy: 0.5778 - val_loss: 0.6572 - val_accuracy: 0.6437\n",
            "Epoch 264/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6854 - accuracy: 0.5778 - val_loss: 0.6572 - val_accuracy: 0.6437\n",
            "Epoch 265/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6854 - accuracy: 0.5778 - val_loss: 0.6572 - val_accuracy: 0.6437\n",
            "Epoch 266/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6854 - accuracy: 0.5778 - val_loss: 0.6572 - val_accuracy: 0.6437\n",
            "Epoch 267/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6854 - accuracy: 0.5778 - val_loss: 0.6571 - val_accuracy: 0.6437\n",
            "Epoch 268/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6854 - accuracy: 0.5778 - val_loss: 0.6571 - val_accuracy: 0.6437\n",
            "Epoch 269/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6854 - accuracy: 0.5778 - val_loss: 0.6571 - val_accuracy: 0.6437\n",
            "Epoch 270/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6853 - accuracy: 0.5778 - val_loss: 0.6571 - val_accuracy: 0.6437\n",
            "Epoch 271/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6853 - accuracy: 0.5778 - val_loss: 0.6571 - val_accuracy: 0.6437\n",
            "Epoch 272/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6853 - accuracy: 0.5778 - val_loss: 0.6571 - val_accuracy: 0.6437\n",
            "Epoch 273/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6853 - accuracy: 0.5778 - val_loss: 0.6571 - val_accuracy: 0.6437\n",
            "Epoch 274/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6853 - accuracy: 0.5778 - val_loss: 0.6571 - val_accuracy: 0.6437\n",
            "Epoch 275/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6853 - accuracy: 0.5778 - val_loss: 0.6571 - val_accuracy: 0.6437\n",
            "Epoch 276/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6853 - accuracy: 0.5802 - val_loss: 0.6570 - val_accuracy: 0.6437\n",
            "Epoch 277/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6853 - accuracy: 0.5802 - val_loss: 0.6570 - val_accuracy: 0.6437\n",
            "Epoch 278/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6852 - accuracy: 0.5802 - val_loss: 0.6570 - val_accuracy: 0.6437\n",
            "Epoch 279/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6852 - accuracy: 0.5802 - val_loss: 0.6570 - val_accuracy: 0.6437\n",
            "Epoch 280/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6852 - accuracy: 0.5802 - val_loss: 0.6570 - val_accuracy: 0.6437\n",
            "Epoch 281/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6852 - accuracy: 0.5802 - val_loss: 0.6570 - val_accuracy: 0.6437\n",
            "Epoch 282/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6852 - accuracy: 0.5802 - val_loss: 0.6570 - val_accuracy: 0.6437\n",
            "Epoch 283/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6852 - accuracy: 0.5802 - val_loss: 0.6570 - val_accuracy: 0.6437\n",
            "Epoch 284/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6852 - accuracy: 0.5827 - val_loss: 0.6570 - val_accuracy: 0.6437\n",
            "Epoch 285/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6852 - accuracy: 0.5827 - val_loss: 0.6569 - val_accuracy: 0.6437\n",
            "Epoch 286/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6852 - accuracy: 0.5827 - val_loss: 0.6569 - val_accuracy: 0.6437\n",
            "Epoch 287/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6851 - accuracy: 0.5827 - val_loss: 0.6569 - val_accuracy: 0.6437\n",
            "Epoch 288/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6851 - accuracy: 0.5827 - val_loss: 0.6569 - val_accuracy: 0.6437\n",
            "Epoch 289/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6851 - accuracy: 0.5827 - val_loss: 0.6569 - val_accuracy: 0.6437\n",
            "Epoch 290/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6851 - accuracy: 0.5827 - val_loss: 0.6569 - val_accuracy: 0.6437\n",
            "Epoch 291/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6851 - accuracy: 0.5827 - val_loss: 0.6569 - val_accuracy: 0.6437\n",
            "Epoch 292/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6851 - accuracy: 0.5827 - val_loss: 0.6569 - val_accuracy: 0.6437\n",
            "Epoch 293/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6851 - accuracy: 0.5827 - val_loss: 0.6569 - val_accuracy: 0.6437\n",
            "Epoch 294/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6851 - accuracy: 0.5852 - val_loss: 0.6568 - val_accuracy: 0.6437\n",
            "Epoch 295/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6851 - accuracy: 0.5852 - val_loss: 0.6568 - val_accuracy: 0.6437\n",
            "Epoch 296/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6850 - accuracy: 0.5852 - val_loss: 0.6568 - val_accuracy: 0.6437\n",
            "Epoch 297/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6850 - accuracy: 0.5852 - val_loss: 0.6568 - val_accuracy: 0.6437\n",
            "Epoch 298/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6850 - accuracy: 0.5852 - val_loss: 0.6568 - val_accuracy: 0.6437\n",
            "Epoch 299/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6850 - accuracy: 0.5852 - val_loss: 0.6568 - val_accuracy: 0.6437\n",
            "Epoch 300/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6850 - accuracy: 0.5852 - val_loss: 0.6568 - val_accuracy: 0.6437\n",
            "Epoch 301/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6850 - accuracy: 0.5852 - val_loss: 0.6568 - val_accuracy: 0.6437\n",
            "Epoch 302/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6850 - accuracy: 0.5852 - val_loss: 0.6568 - val_accuracy: 0.6437\n",
            "Epoch 303/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6850 - accuracy: 0.5877 - val_loss: 0.6567 - val_accuracy: 0.6437\n",
            "Epoch 304/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6849 - accuracy: 0.5877 - val_loss: 0.6567 - val_accuracy: 0.6437\n",
            "Epoch 305/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6849 - accuracy: 0.5877 - val_loss: 0.6567 - val_accuracy: 0.6437\n",
            "Epoch 306/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6849 - accuracy: 0.5877 - val_loss: 0.6567 - val_accuracy: 0.6437\n",
            "Epoch 307/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6849 - accuracy: 0.5877 - val_loss: 0.6567 - val_accuracy: 0.6437\n",
            "Epoch 308/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6849 - accuracy: 0.5877 - val_loss: 0.6567 - val_accuracy: 0.6437\n",
            "Epoch 309/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6849 - accuracy: 0.5877 - val_loss: 0.6567 - val_accuracy: 0.6437\n",
            "Epoch 310/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6849 - accuracy: 0.5877 - val_loss: 0.6567 - val_accuracy: 0.6437\n",
            "Epoch 311/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6849 - accuracy: 0.5877 - val_loss: 0.6567 - val_accuracy: 0.6437\n",
            "Epoch 312/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6849 - accuracy: 0.5877 - val_loss: 0.6566 - val_accuracy: 0.6437\n",
            "Epoch 313/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6848 - accuracy: 0.5877 - val_loss: 0.6566 - val_accuracy: 0.6437\n",
            "Epoch 314/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6848 - accuracy: 0.5877 - val_loss: 0.6566 - val_accuracy: 0.6437\n",
            "Epoch 315/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6848 - accuracy: 0.5877 - val_loss: 0.6566 - val_accuracy: 0.6437\n",
            "Epoch 316/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6848 - accuracy: 0.5877 - val_loss: 0.6566 - val_accuracy: 0.6437\n",
            "Epoch 317/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6848 - accuracy: 0.5877 - val_loss: 0.6566 - val_accuracy: 0.6437\n",
            "Epoch 318/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6848 - accuracy: 0.5877 - val_loss: 0.6566 - val_accuracy: 0.6437\n",
            "Epoch 319/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6848 - accuracy: 0.5877 - val_loss: 0.6566 - val_accuracy: 0.6437\n",
            "Epoch 320/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6848 - accuracy: 0.5877 - val_loss: 0.6566 - val_accuracy: 0.6437\n",
            "Epoch 321/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6847 - accuracy: 0.5877 - val_loss: 0.6565 - val_accuracy: 0.6437\n",
            "Epoch 322/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6847 - accuracy: 0.5877 - val_loss: 0.6565 - val_accuracy: 0.6437\n",
            "Epoch 323/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6847 - accuracy: 0.5877 - val_loss: 0.6565 - val_accuracy: 0.6437\n",
            "Epoch 324/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6847 - accuracy: 0.5877 - val_loss: 0.6565 - val_accuracy: 0.6437\n",
            "Epoch 325/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6847 - accuracy: 0.5877 - val_loss: 0.6565 - val_accuracy: 0.6437\n",
            "Epoch 326/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6847 - accuracy: 0.5877 - val_loss: 0.6565 - val_accuracy: 0.6437\n",
            "Epoch 327/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6847 - accuracy: 0.5877 - val_loss: 0.6565 - val_accuracy: 0.6437\n",
            "Epoch 328/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6847 - accuracy: 0.5877 - val_loss: 0.6565 - val_accuracy: 0.6437\n",
            "Epoch 329/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6847 - accuracy: 0.5877 - val_loss: 0.6565 - val_accuracy: 0.6437\n",
            "Epoch 330/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6846 - accuracy: 0.5877 - val_loss: 0.6564 - val_accuracy: 0.6437\n",
            "Epoch 331/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6846 - accuracy: 0.5877 - val_loss: 0.6564 - val_accuracy: 0.6437\n",
            "Epoch 332/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6846 - accuracy: 0.5877 - val_loss: 0.6564 - val_accuracy: 0.6437\n",
            "Epoch 333/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6846 - accuracy: 0.5877 - val_loss: 0.6564 - val_accuracy: 0.6437\n",
            "Epoch 334/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6846 - accuracy: 0.5877 - val_loss: 0.6564 - val_accuracy: 0.6437\n",
            "Epoch 335/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6846 - accuracy: 0.5877 - val_loss: 0.6564 - val_accuracy: 0.6437\n",
            "Epoch 336/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6846 - accuracy: 0.5877 - val_loss: 0.6564 - val_accuracy: 0.6437\n",
            "Epoch 337/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6846 - accuracy: 0.5877 - val_loss: 0.6564 - val_accuracy: 0.6437\n",
            "Epoch 338/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6845 - accuracy: 0.5852 - val_loss: 0.6564 - val_accuracy: 0.6437\n",
            "Epoch 339/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6845 - accuracy: 0.5852 - val_loss: 0.6563 - val_accuracy: 0.6437\n",
            "Epoch 340/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6845 - accuracy: 0.5852 - val_loss: 0.6563 - val_accuracy: 0.6437\n",
            "Epoch 341/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6845 - accuracy: 0.5852 - val_loss: 0.6563 - val_accuracy: 0.6437\n",
            "Epoch 342/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6845 - accuracy: 0.5852 - val_loss: 0.6563 - val_accuracy: 0.6437\n",
            "Epoch 343/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6845 - accuracy: 0.5852 - val_loss: 0.6563 - val_accuracy: 0.6437\n",
            "Epoch 344/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6845 - accuracy: 0.5852 - val_loss: 0.6563 - val_accuracy: 0.6437\n",
            "Epoch 345/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6845 - accuracy: 0.5852 - val_loss: 0.6563 - val_accuracy: 0.6437\n",
            "Epoch 346/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6845 - accuracy: 0.5852 - val_loss: 0.6563 - val_accuracy: 0.6437\n",
            "Epoch 347/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6844 - accuracy: 0.5852 - val_loss: 0.6563 - val_accuracy: 0.6437\n",
            "Epoch 348/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6844 - accuracy: 0.5852 - val_loss: 0.6562 - val_accuracy: 0.6437\n",
            "Epoch 349/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6844 - accuracy: 0.5852 - val_loss: 0.6562 - val_accuracy: 0.6437\n",
            "Epoch 350/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6844 - accuracy: 0.5852 - val_loss: 0.6562 - val_accuracy: 0.6437\n",
            "Epoch 351/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6844 - accuracy: 0.5852 - val_loss: 0.6562 - val_accuracy: 0.6437\n",
            "Epoch 352/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6844 - accuracy: 0.5852 - val_loss: 0.6562 - val_accuracy: 0.6437\n",
            "Epoch 353/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6844 - accuracy: 0.5852 - val_loss: 0.6562 - val_accuracy: 0.6437\n",
            "Epoch 354/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6844 - accuracy: 0.5852 - val_loss: 0.6562 - val_accuracy: 0.6437\n",
            "Epoch 355/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6843 - accuracy: 0.5852 - val_loss: 0.6562 - val_accuracy: 0.6437\n",
            "Epoch 356/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6843 - accuracy: 0.5877 - val_loss: 0.6562 - val_accuracy: 0.6437\n",
            "Epoch 357/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6843 - accuracy: 0.5877 - val_loss: 0.6561 - val_accuracy: 0.6437\n",
            "Epoch 358/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6843 - accuracy: 0.5877 - val_loss: 0.6561 - val_accuracy: 0.6437\n",
            "Epoch 359/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6843 - accuracy: 0.5877 - val_loss: 0.6561 - val_accuracy: 0.6437\n",
            "Epoch 360/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6843 - accuracy: 0.5877 - val_loss: 0.6561 - val_accuracy: 0.6437\n",
            "Epoch 361/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6843 - accuracy: 0.5877 - val_loss: 0.6561 - val_accuracy: 0.6437\n",
            "Epoch 362/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6843 - accuracy: 0.5877 - val_loss: 0.6561 - val_accuracy: 0.6437\n",
            "Epoch 363/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6843 - accuracy: 0.5877 - val_loss: 0.6561 - val_accuracy: 0.6437\n",
            "Epoch 364/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6842 - accuracy: 0.5877 - val_loss: 0.6561 - val_accuracy: 0.6437\n",
            "Epoch 365/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6842 - accuracy: 0.5877 - val_loss: 0.6561 - val_accuracy: 0.6437\n",
            "Epoch 366/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6842 - accuracy: 0.5877 - val_loss: 0.6560 - val_accuracy: 0.6437\n",
            "Epoch 367/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6842 - accuracy: 0.5877 - val_loss: 0.6560 - val_accuracy: 0.6437\n",
            "Epoch 368/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6842 - accuracy: 0.5877 - val_loss: 0.6560 - val_accuracy: 0.6437\n",
            "Epoch 369/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6842 - accuracy: 0.5877 - val_loss: 0.6560 - val_accuracy: 0.6437\n",
            "Epoch 370/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6842 - accuracy: 0.5877 - val_loss: 0.6560 - val_accuracy: 0.6437\n",
            "Epoch 371/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6842 - accuracy: 0.5877 - val_loss: 0.6560 - val_accuracy: 0.6437\n",
            "Epoch 372/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6842 - accuracy: 0.5877 - val_loss: 0.6560 - val_accuracy: 0.6437\n",
            "Epoch 373/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6841 - accuracy: 0.5877 - val_loss: 0.6560 - val_accuracy: 0.6437\n",
            "Epoch 374/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6841 - accuracy: 0.5877 - val_loss: 0.6560 - val_accuracy: 0.6437\n",
            "Epoch 375/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6841 - accuracy: 0.5877 - val_loss: 0.6559 - val_accuracy: 0.6437\n",
            "Epoch 376/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6841 - accuracy: 0.5877 - val_loss: 0.6559 - val_accuracy: 0.6437\n",
            "Epoch 377/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6841 - accuracy: 0.5877 - val_loss: 0.6559 - val_accuracy: 0.6437\n",
            "Epoch 378/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6841 - accuracy: 0.5877 - val_loss: 0.6559 - val_accuracy: 0.6437\n",
            "Epoch 379/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6841 - accuracy: 0.5877 - val_loss: 0.6559 - val_accuracy: 0.6437\n",
            "Epoch 380/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6841 - accuracy: 0.5877 - val_loss: 0.6559 - val_accuracy: 0.6437\n",
            "Epoch 381/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6840 - accuracy: 0.5877 - val_loss: 0.6559 - val_accuracy: 0.6437\n",
            "Epoch 382/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6840 - accuracy: 0.5877 - val_loss: 0.6559 - val_accuracy: 0.6437\n",
            "Epoch 383/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6840 - accuracy: 0.5901 - val_loss: 0.6559 - val_accuracy: 0.6437\n",
            "Epoch 384/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6840 - accuracy: 0.5901 - val_loss: 0.6558 - val_accuracy: 0.6437\n",
            "Epoch 385/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6840 - accuracy: 0.5901 - val_loss: 0.6558 - val_accuracy: 0.6437\n",
            "Epoch 386/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6840 - accuracy: 0.5901 - val_loss: 0.6558 - val_accuracy: 0.6437\n",
            "Epoch 387/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6840 - accuracy: 0.5901 - val_loss: 0.6558 - val_accuracy: 0.6437\n",
            "Epoch 388/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6840 - accuracy: 0.5901 - val_loss: 0.6558 - val_accuracy: 0.6437\n",
            "Epoch 389/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6840 - accuracy: 0.5901 - val_loss: 0.6558 - val_accuracy: 0.6437\n",
            "Epoch 390/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6839 - accuracy: 0.5901 - val_loss: 0.6558 - val_accuracy: 0.6437\n",
            "Epoch 391/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6839 - accuracy: 0.5901 - val_loss: 0.6558 - val_accuracy: 0.6437\n",
            "Epoch 392/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6839 - accuracy: 0.5901 - val_loss: 0.6558 - val_accuracy: 0.6437\n",
            "Epoch 393/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6839 - accuracy: 0.5901 - val_loss: 0.6557 - val_accuracy: 0.6437\n",
            "Epoch 394/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6839 - accuracy: 0.5901 - val_loss: 0.6557 - val_accuracy: 0.6437\n",
            "Epoch 395/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6839 - accuracy: 0.5901 - val_loss: 0.6557 - val_accuracy: 0.6437\n",
            "Epoch 396/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6839 - accuracy: 0.5901 - val_loss: 0.6557 - val_accuracy: 0.6437\n",
            "Epoch 397/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6839 - accuracy: 0.5901 - val_loss: 0.6557 - val_accuracy: 0.6437\n",
            "Epoch 398/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6838 - accuracy: 0.5901 - val_loss: 0.6557 - val_accuracy: 0.6437\n",
            "Epoch 399/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6838 - accuracy: 0.5901 - val_loss: 0.6557 - val_accuracy: 0.6437\n",
            "Epoch 400/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6838 - accuracy: 0.5901 - val_loss: 0.6557 - val_accuracy: 0.6437\n",
            "Epoch 401/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6838 - accuracy: 0.5901 - val_loss: 0.6557 - val_accuracy: 0.6437\n",
            "Epoch 402/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6838 - accuracy: 0.5901 - val_loss: 0.6556 - val_accuracy: 0.6437\n",
            "Epoch 403/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6838 - accuracy: 0.5901 - val_loss: 0.6556 - val_accuracy: 0.6437\n",
            "Epoch 404/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6838 - accuracy: 0.5901 - val_loss: 0.6556 - val_accuracy: 0.6437\n",
            "Epoch 405/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6838 - accuracy: 0.5901 - val_loss: 0.6556 - val_accuracy: 0.6437\n",
            "Epoch 406/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6838 - accuracy: 0.5901 - val_loss: 0.6556 - val_accuracy: 0.6437\n",
            "Epoch 407/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6837 - accuracy: 0.5901 - val_loss: 0.6556 - val_accuracy: 0.6437\n",
            "Epoch 408/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6837 - accuracy: 0.5901 - val_loss: 0.6556 - val_accuracy: 0.6437\n",
            "Epoch 409/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6837 - accuracy: 0.5901 - val_loss: 0.6556 - val_accuracy: 0.6437\n",
            "Epoch 410/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6837 - accuracy: 0.5901 - val_loss: 0.6556 - val_accuracy: 0.6437\n",
            "Epoch 411/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6837 - accuracy: 0.5901 - val_loss: 0.6555 - val_accuracy: 0.6437\n",
            "Epoch 412/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6837 - accuracy: 0.5901 - val_loss: 0.6555 - val_accuracy: 0.6437\n",
            "Epoch 413/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6837 - accuracy: 0.5901 - val_loss: 0.6555 - val_accuracy: 0.6437\n",
            "Epoch 414/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6837 - accuracy: 0.5901 - val_loss: 0.6555 - val_accuracy: 0.6437\n",
            "Epoch 415/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6837 - accuracy: 0.5901 - val_loss: 0.6555 - val_accuracy: 0.6437\n",
            "Epoch 416/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6836 - accuracy: 0.5901 - val_loss: 0.6555 - val_accuracy: 0.6437\n",
            "Epoch 417/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6836 - accuracy: 0.5901 - val_loss: 0.6555 - val_accuracy: 0.6437\n",
            "Epoch 418/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6836 - accuracy: 0.5901 - val_loss: 0.6555 - val_accuracy: 0.6437\n",
            "Epoch 419/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6836 - accuracy: 0.5901 - val_loss: 0.6555 - val_accuracy: 0.6437\n",
            "Epoch 420/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6836 - accuracy: 0.5901 - val_loss: 0.6554 - val_accuracy: 0.6437\n",
            "Epoch 421/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6836 - accuracy: 0.5901 - val_loss: 0.6554 - val_accuracy: 0.6437\n",
            "Epoch 422/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6836 - accuracy: 0.5901 - val_loss: 0.6554 - val_accuracy: 0.6494\n",
            "Epoch 423/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6836 - accuracy: 0.5901 - val_loss: 0.6554 - val_accuracy: 0.6494\n",
            "Epoch 424/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6836 - accuracy: 0.5901 - val_loss: 0.6554 - val_accuracy: 0.6494\n",
            "Epoch 425/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6835 - accuracy: 0.5901 - val_loss: 0.6554 - val_accuracy: 0.6494\n",
            "Epoch 426/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6835 - accuracy: 0.5901 - val_loss: 0.6554 - val_accuracy: 0.6494\n",
            "Epoch 427/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6835 - accuracy: 0.5901 - val_loss: 0.6554 - val_accuracy: 0.6494\n",
            "Epoch 428/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6835 - accuracy: 0.5901 - val_loss: 0.6554 - val_accuracy: 0.6494\n",
            "Epoch 429/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6835 - accuracy: 0.5901 - val_loss: 0.6553 - val_accuracy: 0.6494\n",
            "Epoch 430/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6835 - accuracy: 0.5901 - val_loss: 0.6553 - val_accuracy: 0.6494\n",
            "Epoch 431/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6835 - accuracy: 0.5901 - val_loss: 0.6553 - val_accuracy: 0.6494\n",
            "Epoch 432/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6835 - accuracy: 0.5901 - val_loss: 0.6553 - val_accuracy: 0.6494\n",
            "Epoch 433/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6835 - accuracy: 0.5901 - val_loss: 0.6553 - val_accuracy: 0.6494\n",
            "Epoch 434/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6834 - accuracy: 0.5901 - val_loss: 0.6553 - val_accuracy: 0.6494\n",
            "Epoch 435/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6834 - accuracy: 0.5901 - val_loss: 0.6553 - val_accuracy: 0.6494\n",
            "Epoch 436/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6834 - accuracy: 0.5901 - val_loss: 0.6553 - val_accuracy: 0.6494\n",
            "Epoch 437/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6834 - accuracy: 0.5901 - val_loss: 0.6553 - val_accuracy: 0.6494\n",
            "Epoch 438/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6834 - accuracy: 0.5901 - val_loss: 0.6552 - val_accuracy: 0.6494\n",
            "Epoch 439/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6834 - accuracy: 0.5901 - val_loss: 0.6552 - val_accuracy: 0.6494\n",
            "Epoch 440/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6834 - accuracy: 0.5901 - val_loss: 0.6552 - val_accuracy: 0.6494\n",
            "Epoch 441/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6834 - accuracy: 0.5901 - val_loss: 0.6552 - val_accuracy: 0.6494\n",
            "Epoch 442/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6834 - accuracy: 0.5901 - val_loss: 0.6552 - val_accuracy: 0.6494\n",
            "Epoch 443/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6833 - accuracy: 0.5901 - val_loss: 0.6552 - val_accuracy: 0.6552\n",
            "Epoch 444/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6833 - accuracy: 0.5901 - val_loss: 0.6552 - val_accuracy: 0.6552\n",
            "Epoch 445/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6833 - accuracy: 0.5901 - val_loss: 0.6552 - val_accuracy: 0.6552\n",
            "Epoch 446/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6833 - accuracy: 0.5901 - val_loss: 0.6552 - val_accuracy: 0.6552\n",
            "Epoch 447/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6833 - accuracy: 0.5901 - val_loss: 0.6552 - val_accuracy: 0.6552\n",
            "Epoch 448/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6833 - accuracy: 0.5901 - val_loss: 0.6551 - val_accuracy: 0.6552\n",
            "Epoch 449/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6833 - accuracy: 0.5901 - val_loss: 0.6551 - val_accuracy: 0.6552\n",
            "Epoch 450/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6833 - accuracy: 0.5901 - val_loss: 0.6551 - val_accuracy: 0.6552\n",
            "Epoch 451/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6833 - accuracy: 0.5901 - val_loss: 0.6551 - val_accuracy: 0.6552\n",
            "Epoch 452/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6832 - accuracy: 0.5901 - val_loss: 0.6551 - val_accuracy: 0.6552\n",
            "Epoch 453/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6832 - accuracy: 0.5901 - val_loss: 0.6551 - val_accuracy: 0.6552\n",
            "Epoch 454/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6832 - accuracy: 0.5901 - val_loss: 0.6551 - val_accuracy: 0.6552\n",
            "Epoch 455/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6832 - accuracy: 0.5901 - val_loss: 0.6551 - val_accuracy: 0.6552\n",
            "Epoch 456/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6832 - accuracy: 0.5901 - val_loss: 0.6551 - val_accuracy: 0.6552\n",
            "Epoch 457/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6832 - accuracy: 0.5901 - val_loss: 0.6550 - val_accuracy: 0.6552\n",
            "Epoch 458/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6832 - accuracy: 0.5901 - val_loss: 0.6550 - val_accuracy: 0.6552\n",
            "Epoch 459/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6832 - accuracy: 0.5901 - val_loss: 0.6550 - val_accuracy: 0.6552\n",
            "Epoch 460/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6832 - accuracy: 0.5901 - val_loss: 0.6550 - val_accuracy: 0.6552\n",
            "Epoch 461/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6831 - accuracy: 0.5901 - val_loss: 0.6550 - val_accuracy: 0.6552\n",
            "Epoch 462/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6831 - accuracy: 0.5901 - val_loss: 0.6550 - val_accuracy: 0.6552\n",
            "Epoch 463/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6831 - accuracy: 0.5901 - val_loss: 0.6550 - val_accuracy: 0.6552\n",
            "Epoch 464/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6831 - accuracy: 0.5901 - val_loss: 0.6550 - val_accuracy: 0.6552\n",
            "Epoch 465/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6831 - accuracy: 0.5901 - val_loss: 0.6550 - val_accuracy: 0.6552\n",
            "Epoch 466/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6831 - accuracy: 0.5901 - val_loss: 0.6549 - val_accuracy: 0.6552\n",
            "Epoch 467/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6831 - accuracy: 0.5901 - val_loss: 0.6549 - val_accuracy: 0.6552\n",
            "Epoch 468/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6831 - accuracy: 0.5901 - val_loss: 0.6549 - val_accuracy: 0.6552\n",
            "Epoch 469/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6831 - accuracy: 0.5901 - val_loss: 0.6549 - val_accuracy: 0.6552\n",
            "Epoch 470/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6830 - accuracy: 0.5901 - val_loss: 0.6549 - val_accuracy: 0.6552\n",
            "Epoch 471/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6830 - accuracy: 0.5901 - val_loss: 0.6549 - val_accuracy: 0.6552\n",
            "Epoch 472/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6830 - accuracy: 0.5901 - val_loss: 0.6549 - val_accuracy: 0.6552\n",
            "Epoch 473/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6830 - accuracy: 0.5901 - val_loss: 0.6549 - val_accuracy: 0.6552\n",
            "Epoch 474/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6830 - accuracy: 0.5901 - val_loss: 0.6549 - val_accuracy: 0.6552\n",
            "Epoch 475/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6830 - accuracy: 0.5901 - val_loss: 0.6548 - val_accuracy: 0.6609\n",
            "Epoch 476/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6830 - accuracy: 0.5901 - val_loss: 0.6548 - val_accuracy: 0.6609\n",
            "Epoch 477/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6830 - accuracy: 0.5901 - val_loss: 0.6548 - val_accuracy: 0.6609\n",
            "Epoch 478/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6830 - accuracy: 0.5901 - val_loss: 0.6548 - val_accuracy: 0.6609\n",
            "Epoch 479/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6829 - accuracy: 0.5901 - val_loss: 0.6548 - val_accuracy: 0.6609\n",
            "Epoch 480/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6829 - accuracy: 0.5901 - val_loss: 0.6548 - val_accuracy: 0.6609\n",
            "Epoch 481/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6829 - accuracy: 0.5901 - val_loss: 0.6548 - val_accuracy: 0.6609\n",
            "Epoch 482/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6829 - accuracy: 0.5901 - val_loss: 0.6548 - val_accuracy: 0.6609\n",
            "Epoch 483/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6829 - accuracy: 0.5901 - val_loss: 0.6548 - val_accuracy: 0.6609\n",
            "Epoch 484/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6829 - accuracy: 0.5901 - val_loss: 0.6547 - val_accuracy: 0.6609\n",
            "Epoch 485/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6829 - accuracy: 0.5901 - val_loss: 0.6547 - val_accuracy: 0.6609\n",
            "Epoch 486/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6829 - accuracy: 0.5901 - val_loss: 0.6547 - val_accuracy: 0.6609\n",
            "Epoch 487/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6829 - accuracy: 0.5901 - val_loss: 0.6547 - val_accuracy: 0.6609\n",
            "Epoch 488/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6828 - accuracy: 0.5901 - val_loss: 0.6547 - val_accuracy: 0.6609\n",
            "Epoch 489/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6828 - accuracy: 0.5901 - val_loss: 0.6547 - val_accuracy: 0.6609\n",
            "Epoch 490/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6828 - accuracy: 0.5901 - val_loss: 0.6547 - val_accuracy: 0.6609\n",
            "Epoch 491/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6828 - accuracy: 0.5901 - val_loss: 0.6547 - val_accuracy: 0.6667\n",
            "Epoch 492/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6828 - accuracy: 0.5901 - val_loss: 0.6547 - val_accuracy: 0.6667\n",
            "Epoch 493/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6828 - accuracy: 0.5901 - val_loss: 0.6546 - val_accuracy: 0.6667\n",
            "Epoch 494/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6828 - accuracy: 0.5901 - val_loss: 0.6546 - val_accuracy: 0.6667\n",
            "Epoch 495/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6828 - accuracy: 0.5901 - val_loss: 0.6546 - val_accuracy: 0.6667\n",
            "Epoch 496/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6828 - accuracy: 0.5901 - val_loss: 0.6546 - val_accuracy: 0.6667\n",
            "Epoch 497/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6827 - accuracy: 0.5901 - val_loss: 0.6546 - val_accuracy: 0.6667\n",
            "Epoch 498/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6827 - accuracy: 0.5901 - val_loss: 0.6546 - val_accuracy: 0.6667\n",
            "Epoch 499/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6827 - accuracy: 0.5901 - val_loss: 0.6546 - val_accuracy: 0.6667\n",
            "Epoch 500/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6827 - accuracy: 0.5901 - val_loss: 0.6546 - val_accuracy: 0.6667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1RZn7behl9F",
        "outputId": "3460010f-a456-4521-dc31-52526a75ae0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "r.history['loss']\n"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6886234283447266,\n",
              " 0.6886094212532043,\n",
              " 0.6885955333709717,\n",
              " 0.6885818839073181,\n",
              " 0.6885680556297302,\n",
              " 0.6885546445846558,\n",
              " 0.6885409951210022,\n",
              " 0.6885277032852173,\n",
              " 0.6885139346122742,\n",
              " 0.6885005235671997,\n",
              " 0.6884869337081909,\n",
              " 0.6884734034538269,\n",
              " 0.6884599924087524,\n",
              " 0.688447117805481,\n",
              " 0.6884335875511169,\n",
              " 0.6884204149246216,\n",
              " 0.6884073615074158,\n",
              " 0.6883942484855652,\n",
              " 0.6883813142776489,\n",
              " 0.6883687973022461,\n",
              " 0.688355565071106,\n",
              " 0.6883428692817688,\n",
              " 0.6883301734924316,\n",
              " 0.6883172392845154,\n",
              " 0.6883044838905334,\n",
              " 0.6882916688919067,\n",
              " 0.6882790923118591,\n",
              " 0.6882660984992981,\n",
              " 0.6882534623146057,\n",
              " 0.6882407665252686,\n",
              " 0.6882279515266418,\n",
              " 0.6882153153419495,\n",
              " 0.6882026791572571,\n",
              " 0.688190221786499,\n",
              " 0.6881776452064514,\n",
              " 0.6881647706031799,\n",
              " 0.6881520748138428,\n",
              " 0.688139796257019,\n",
              " 0.6881272196769714,\n",
              " 0.6881142854690552,\n",
              " 0.6881017684936523,\n",
              " 0.6880892515182495,\n",
              " 0.6880766749382019,\n",
              " 0.6880640983581543,\n",
              " 0.6880518198013306,\n",
              " 0.6880390644073486,\n",
              " 0.6880267262458801,\n",
              " 0.6880142092704773,\n",
              " 0.6880014538764954,\n",
              " 0.6879887580871582,\n",
              " 0.687976062297821,\n",
              " 0.6879637837409973,\n",
              " 0.687951385974884,\n",
              " 0.6879392266273499,\n",
              " 0.6879271864891052,\n",
              " 0.6879147291183472,\n",
              " 0.6879023313522339,\n",
              " 0.6878899335861206,\n",
              " 0.687877893447876,\n",
              " 0.6878657341003418,\n",
              " 0.6878532767295837,\n",
              " 0.6878410577774048,\n",
              " 0.687828540802002,\n",
              " 0.6878163814544678,\n",
              " 0.687804102897644,\n",
              " 0.6877920031547546,\n",
              " 0.6877794861793518,\n",
              " 0.6877673268318176,\n",
              " 0.6877550482749939,\n",
              " 0.6877424716949463,\n",
              " 0.6877301335334778,\n",
              " 0.6877181529998779,\n",
              " 0.6877055764198303,\n",
              " 0.6876933574676514,\n",
              " 0.6876808404922485,\n",
              " 0.6876685619354248,\n",
              " 0.6876562833786011,\n",
              " 0.6876442432403564,\n",
              " 0.6876319646835327,\n",
              " 0.6876198649406433,\n",
              " 0.6876075863838196,\n",
              " 0.687595546245575,\n",
              " 0.6875835061073303,\n",
              " 0.6875714063644409,\n",
              " 0.6875598430633545,\n",
              " 0.6875478625297546,\n",
              " 0.6875359416007996,\n",
              " 0.687524139881134,\n",
              " 0.6875119209289551,\n",
              " 0.6875,\n",
              " 0.6874880194664001,\n",
              " 0.6874760389328003,\n",
              " 0.6874638795852661,\n",
              " 0.6874521374702454,\n",
              " 0.6874402165412903,\n",
              " 0.6874279379844666,\n",
              " 0.6874158382415771,\n",
              " 0.6874037981033325,\n",
              " 0.6873916983604431,\n",
              " 0.6873793601989746,\n",
              " 0.68736732006073,\n",
              " 0.6873551607131958,\n",
              " 0.6873429417610168,\n",
              " 0.6873307824134827,\n",
              " 0.6873185634613037,\n",
              " 0.6873064041137695,\n",
              " 0.6872941851615906,\n",
              " 0.6872822046279907,\n",
              " 0.6872695684432983,\n",
              " 0.6872576475143433,\n",
              " 0.6872450709342957,\n",
              " 0.6872330904006958,\n",
              " 0.687220573425293,\n",
              " 0.6872081756591797,\n",
              " 0.6871957778930664,\n",
              " 0.6871837377548218,\n",
              " 0.687171220779419,\n",
              " 0.6871588230133057,\n",
              " 0.6871461272239685,\n",
              " 0.6871340274810791,\n",
              " 0.687121570110321,\n",
              " 0.6871091723442078,\n",
              " 0.6870966553688049,\n",
              " 0.6870840787887573,\n",
              " 0.6870718598365784,\n",
              " 0.6870592832565308,\n",
              " 0.6870468258857727,\n",
              " 0.6870347857475281,\n",
              " 0.6870226263999939,\n",
              " 0.6870104670524597,\n",
              " 0.6869982481002808,\n",
              " 0.6869860291481018,\n",
              " 0.686974048614502,\n",
              " 0.6869615316390991,\n",
              " 0.6869493126869202,\n",
              " 0.6869369149208069,\n",
              " 0.6869247555732727,\n",
              " 0.6869124174118042,\n",
              " 0.68690025806427,\n",
              " 0.6868877410888672,\n",
              " 0.6868753433227539,\n",
              " 0.6868631839752197,\n",
              " 0.6868508458137512,\n",
              " 0.6868385672569275,\n",
              " 0.6868263483047485,\n",
              " 0.68681401014328,\n",
              " 0.686801552772522,\n",
              " 0.6867895126342773,\n",
              " 0.6867777705192566,\n",
              " 0.6867658495903015,\n",
              " 0.6867542266845703,\n",
              " 0.6867423057556152,\n",
              " 0.6867302656173706,\n",
              " 0.686718225479126,\n",
              " 0.6867062449455261,\n",
              " 0.6866939663887024,\n",
              " 0.6866820454597473,\n",
              " 0.6866697669029236,\n",
              " 0.6866576671600342,\n",
              " 0.6866455674171448,\n",
              " 0.6866334676742554,\n",
              " 0.6866213083267212,\n",
              " 0.6866092085838318,\n",
              " 0.6865973472595215,\n",
              " 0.6865852475166321,\n",
              " 0.6865729689598083,\n",
              " 0.6865610480308533,\n",
              " 0.6865485906600952,\n",
              " 0.6865366101264954,\n",
              " 0.6865243315696716,\n",
              " 0.6865123510360718,\n",
              " 0.6865002512931824,\n",
              " 0.686488151550293,\n",
              " 0.6864761114120483,\n",
              " 0.6864638328552246,\n",
              " 0.6864520311355591,\n",
              " 0.6864400506019592,\n",
              " 0.6864279508590698,\n",
              " 0.68641597032547,\n",
              " 0.6864039301872253,\n",
              " 0.6863917708396912,\n",
              " 0.6863799095153809,\n",
              " 0.686367928981781,\n",
              " 0.686356246471405,\n",
              " 0.6863437294960022,\n",
              " 0.6863318681716919,\n",
              " 0.686319887638092,\n",
              " 0.6863080263137817,\n",
              " 0.6862960457801819,\n",
              " 0.6862841248512268,\n",
              " 0.6862719655036926,\n",
              " 0.686259925365448,\n",
              " 0.6862481832504272,\n",
              " 0.6862362027168274,\n",
              " 0.6862241625785828,\n",
              " 0.6862120628356934,\n",
              " 0.6861999034881592,\n",
              " 0.6861882209777832,\n",
              " 0.6861763596534729,\n",
              " 0.686164379119873,\n",
              " 0.6861523985862732,\n",
              " 0.6861401796340942,\n",
              " 0.6861283183097839,\n",
              " 0.6861162185668945,\n",
              " 0.6861039996147156,\n",
              " 0.6860916018486023,\n",
              " 0.6860793828964233,\n",
              " 0.6860671043395996,\n",
              " 0.686055064201355,\n",
              " 0.6860429048538208,\n",
              " 0.6860306859016418,\n",
              " 0.686018705368042,\n",
              " 0.6860069036483765,\n",
              " 0.6859950423240662,\n",
              " 0.6859831809997559,\n",
              " 0.6859713196754456,\n",
              " 0.6859593987464905,\n",
              " 0.6859474182128906,\n",
              " 0.6859356164932251,\n",
              " 0.6859238147735596,\n",
              " 0.6859123110771179,\n",
              " 0.6859004497528076,\n",
              " 0.685888946056366,\n",
              " 0.6858773231506348,\n",
              " 0.6858655214309692,\n",
              " 0.6858535408973694,\n",
              " 0.6858416795730591,\n",
              " 0.6858300566673279,\n",
              " 0.6858181357383728,\n",
              " 0.6858064532279968,\n",
              " 0.6857949495315552,\n",
              " 0.6857832670211792,\n",
              " 0.6857715845108032,\n",
              " 0.6857597231864929,\n",
              " 0.685748279094696,\n",
              " 0.6857362389564514,\n",
              " 0.6857244968414307,\n",
              " 0.6857128143310547,\n",
              " 0.6857010722160339,\n",
              " 0.6856894493103027,\n",
              " 0.6856780052185059,\n",
              " 0.6856663823127747,\n",
              " 0.6856546401977539,\n",
              " 0.6856429576873779,\n",
              " 0.6856309771537781,\n",
              " 0.6856195330619812,\n",
              " 0.6856078505516052,\n",
              " 0.6855961680412292,\n",
              " 0.6855847239494324,\n",
              " 0.6855731010437012,\n",
              " 0.6855615973472595,\n",
              " 0.6855500340461731,\n",
              " 0.6855383515357971,\n",
              " 0.6855269074440002,\n",
              " 0.6855152249336243,\n",
              " 0.6855037808418274,\n",
              " 0.6854921579360962,\n",
              " 0.6854807138442993,\n",
              " 0.6854690313339233,\n",
              " 0.6854575872421265,\n",
              " 0.6854459643363953,\n",
              " 0.6854344606399536,\n",
              " 0.6854228377342224,\n",
              " 0.6854113340377808,\n",
              " 0.6853997111320496,\n",
              " 0.6853880286216736,\n",
              " 0.6853761076927185,\n",
              " 0.6853646039962769,\n",
              " 0.6853535175323486,\n",
              " 0.6853415369987488,\n",
              " 0.6853300333023071,\n",
              " 0.6853187680244446,\n",
              " 0.6853069067001343,\n",
              " 0.6852953433990479,\n",
              " 0.6852837204933167,\n",
              " 0.6852721571922302,\n",
              " 0.6852602958679199,\n",
              " 0.6852489113807678,\n",
              " 0.6852373480796814,\n",
              " 0.685225784778595,\n",
              " 0.6852142810821533,\n",
              " 0.6852026581764221,\n",
              " 0.6851909160614014,\n",
              " 0.6851791739463806,\n",
              " 0.6851675510406494,\n",
              " 0.6851558685302734,\n",
              " 0.6851438879966736,\n",
              " 0.6851322650909424,\n",
              " 0.6851208806037903,\n",
              " 0.6851093173027039,\n",
              " 0.6850979328155518,\n",
              " 0.6850864887237549,\n",
              " 0.6850747466087341,\n",
              " 0.6850631833076477,\n",
              " 0.6850517392158508,\n",
              " 0.6850403547286987,\n",
              " 0.6850289106369019,\n",
              " 0.685017466545105,\n",
              " 0.6850056052207947,\n",
              " 0.6849941611289978,\n",
              " 0.6849824786186218,\n",
              " 0.684971034526825,\n",
              " 0.684959352016449,\n",
              " 0.6849476099014282,\n",
              " 0.684935986995697,\n",
              " 0.6849241852760315,\n",
              " 0.684912383556366,\n",
              " 0.6849007606506348,\n",
              " 0.6848887205123901,\n",
              " 0.6848772168159485,\n",
              " 0.6848652958869934,\n",
              " 0.6848534345626831,\n",
              " 0.6848415732383728,\n",
              " 0.684829831123352,\n",
              " 0.684817910194397,\n",
              " 0.6848061084747314,\n",
              " 0.6847941279411316,\n",
              " 0.6847821474075317,\n",
              " 0.6847702860832214,\n",
              " 0.6847583055496216,\n",
              " 0.6847466826438904,\n",
              " 0.6847346425056458,\n",
              " 0.6847228407859802,\n",
              " 0.6847110986709595,\n",
              " 0.684699296951294,\n",
              " 0.6846873164176941,\n",
              " 0.6846757531166077,\n",
              " 0.6846638321876526,\n",
              " 0.6846519708633423,\n",
              " 0.6846402287483215,\n",
              " 0.6846286058425903,\n",
              " 0.6846168041229248,\n",
              " 0.6846053600311279,\n",
              " 0.6845933794975281,\n",
              " 0.6845817565917969,\n",
              " 0.6845698356628418,\n",
              " 0.6845581531524658,\n",
              " 0.6845465898513794,\n",
              " 0.6845349669456482,\n",
              " 0.6845230460166931,\n",
              " 0.6845111846923828,\n",
              " 0.6844993233680725,\n",
              " 0.6844875812530518,\n",
              " 0.6844757199287415,\n",
              " 0.6844640374183655,\n",
              " 0.6844519972801208,\n",
              " 0.6844404339790344,\n",
              " 0.6844289302825928,\n",
              " 0.6844172477722168,\n",
              " 0.6844059228897095,\n",
              " 0.6843945384025574,\n",
              " 0.6843828558921814,\n",
              " 0.6843710541725159,\n",
              " 0.6843594908714294,\n",
              " 0.684347927570343,\n",
              " 0.6843364834785461,\n",
              " 0.6843249201774597,\n",
              " 0.6843131184577942,\n",
              " 0.6843016147613525,\n",
              " 0.6842899322509766,\n",
              " 0.6842782497406006,\n",
              " 0.684266209602356,\n",
              " 0.6842546463012695,\n",
              " 0.6842430830001831,\n",
              " 0.6842315196990967,\n",
              " 0.6842198371887207,\n",
              " 0.6842082738876343,\n",
              " 0.684196412563324,\n",
              " 0.684184730052948,\n",
              " 0.6841734051704407,\n",
              " 0.6841620802879333,\n",
              " 0.6841503977775574,\n",
              " 0.6841385960578918,\n",
              " 0.6841267943382263,\n",
              " 0.684114933013916,\n",
              " 0.6841031312942505,\n",
              " 0.6840915083885193,\n",
              " 0.6840799450874329,\n",
              " 0.6840682625770569,\n",
              " 0.6840566396713257,\n",
              " 0.6840450167655945,\n",
              " 0.6840333342552185,\n",
              " 0.6840218305587769,\n",
              " 0.6840101480484009,\n",
              " 0.6839982271194458,\n",
              " 0.6839867830276489,\n",
              " 0.6839752793312073,\n",
              " 0.6839634776115417,\n",
              " 0.6839520335197449,\n",
              " 0.6839403510093689,\n",
              " 0.6839286088943481,\n",
              " 0.683917224407196,\n",
              " 0.6839057803153992,\n",
              " 0.6838940382003784,\n",
              " 0.6838827133178711,\n",
              " 0.6838712692260742,\n",
              " 0.6838598847389221,\n",
              " 0.6838483810424805,\n",
              " 0.6838369965553284,\n",
              " 0.6838255524635315,\n",
              " 0.6838141083717346,\n",
              " 0.6838027834892273,\n",
              " 0.6837913393974304,\n",
              " 0.6837800145149231,\n",
              " 0.6837688088417053,\n",
              " 0.6837575435638428,\n",
              " 0.6837461590766907,\n",
              " 0.6837349534034729,\n",
              " 0.6837238073348999,\n",
              " 0.6837124228477478,\n",
              " 0.6837007999420166,\n",
              " 0.6836899518966675,\n",
              " 0.6836785078048706,\n",
              " 0.6836671233177185,\n",
              " 0.683655858039856,\n",
              " 0.683644711971283,\n",
              " 0.6836334466934204,\n",
              " 0.6836221814155579,\n",
              " 0.6836109161376953,\n",
              " 0.6835996508598328,\n",
              " 0.6835880875587463,\n",
              " 0.6835766434669495,\n",
              " 0.6835651993751526,\n",
              " 0.6835538148880005,\n",
              " 0.6835424900054932,\n",
              " 0.6835309863090515,\n",
              " 0.6835194826126099,\n",
              " 0.6835082173347473,\n",
              " 0.6834967732429504,\n",
              " 0.6834854483604431,\n",
              " 0.6834742426872253,\n",
              " 0.6834630966186523,\n",
              " 0.6834517121315002,\n",
              " 0.6834408044815063,\n",
              " 0.6834297776222229,\n",
              " 0.683418333530426,\n",
              " 0.683407187461853,\n",
              " 0.6833959221839905,\n",
              " 0.6833850145339966,\n",
              " 0.6833740472793579,\n",
              " 0.6833627223968506,\n",
              " 0.6833515763282776,\n",
              " 0.6833404302597046,\n",
              " 0.683329701423645,\n",
              " 0.6833184361457825,\n",
              " 0.6833072900772095,\n",
              " 0.683296263217926,\n",
              " 0.6832850575447083,\n",
              " 0.6832737922668457,\n",
              " 0.6832627058029175,\n",
              " 0.6832513213157654,\n",
              " 0.6832404732704163,\n",
              " 0.6832296252250671,\n",
              " 0.6832184791564941,\n",
              " 0.6832075119018555,\n",
              " 0.6831963658332825,\n",
              " 0.6831852197647095,\n",
              " 0.6831742525100708,\n",
              " 0.6831631064414978,\n",
              " 0.6831519603729248,\n",
              " 0.683140754699707,\n",
              " 0.683129608631134,\n",
              " 0.6831187009811401,\n",
              " 0.6831072568893433,\n",
              " 0.6830961108207703,\n",
              " 0.6830853223800659,\n",
              " 0.6830741763114929,\n",
              " 0.6830629706382751,\n",
              " 0.6830518245697021,\n",
              " 0.6830406785011292,\n",
              " 0.6830294132232666,\n",
              " 0.6830182671546936,\n",
              " 0.683007538318634,\n",
              " 0.6829963326454163,\n",
              " 0.6829850673675537,\n",
              " 0.6829741597175598,\n",
              " 0.6829630732536316,\n",
              " 0.6829520463943481,\n",
              " 0.6829410791397095,\n",
              " 0.682930052280426,\n",
              " 0.6829191446304321,\n",
              " 0.6829081773757935,\n",
              " 0.6828972101211548,\n",
              " 0.6828861832618713,\n",
              " 0.6828749775886536,\n",
              " 0.6828638911247253,\n",
              " 0.6828528046607971,\n",
              " 0.6828416585922241,\n",
              " 0.6828306317329407,\n",
              " 0.6828196048736572,\n",
              " 0.6828084588050842,\n",
              " 0.6827969551086426,\n",
              " 0.6827859282493591,\n",
              " 0.6827744245529175,\n",
              " 0.6827635765075684,\n",
              " 0.6827524900436401,\n",
              " 0.6827413439750671,\n",
              " 0.6827306151390076,\n",
              " 0.6827197670936584,\n",
              " 0.6827084422111511]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYeX-wXpFYwf",
        "outputId": "5761a20b-4df0-41ed-91fa-8d737c0d2f52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model1 = Sequential([\n",
        "    Dense(8, input_shape=(10,), activation='relu'),\n",
        "    Dense(5, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model1.summary()\n",
        "model1.compile(optimizer='Adagrad',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "r1=model1.fit(X_train, y_train, epochs=500,validation_data=(X_test,y_test))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_11 (Dense)             (None, 8)                 88        \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 5)                 45        \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 1)                 6         \n",
            "=================================================================\n",
            "Total params: 139\n",
            "Trainable params: 139\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "13/13 [==============================] - 0s 11ms/step - loss: 1.0219 - accuracy: 0.3309 - val_loss: 1.0537 - val_accuracy: 0.2931\n",
            "Epoch 2/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 1.0091 - accuracy: 0.3383 - val_loss: 1.0430 - val_accuracy: 0.2931\n",
            "Epoch 3/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.9998 - accuracy: 0.3457 - val_loss: 1.0342 - val_accuracy: 0.2874\n",
            "Epoch 4/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.9920 - accuracy: 0.3407 - val_loss: 1.0267 - val_accuracy: 0.2931\n",
            "Epoch 5/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.9853 - accuracy: 0.3481 - val_loss: 1.0201 - val_accuracy: 0.2931\n",
            "Epoch 6/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.9792 - accuracy: 0.3481 - val_loss: 1.0142 - val_accuracy: 0.2989\n",
            "Epoch 7/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.9737 - accuracy: 0.3556 - val_loss: 1.0087 - val_accuracy: 0.3103\n",
            "Epoch 8/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.9687 - accuracy: 0.3605 - val_loss: 1.0036 - val_accuracy: 0.3103\n",
            "Epoch 9/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.9641 - accuracy: 0.3605 - val_loss: 0.9989 - val_accuracy: 0.3103\n",
            "Epoch 10/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.9597 - accuracy: 0.3580 - val_loss: 0.9944 - val_accuracy: 0.3103\n",
            "Epoch 11/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.9556 - accuracy: 0.3580 - val_loss: 0.9902 - val_accuracy: 0.3218\n",
            "Epoch 12/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.9517 - accuracy: 0.3580 - val_loss: 0.9862 - val_accuracy: 0.3276\n",
            "Epoch 13/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.9480 - accuracy: 0.3605 - val_loss: 0.9825 - val_accuracy: 0.3333\n",
            "Epoch 14/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.9445 - accuracy: 0.3630 - val_loss: 0.9790 - val_accuracy: 0.3333\n",
            "Epoch 15/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.9412 - accuracy: 0.3654 - val_loss: 0.9755 - val_accuracy: 0.3333\n",
            "Epoch 16/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.9379 - accuracy: 0.3630 - val_loss: 0.9723 - val_accuracy: 0.3333\n",
            "Epoch 17/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.9348 - accuracy: 0.3654 - val_loss: 0.9691 - val_accuracy: 0.3391\n",
            "Epoch 18/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.9317 - accuracy: 0.3630 - val_loss: 0.9660 - val_accuracy: 0.3391\n",
            "Epoch 19/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.9287 - accuracy: 0.3654 - val_loss: 0.9630 - val_accuracy: 0.3391\n",
            "Epoch 20/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.9259 - accuracy: 0.3630 - val_loss: 0.9601 - val_accuracy: 0.3391\n",
            "Epoch 21/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.9232 - accuracy: 0.3630 - val_loss: 0.9574 - val_accuracy: 0.3333\n",
            "Epoch 22/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.9205 - accuracy: 0.3679 - val_loss: 0.9546 - val_accuracy: 0.3333\n",
            "Epoch 23/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.9179 - accuracy: 0.3679 - val_loss: 0.9520 - val_accuracy: 0.3391\n",
            "Epoch 24/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.9154 - accuracy: 0.3704 - val_loss: 0.9494 - val_accuracy: 0.3391\n",
            "Epoch 25/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.9129 - accuracy: 0.3753 - val_loss: 0.9469 - val_accuracy: 0.3391\n",
            "Epoch 26/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.9105 - accuracy: 0.3753 - val_loss: 0.9444 - val_accuracy: 0.3391\n",
            "Epoch 27/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.9081 - accuracy: 0.3728 - val_loss: 0.9421 - val_accuracy: 0.3391\n",
            "Epoch 28/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.9059 - accuracy: 0.3753 - val_loss: 0.9398 - val_accuracy: 0.3391\n",
            "Epoch 29/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.9036 - accuracy: 0.3728 - val_loss: 0.9375 - val_accuracy: 0.3391\n",
            "Epoch 30/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.9014 - accuracy: 0.3753 - val_loss: 0.9353 - val_accuracy: 0.3391\n",
            "Epoch 31/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.8993 - accuracy: 0.3778 - val_loss: 0.9332 - val_accuracy: 0.3391\n",
            "Epoch 32/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8973 - accuracy: 0.3778 - val_loss: 0.9311 - val_accuracy: 0.3391\n",
            "Epoch 33/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8952 - accuracy: 0.3852 - val_loss: 0.9290 - val_accuracy: 0.3391\n",
            "Epoch 34/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.8933 - accuracy: 0.3901 - val_loss: 0.9270 - val_accuracy: 0.3506\n",
            "Epoch 35/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8914 - accuracy: 0.3901 - val_loss: 0.9251 - val_accuracy: 0.3506\n",
            "Epoch 36/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8895 - accuracy: 0.3852 - val_loss: 0.9231 - val_accuracy: 0.3506\n",
            "Epoch 37/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8876 - accuracy: 0.3877 - val_loss: 0.9212 - val_accuracy: 0.3448\n",
            "Epoch 38/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8857 - accuracy: 0.3901 - val_loss: 0.9193 - val_accuracy: 0.3448\n",
            "Epoch 39/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.8839 - accuracy: 0.3926 - val_loss: 0.9174 - val_accuracy: 0.3506\n",
            "Epoch 40/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8821 - accuracy: 0.3926 - val_loss: 0.9156 - val_accuracy: 0.3506\n",
            "Epoch 41/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.8804 - accuracy: 0.3926 - val_loss: 0.9138 - val_accuracy: 0.3506\n",
            "Epoch 42/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8786 - accuracy: 0.3951 - val_loss: 0.9121 - val_accuracy: 0.3563\n",
            "Epoch 43/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8769 - accuracy: 0.4000 - val_loss: 0.9104 - val_accuracy: 0.3563\n",
            "Epoch 44/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8752 - accuracy: 0.4049 - val_loss: 0.9087 - val_accuracy: 0.3621\n",
            "Epoch 45/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.8735 - accuracy: 0.4074 - val_loss: 0.9070 - val_accuracy: 0.3621\n",
            "Epoch 46/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8719 - accuracy: 0.4074 - val_loss: 0.9054 - val_accuracy: 0.3621\n",
            "Epoch 47/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8703 - accuracy: 0.4099 - val_loss: 0.9038 - val_accuracy: 0.3621\n",
            "Epoch 48/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8687 - accuracy: 0.4099 - val_loss: 0.9022 - val_accuracy: 0.3621\n",
            "Epoch 49/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8672 - accuracy: 0.4099 - val_loss: 0.9007 - val_accuracy: 0.3621\n",
            "Epoch 50/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8658 - accuracy: 0.4099 - val_loss: 0.8991 - val_accuracy: 0.3621\n",
            "Epoch 51/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8643 - accuracy: 0.4074 - val_loss: 0.8976 - val_accuracy: 0.3621\n",
            "Epoch 52/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8628 - accuracy: 0.4099 - val_loss: 0.8961 - val_accuracy: 0.3621\n",
            "Epoch 53/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.8614 - accuracy: 0.4099 - val_loss: 0.8946 - val_accuracy: 0.3621\n",
            "Epoch 54/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8600 - accuracy: 0.4099 - val_loss: 0.8932 - val_accuracy: 0.3621\n",
            "Epoch 55/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.8585 - accuracy: 0.4123 - val_loss: 0.8917 - val_accuracy: 0.3621\n",
            "Epoch 56/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8571 - accuracy: 0.4148 - val_loss: 0.8903 - val_accuracy: 0.3678\n",
            "Epoch 57/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8557 - accuracy: 0.4123 - val_loss: 0.8889 - val_accuracy: 0.3678\n",
            "Epoch 58/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8544 - accuracy: 0.4123 - val_loss: 0.8875 - val_accuracy: 0.3678\n",
            "Epoch 59/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.8531 - accuracy: 0.4123 - val_loss: 0.8862 - val_accuracy: 0.3678\n",
            "Epoch 60/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8518 - accuracy: 0.4123 - val_loss: 0.8848 - val_accuracy: 0.3678\n",
            "Epoch 61/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.8505 - accuracy: 0.4123 - val_loss: 0.8835 - val_accuracy: 0.3678\n",
            "Epoch 62/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8492 - accuracy: 0.4148 - val_loss: 0.8822 - val_accuracy: 0.3678\n",
            "Epoch 63/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8480 - accuracy: 0.4173 - val_loss: 0.8809 - val_accuracy: 0.3678\n",
            "Epoch 64/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8468 - accuracy: 0.4198 - val_loss: 0.8796 - val_accuracy: 0.3736\n",
            "Epoch 65/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8455 - accuracy: 0.4198 - val_loss: 0.8783 - val_accuracy: 0.3621\n",
            "Epoch 66/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8443 - accuracy: 0.4198 - val_loss: 0.8771 - val_accuracy: 0.3621\n",
            "Epoch 67/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8432 - accuracy: 0.4247 - val_loss: 0.8759 - val_accuracy: 0.3621\n",
            "Epoch 68/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8420 - accuracy: 0.4247 - val_loss: 0.8746 - val_accuracy: 0.3736\n",
            "Epoch 69/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8408 - accuracy: 0.4272 - val_loss: 0.8734 - val_accuracy: 0.3736\n",
            "Epoch 70/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.8397 - accuracy: 0.4272 - val_loss: 0.8722 - val_accuracy: 0.3678\n",
            "Epoch 71/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.8385 - accuracy: 0.4296 - val_loss: 0.8709 - val_accuracy: 0.3736\n",
            "Epoch 72/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8374 - accuracy: 0.4321 - val_loss: 0.8697 - val_accuracy: 0.3678\n",
            "Epoch 73/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8363 - accuracy: 0.4321 - val_loss: 0.8686 - val_accuracy: 0.3678\n",
            "Epoch 74/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8352 - accuracy: 0.4346 - val_loss: 0.8674 - val_accuracy: 0.3678\n",
            "Epoch 75/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8341 - accuracy: 0.4395 - val_loss: 0.8662 - val_accuracy: 0.3678\n",
            "Epoch 76/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8329 - accuracy: 0.4444 - val_loss: 0.8651 - val_accuracy: 0.3736\n",
            "Epoch 77/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8318 - accuracy: 0.4444 - val_loss: 0.8639 - val_accuracy: 0.3736\n",
            "Epoch 78/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8307 - accuracy: 0.4444 - val_loss: 0.8627 - val_accuracy: 0.3736\n",
            "Epoch 79/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8296 - accuracy: 0.4469 - val_loss: 0.8616 - val_accuracy: 0.3851\n",
            "Epoch 80/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8285 - accuracy: 0.4519 - val_loss: 0.8605 - val_accuracy: 0.3851\n",
            "Epoch 81/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8274 - accuracy: 0.4519 - val_loss: 0.8594 - val_accuracy: 0.3851\n",
            "Epoch 82/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.8263 - accuracy: 0.4519 - val_loss: 0.8583 - val_accuracy: 0.3851\n",
            "Epoch 83/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8253 - accuracy: 0.4543 - val_loss: 0.8573 - val_accuracy: 0.3908\n",
            "Epoch 84/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8243 - accuracy: 0.4593 - val_loss: 0.8562 - val_accuracy: 0.3908\n",
            "Epoch 85/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8233 - accuracy: 0.4593 - val_loss: 0.8551 - val_accuracy: 0.3966\n",
            "Epoch 86/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8222 - accuracy: 0.4593 - val_loss: 0.8541 - val_accuracy: 0.3966\n",
            "Epoch 87/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.8212 - accuracy: 0.4593 - val_loss: 0.8530 - val_accuracy: 0.4023\n",
            "Epoch 88/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8202 - accuracy: 0.4593 - val_loss: 0.8520 - val_accuracy: 0.4023\n",
            "Epoch 89/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8192 - accuracy: 0.4617 - val_loss: 0.8510 - val_accuracy: 0.3966\n",
            "Epoch 90/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8183 - accuracy: 0.4617 - val_loss: 0.8499 - val_accuracy: 0.3966\n",
            "Epoch 91/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.8172 - accuracy: 0.4593 - val_loss: 0.8489 - val_accuracy: 0.3966\n",
            "Epoch 92/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8162 - accuracy: 0.4593 - val_loss: 0.8479 - val_accuracy: 0.3966\n",
            "Epoch 93/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.8153 - accuracy: 0.4568 - val_loss: 0.8469 - val_accuracy: 0.3966\n",
            "Epoch 94/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8143 - accuracy: 0.4593 - val_loss: 0.8459 - val_accuracy: 0.3966\n",
            "Epoch 95/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8134 - accuracy: 0.4568 - val_loss: 0.8450 - val_accuracy: 0.3966\n",
            "Epoch 96/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.8125 - accuracy: 0.4568 - val_loss: 0.8440 - val_accuracy: 0.3966\n",
            "Epoch 97/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8116 - accuracy: 0.4568 - val_loss: 0.8430 - val_accuracy: 0.3966\n",
            "Epoch 98/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8106 - accuracy: 0.4568 - val_loss: 0.8421 - val_accuracy: 0.3966\n",
            "Epoch 99/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8097 - accuracy: 0.4593 - val_loss: 0.8412 - val_accuracy: 0.3966\n",
            "Epoch 100/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8088 - accuracy: 0.4642 - val_loss: 0.8403 - val_accuracy: 0.3966\n",
            "Epoch 101/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8080 - accuracy: 0.4617 - val_loss: 0.8394 - val_accuracy: 0.3966\n",
            "Epoch 102/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8071 - accuracy: 0.4617 - val_loss: 0.8385 - val_accuracy: 0.3966\n",
            "Epoch 103/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8063 - accuracy: 0.4642 - val_loss: 0.8377 - val_accuracy: 0.3966\n",
            "Epoch 104/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8054 - accuracy: 0.4716 - val_loss: 0.8368 - val_accuracy: 0.4023\n",
            "Epoch 105/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8046 - accuracy: 0.4765 - val_loss: 0.8359 - val_accuracy: 0.4080\n",
            "Epoch 106/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8038 - accuracy: 0.4765 - val_loss: 0.8351 - val_accuracy: 0.4080\n",
            "Epoch 107/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.8030 - accuracy: 0.4765 - val_loss: 0.8343 - val_accuracy: 0.4080\n",
            "Epoch 108/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8022 - accuracy: 0.4765 - val_loss: 0.8335 - val_accuracy: 0.4138\n",
            "Epoch 109/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8014 - accuracy: 0.4765 - val_loss: 0.8326 - val_accuracy: 0.4138\n",
            "Epoch 110/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8006 - accuracy: 0.4765 - val_loss: 0.8318 - val_accuracy: 0.4138\n",
            "Epoch 111/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.7998 - accuracy: 0.4790 - val_loss: 0.8310 - val_accuracy: 0.4195\n",
            "Epoch 112/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7991 - accuracy: 0.4815 - val_loss: 0.8302 - val_accuracy: 0.4195\n",
            "Epoch 113/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.7983 - accuracy: 0.4815 - val_loss: 0.8295 - val_accuracy: 0.4195\n",
            "Epoch 114/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7976 - accuracy: 0.4815 - val_loss: 0.8287 - val_accuracy: 0.4138\n",
            "Epoch 115/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7968 - accuracy: 0.4815 - val_loss: 0.8279 - val_accuracy: 0.4138\n",
            "Epoch 116/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7961 - accuracy: 0.4815 - val_loss: 0.8271 - val_accuracy: 0.4138\n",
            "Epoch 117/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7953 - accuracy: 0.4815 - val_loss: 0.8264 - val_accuracy: 0.4138\n",
            "Epoch 118/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7946 - accuracy: 0.4840 - val_loss: 0.8256 - val_accuracy: 0.4138\n",
            "Epoch 119/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7939 - accuracy: 0.4889 - val_loss: 0.8249 - val_accuracy: 0.4138\n",
            "Epoch 120/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7932 - accuracy: 0.4889 - val_loss: 0.8241 - val_accuracy: 0.4138\n",
            "Epoch 121/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7925 - accuracy: 0.4938 - val_loss: 0.8234 - val_accuracy: 0.4195\n",
            "Epoch 122/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7917 - accuracy: 0.4938 - val_loss: 0.8226 - val_accuracy: 0.4195\n",
            "Epoch 123/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7910 - accuracy: 0.4963 - val_loss: 0.8219 - val_accuracy: 0.4195\n",
            "Epoch 124/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7904 - accuracy: 0.4963 - val_loss: 0.8212 - val_accuracy: 0.4138\n",
            "Epoch 125/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7897 - accuracy: 0.4988 - val_loss: 0.8205 - val_accuracy: 0.4138\n",
            "Epoch 126/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7890 - accuracy: 0.4963 - val_loss: 0.8197 - val_accuracy: 0.4080\n",
            "Epoch 127/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7883 - accuracy: 0.5012 - val_loss: 0.8190 - val_accuracy: 0.4080\n",
            "Epoch 128/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7876 - accuracy: 0.4988 - val_loss: 0.8183 - val_accuracy: 0.4195\n",
            "Epoch 129/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7869 - accuracy: 0.4988 - val_loss: 0.8176 - val_accuracy: 0.4195\n",
            "Epoch 130/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7863 - accuracy: 0.4988 - val_loss: 0.8169 - val_accuracy: 0.4253\n",
            "Epoch 131/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7856 - accuracy: 0.4988 - val_loss: 0.8162 - val_accuracy: 0.4253\n",
            "Epoch 132/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7849 - accuracy: 0.4988 - val_loss: 0.8156 - val_accuracy: 0.4253\n",
            "Epoch 133/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7843 - accuracy: 0.4988 - val_loss: 0.8149 - val_accuracy: 0.4253\n",
            "Epoch 134/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7836 - accuracy: 0.4988 - val_loss: 0.8142 - val_accuracy: 0.4253\n",
            "Epoch 135/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7830 - accuracy: 0.5037 - val_loss: 0.8135 - val_accuracy: 0.4253\n",
            "Epoch 136/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7823 - accuracy: 0.5037 - val_loss: 0.8128 - val_accuracy: 0.4253\n",
            "Epoch 137/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7817 - accuracy: 0.5062 - val_loss: 0.8121 - val_accuracy: 0.4253\n",
            "Epoch 138/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7810 - accuracy: 0.5062 - val_loss: 0.8115 - val_accuracy: 0.4253\n",
            "Epoch 139/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7804 - accuracy: 0.5062 - val_loss: 0.8108 - val_accuracy: 0.4253\n",
            "Epoch 140/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7798 - accuracy: 0.5062 - val_loss: 0.8102 - val_accuracy: 0.4253\n",
            "Epoch 141/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7791 - accuracy: 0.5037 - val_loss: 0.8095 - val_accuracy: 0.4253\n",
            "Epoch 142/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7785 - accuracy: 0.5012 - val_loss: 0.8088 - val_accuracy: 0.4253\n",
            "Epoch 143/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7779 - accuracy: 0.5012 - val_loss: 0.8082 - val_accuracy: 0.4310\n",
            "Epoch 144/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7773 - accuracy: 0.5012 - val_loss: 0.8075 - val_accuracy: 0.4368\n",
            "Epoch 145/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7767 - accuracy: 0.5012 - val_loss: 0.8069 - val_accuracy: 0.4425\n",
            "Epoch 146/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7760 - accuracy: 0.5012 - val_loss: 0.8062 - val_accuracy: 0.4425\n",
            "Epoch 147/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7754 - accuracy: 0.5012 - val_loss: 0.8056 - val_accuracy: 0.4425\n",
            "Epoch 148/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7748 - accuracy: 0.4988 - val_loss: 0.8050 - val_accuracy: 0.4483\n",
            "Epoch 149/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7742 - accuracy: 0.4988 - val_loss: 0.8043 - val_accuracy: 0.4540\n",
            "Epoch 150/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7736 - accuracy: 0.4988 - val_loss: 0.8037 - val_accuracy: 0.4540\n",
            "Epoch 151/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7730 - accuracy: 0.4988 - val_loss: 0.8031 - val_accuracy: 0.4540\n",
            "Epoch 152/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7724 - accuracy: 0.4988 - val_loss: 0.8024 - val_accuracy: 0.4540\n",
            "Epoch 153/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7719 - accuracy: 0.4988 - val_loss: 0.8018 - val_accuracy: 0.4540\n",
            "Epoch 154/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7713 - accuracy: 0.4988 - val_loss: 0.8012 - val_accuracy: 0.4540\n",
            "Epoch 155/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7707 - accuracy: 0.5012 - val_loss: 0.8006 - val_accuracy: 0.4540\n",
            "Epoch 156/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.7701 - accuracy: 0.5012 - val_loss: 0.7999 - val_accuracy: 0.4540\n",
            "Epoch 157/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7695 - accuracy: 0.5012 - val_loss: 0.7994 - val_accuracy: 0.4540\n",
            "Epoch 158/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7690 - accuracy: 0.5012 - val_loss: 0.7987 - val_accuracy: 0.4483\n",
            "Epoch 159/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7684 - accuracy: 0.5037 - val_loss: 0.7981 - val_accuracy: 0.4483\n",
            "Epoch 160/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7678 - accuracy: 0.5012 - val_loss: 0.7975 - val_accuracy: 0.4483\n",
            "Epoch 161/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7672 - accuracy: 0.5012 - val_loss: 0.7969 - val_accuracy: 0.4425\n",
            "Epoch 162/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7667 - accuracy: 0.5012 - val_loss: 0.7963 - val_accuracy: 0.4425\n",
            "Epoch 163/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7661 - accuracy: 0.5037 - val_loss: 0.7957 - val_accuracy: 0.4425\n",
            "Epoch 164/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7656 - accuracy: 0.5037 - val_loss: 0.7952 - val_accuracy: 0.4425\n",
            "Epoch 165/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.7650 - accuracy: 0.5037 - val_loss: 0.7946 - val_accuracy: 0.4425\n",
            "Epoch 166/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.7645 - accuracy: 0.5037 - val_loss: 0.7940 - val_accuracy: 0.4425\n",
            "Epoch 167/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7639 - accuracy: 0.5037 - val_loss: 0.7934 - val_accuracy: 0.4483\n",
            "Epoch 168/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7634 - accuracy: 0.5037 - val_loss: 0.7928 - val_accuracy: 0.4483\n",
            "Epoch 169/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7628 - accuracy: 0.5062 - val_loss: 0.7923 - val_accuracy: 0.4483\n",
            "Epoch 170/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.7623 - accuracy: 0.5062 - val_loss: 0.7917 - val_accuracy: 0.4483\n",
            "Epoch 171/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7618 - accuracy: 0.5062 - val_loss: 0.7911 - val_accuracy: 0.4483\n",
            "Epoch 172/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7612 - accuracy: 0.5062 - val_loss: 0.7906 - val_accuracy: 0.4483\n",
            "Epoch 173/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7607 - accuracy: 0.5062 - val_loss: 0.7900 - val_accuracy: 0.4483\n",
            "Epoch 174/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.7602 - accuracy: 0.5062 - val_loss: 0.7895 - val_accuracy: 0.4483\n",
            "Epoch 175/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7597 - accuracy: 0.5086 - val_loss: 0.7889 - val_accuracy: 0.4483\n",
            "Epoch 176/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7591 - accuracy: 0.5062 - val_loss: 0.7884 - val_accuracy: 0.4483\n",
            "Epoch 177/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7586 - accuracy: 0.5086 - val_loss: 0.7878 - val_accuracy: 0.4483\n",
            "Epoch 178/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7581 - accuracy: 0.5086 - val_loss: 0.7873 - val_accuracy: 0.4483\n",
            "Epoch 179/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7576 - accuracy: 0.5086 - val_loss: 0.7867 - val_accuracy: 0.4483\n",
            "Epoch 180/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7571 - accuracy: 0.5086 - val_loss: 0.7862 - val_accuracy: 0.4483\n",
            "Epoch 181/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7566 - accuracy: 0.5086 - val_loss: 0.7857 - val_accuracy: 0.4483\n",
            "Epoch 182/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7561 - accuracy: 0.5086 - val_loss: 0.7851 - val_accuracy: 0.4483\n",
            "Epoch 183/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7556 - accuracy: 0.5086 - val_loss: 0.7846 - val_accuracy: 0.4483\n",
            "Epoch 184/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7551 - accuracy: 0.5086 - val_loss: 0.7841 - val_accuracy: 0.4483\n",
            "Epoch 185/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7546 - accuracy: 0.5086 - val_loss: 0.7836 - val_accuracy: 0.4540\n",
            "Epoch 186/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7541 - accuracy: 0.5086 - val_loss: 0.7831 - val_accuracy: 0.4598\n",
            "Epoch 187/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7536 - accuracy: 0.5086 - val_loss: 0.7825 - val_accuracy: 0.4598\n",
            "Epoch 188/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7531 - accuracy: 0.5086 - val_loss: 0.7820 - val_accuracy: 0.4598\n",
            "Epoch 189/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7527 - accuracy: 0.5062 - val_loss: 0.7815 - val_accuracy: 0.4598\n",
            "Epoch 190/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7522 - accuracy: 0.5062 - val_loss: 0.7810 - val_accuracy: 0.4598\n",
            "Epoch 191/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7517 - accuracy: 0.5062 - val_loss: 0.7805 - val_accuracy: 0.4598\n",
            "Epoch 192/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7512 - accuracy: 0.5086 - val_loss: 0.7800 - val_accuracy: 0.4598\n",
            "Epoch 193/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7507 - accuracy: 0.5062 - val_loss: 0.7795 - val_accuracy: 0.4598\n",
            "Epoch 194/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7503 - accuracy: 0.5062 - val_loss: 0.7790 - val_accuracy: 0.4598\n",
            "Epoch 195/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7498 - accuracy: 0.5086 - val_loss: 0.7785 - val_accuracy: 0.4598\n",
            "Epoch 196/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7493 - accuracy: 0.5111 - val_loss: 0.7780 - val_accuracy: 0.4598\n",
            "Epoch 197/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7488 - accuracy: 0.5111 - val_loss: 0.7775 - val_accuracy: 0.4655\n",
            "Epoch 198/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.7483 - accuracy: 0.5136 - val_loss: 0.7770 - val_accuracy: 0.4655\n",
            "Epoch 199/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7479 - accuracy: 0.5136 - val_loss: 0.7766 - val_accuracy: 0.4540\n",
            "Epoch 200/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7474 - accuracy: 0.5136 - val_loss: 0.7761 - val_accuracy: 0.4540\n",
            "Epoch 201/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7469 - accuracy: 0.5136 - val_loss: 0.7756 - val_accuracy: 0.4540\n",
            "Epoch 202/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7464 - accuracy: 0.5136 - val_loss: 0.7751 - val_accuracy: 0.4540\n",
            "Epoch 203/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7460 - accuracy: 0.5136 - val_loss: 0.7747 - val_accuracy: 0.4540\n",
            "Epoch 204/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7455 - accuracy: 0.5136 - val_loss: 0.7742 - val_accuracy: 0.4598\n",
            "Epoch 205/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7450 - accuracy: 0.5160 - val_loss: 0.7737 - val_accuracy: 0.4598\n",
            "Epoch 206/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7446 - accuracy: 0.5160 - val_loss: 0.7732 - val_accuracy: 0.4598\n",
            "Epoch 207/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7441 - accuracy: 0.5185 - val_loss: 0.7728 - val_accuracy: 0.4598\n",
            "Epoch 208/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7437 - accuracy: 0.5185 - val_loss: 0.7723 - val_accuracy: 0.4598\n",
            "Epoch 209/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7432 - accuracy: 0.5210 - val_loss: 0.7719 - val_accuracy: 0.4598\n",
            "Epoch 210/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7428 - accuracy: 0.5210 - val_loss: 0.7714 - val_accuracy: 0.4598\n",
            "Epoch 211/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.7423 - accuracy: 0.5235 - val_loss: 0.7710 - val_accuracy: 0.4598\n",
            "Epoch 212/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7419 - accuracy: 0.5235 - val_loss: 0.7705 - val_accuracy: 0.4598\n",
            "Epoch 213/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7414 - accuracy: 0.5284 - val_loss: 0.7701 - val_accuracy: 0.4598\n",
            "Epoch 214/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7410 - accuracy: 0.5284 - val_loss: 0.7696 - val_accuracy: 0.4540\n",
            "Epoch 215/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7406 - accuracy: 0.5309 - val_loss: 0.7692 - val_accuracy: 0.4598\n",
            "Epoch 216/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.7401 - accuracy: 0.5309 - val_loss: 0.7687 - val_accuracy: 0.4598\n",
            "Epoch 217/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7397 - accuracy: 0.5309 - val_loss: 0.7683 - val_accuracy: 0.4598\n",
            "Epoch 218/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7392 - accuracy: 0.5309 - val_loss: 0.7678 - val_accuracy: 0.4598\n",
            "Epoch 219/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7388 - accuracy: 0.5284 - val_loss: 0.7674 - val_accuracy: 0.4598\n",
            "Epoch 220/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7384 - accuracy: 0.5284 - val_loss: 0.7670 - val_accuracy: 0.4598\n",
            "Epoch 221/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7379 - accuracy: 0.5284 - val_loss: 0.7665 - val_accuracy: 0.4540\n",
            "Epoch 222/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7375 - accuracy: 0.5284 - val_loss: 0.7661 - val_accuracy: 0.4540\n",
            "Epoch 223/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7370 - accuracy: 0.5259 - val_loss: 0.7657 - val_accuracy: 0.4540\n",
            "Epoch 224/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7366 - accuracy: 0.5309 - val_loss: 0.7652 - val_accuracy: 0.4540\n",
            "Epoch 225/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7362 - accuracy: 0.5309 - val_loss: 0.7648 - val_accuracy: 0.4540\n",
            "Epoch 226/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7357 - accuracy: 0.5333 - val_loss: 0.7644 - val_accuracy: 0.4540\n",
            "Epoch 227/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7353 - accuracy: 0.5333 - val_loss: 0.7640 - val_accuracy: 0.4598\n",
            "Epoch 228/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7349 - accuracy: 0.5333 - val_loss: 0.7636 - val_accuracy: 0.4598\n",
            "Epoch 229/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7345 - accuracy: 0.5333 - val_loss: 0.7631 - val_accuracy: 0.4598\n",
            "Epoch 230/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7340 - accuracy: 0.5358 - val_loss: 0.7627 - val_accuracy: 0.4598\n",
            "Epoch 231/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7336 - accuracy: 0.5358 - val_loss: 0.7623 - val_accuracy: 0.4598\n",
            "Epoch 232/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7332 - accuracy: 0.5383 - val_loss: 0.7619 - val_accuracy: 0.4598\n",
            "Epoch 233/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.7327 - accuracy: 0.5383 - val_loss: 0.7615 - val_accuracy: 0.4598\n",
            "Epoch 234/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7323 - accuracy: 0.5383 - val_loss: 0.7610 - val_accuracy: 0.4598\n",
            "Epoch 235/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7319 - accuracy: 0.5407 - val_loss: 0.7606 - val_accuracy: 0.4598\n",
            "Epoch 236/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7314 - accuracy: 0.5407 - val_loss: 0.7602 - val_accuracy: 0.4598\n",
            "Epoch 237/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7310 - accuracy: 0.5383 - val_loss: 0.7598 - val_accuracy: 0.4598\n",
            "Epoch 238/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7306 - accuracy: 0.5432 - val_loss: 0.7594 - val_accuracy: 0.4598\n",
            "Epoch 239/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7302 - accuracy: 0.5432 - val_loss: 0.7589 - val_accuracy: 0.4598\n",
            "Epoch 240/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7297 - accuracy: 0.5432 - val_loss: 0.7585 - val_accuracy: 0.4598\n",
            "Epoch 241/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7293 - accuracy: 0.5432 - val_loss: 0.7581 - val_accuracy: 0.4598\n",
            "Epoch 242/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7289 - accuracy: 0.5432 - val_loss: 0.7577 - val_accuracy: 0.4598\n",
            "Epoch 243/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.7285 - accuracy: 0.5457 - val_loss: 0.7573 - val_accuracy: 0.4598\n",
            "Epoch 244/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7281 - accuracy: 0.5457 - val_loss: 0.7569 - val_accuracy: 0.4598\n",
            "Epoch 245/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7277 - accuracy: 0.5432 - val_loss: 0.7565 - val_accuracy: 0.4655\n",
            "Epoch 246/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7273 - accuracy: 0.5506 - val_loss: 0.7562 - val_accuracy: 0.4713\n",
            "Epoch 247/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7269 - accuracy: 0.5506 - val_loss: 0.7558 - val_accuracy: 0.4713\n",
            "Epoch 248/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7265 - accuracy: 0.5531 - val_loss: 0.7554 - val_accuracy: 0.4713\n",
            "Epoch 249/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7261 - accuracy: 0.5531 - val_loss: 0.7550 - val_accuracy: 0.4713\n",
            "Epoch 250/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.7257 - accuracy: 0.5531 - val_loss: 0.7546 - val_accuracy: 0.4713\n",
            "Epoch 251/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7253 - accuracy: 0.5506 - val_loss: 0.7542 - val_accuracy: 0.4713\n",
            "Epoch 252/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7249 - accuracy: 0.5506 - val_loss: 0.7538 - val_accuracy: 0.4713\n",
            "Epoch 253/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7245 - accuracy: 0.5531 - val_loss: 0.7534 - val_accuracy: 0.4713\n",
            "Epoch 254/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7241 - accuracy: 0.5556 - val_loss: 0.7530 - val_accuracy: 0.4770\n",
            "Epoch 255/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7237 - accuracy: 0.5506 - val_loss: 0.7527 - val_accuracy: 0.4828\n",
            "Epoch 256/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7233 - accuracy: 0.5506 - val_loss: 0.7523 - val_accuracy: 0.4828\n",
            "Epoch 257/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7230 - accuracy: 0.5506 - val_loss: 0.7519 - val_accuracy: 0.4885\n",
            "Epoch 258/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7226 - accuracy: 0.5531 - val_loss: 0.7515 - val_accuracy: 0.4885\n",
            "Epoch 259/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7222 - accuracy: 0.5531 - val_loss: 0.7511 - val_accuracy: 0.4885\n",
            "Epoch 260/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.7218 - accuracy: 0.5556 - val_loss: 0.7508 - val_accuracy: 0.4885\n",
            "Epoch 261/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7214 - accuracy: 0.5556 - val_loss: 0.7504 - val_accuracy: 0.4885\n",
            "Epoch 262/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7210 - accuracy: 0.5556 - val_loss: 0.7500 - val_accuracy: 0.4885\n",
            "Epoch 263/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.7206 - accuracy: 0.5556 - val_loss: 0.7497 - val_accuracy: 0.4885\n",
            "Epoch 264/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7203 - accuracy: 0.5556 - val_loss: 0.7493 - val_accuracy: 0.4885\n",
            "Epoch 265/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7199 - accuracy: 0.5580 - val_loss: 0.7489 - val_accuracy: 0.4885\n",
            "Epoch 266/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7195 - accuracy: 0.5580 - val_loss: 0.7485 - val_accuracy: 0.4885\n",
            "Epoch 267/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7191 - accuracy: 0.5580 - val_loss: 0.7482 - val_accuracy: 0.4885\n",
            "Epoch 268/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.7188 - accuracy: 0.5580 - val_loss: 0.7478 - val_accuracy: 0.4885\n",
            "Epoch 269/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7184 - accuracy: 0.5580 - val_loss: 0.7475 - val_accuracy: 0.4885\n",
            "Epoch 270/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.7180 - accuracy: 0.5580 - val_loss: 0.7471 - val_accuracy: 0.4885\n",
            "Epoch 271/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.7177 - accuracy: 0.5556 - val_loss: 0.7468 - val_accuracy: 0.4885\n",
            "Epoch 272/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7173 - accuracy: 0.5556 - val_loss: 0.7464 - val_accuracy: 0.4885\n",
            "Epoch 273/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7170 - accuracy: 0.5556 - val_loss: 0.7461 - val_accuracy: 0.4885\n",
            "Epoch 274/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7166 - accuracy: 0.5556 - val_loss: 0.7457 - val_accuracy: 0.4885\n",
            "Epoch 275/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7163 - accuracy: 0.5580 - val_loss: 0.7454 - val_accuracy: 0.4885\n",
            "Epoch 276/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7159 - accuracy: 0.5580 - val_loss: 0.7450 - val_accuracy: 0.4885\n",
            "Epoch 277/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7156 - accuracy: 0.5580 - val_loss: 0.7447 - val_accuracy: 0.4885\n",
            "Epoch 278/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7152 - accuracy: 0.5580 - val_loss: 0.7443 - val_accuracy: 0.4885\n",
            "Epoch 279/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7149 - accuracy: 0.5580 - val_loss: 0.7440 - val_accuracy: 0.4885\n",
            "Epoch 280/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7145 - accuracy: 0.5580 - val_loss: 0.7436 - val_accuracy: 0.4885\n",
            "Epoch 281/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7142 - accuracy: 0.5605 - val_loss: 0.7433 - val_accuracy: 0.4885\n",
            "Epoch 282/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7138 - accuracy: 0.5605 - val_loss: 0.7430 - val_accuracy: 0.4885\n",
            "Epoch 283/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7135 - accuracy: 0.5605 - val_loss: 0.7426 - val_accuracy: 0.4885\n",
            "Epoch 284/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7132 - accuracy: 0.5605 - val_loss: 0.7423 - val_accuracy: 0.5000\n",
            "Epoch 285/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7128 - accuracy: 0.5605 - val_loss: 0.7420 - val_accuracy: 0.5057\n",
            "Epoch 286/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7125 - accuracy: 0.5605 - val_loss: 0.7417 - val_accuracy: 0.5057\n",
            "Epoch 287/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7122 - accuracy: 0.5605 - val_loss: 0.7413 - val_accuracy: 0.5057\n",
            "Epoch 288/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7118 - accuracy: 0.5605 - val_loss: 0.7410 - val_accuracy: 0.5057\n",
            "Epoch 289/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7115 - accuracy: 0.5605 - val_loss: 0.7407 - val_accuracy: 0.5057\n",
            "Epoch 290/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7112 - accuracy: 0.5605 - val_loss: 0.7403 - val_accuracy: 0.5057\n",
            "Epoch 291/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7108 - accuracy: 0.5605 - val_loss: 0.7400 - val_accuracy: 0.5057\n",
            "Epoch 292/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.7105 - accuracy: 0.5605 - val_loss: 0.7397 - val_accuracy: 0.5115\n",
            "Epoch 293/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7102 - accuracy: 0.5605 - val_loss: 0.7394 - val_accuracy: 0.5172\n",
            "Epoch 294/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7099 - accuracy: 0.5630 - val_loss: 0.7390 - val_accuracy: 0.5172\n",
            "Epoch 295/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7095 - accuracy: 0.5654 - val_loss: 0.7387 - val_accuracy: 0.5172\n",
            "Epoch 296/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7092 - accuracy: 0.5654 - val_loss: 0.7384 - val_accuracy: 0.5172\n",
            "Epoch 297/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7089 - accuracy: 0.5654 - val_loss: 0.7381 - val_accuracy: 0.5172\n",
            "Epoch 298/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7085 - accuracy: 0.5654 - val_loss: 0.7378 - val_accuracy: 0.5230\n",
            "Epoch 299/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7082 - accuracy: 0.5704 - val_loss: 0.7374 - val_accuracy: 0.5230\n",
            "Epoch 300/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.7079 - accuracy: 0.5704 - val_loss: 0.7371 - val_accuracy: 0.5230\n",
            "Epoch 301/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7076 - accuracy: 0.5704 - val_loss: 0.7368 - val_accuracy: 0.5230\n",
            "Epoch 302/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.7073 - accuracy: 0.5704 - val_loss: 0.7365 - val_accuracy: 0.5230\n",
            "Epoch 303/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7069 - accuracy: 0.5704 - val_loss: 0.7362 - val_accuracy: 0.5230\n",
            "Epoch 304/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7066 - accuracy: 0.5704 - val_loss: 0.7359 - val_accuracy: 0.5230\n",
            "Epoch 305/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7063 - accuracy: 0.5704 - val_loss: 0.7356 - val_accuracy: 0.5230\n",
            "Epoch 306/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7060 - accuracy: 0.5704 - val_loss: 0.7353 - val_accuracy: 0.5230\n",
            "Epoch 307/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7057 - accuracy: 0.5704 - val_loss: 0.7350 - val_accuracy: 0.5230\n",
            "Epoch 308/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.7054 - accuracy: 0.5704 - val_loss: 0.7347 - val_accuracy: 0.5230\n",
            "Epoch 309/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7051 - accuracy: 0.5704 - val_loss: 0.7344 - val_accuracy: 0.5230\n",
            "Epoch 310/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7048 - accuracy: 0.5704 - val_loss: 0.7341 - val_accuracy: 0.5172\n",
            "Epoch 311/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7044 - accuracy: 0.5704 - val_loss: 0.7338 - val_accuracy: 0.5172\n",
            "Epoch 312/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7041 - accuracy: 0.5704 - val_loss: 0.7335 - val_accuracy: 0.5172\n",
            "Epoch 313/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7038 - accuracy: 0.5704 - val_loss: 0.7332 - val_accuracy: 0.5172\n",
            "Epoch 314/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7035 - accuracy: 0.5704 - val_loss: 0.7329 - val_accuracy: 0.5172\n",
            "Epoch 315/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7032 - accuracy: 0.5704 - val_loss: 0.7326 - val_accuracy: 0.5172\n",
            "Epoch 316/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.7029 - accuracy: 0.5728 - val_loss: 0.7323 - val_accuracy: 0.5230\n",
            "Epoch 317/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7026 - accuracy: 0.5728 - val_loss: 0.7320 - val_accuracy: 0.5230\n",
            "Epoch 318/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7023 - accuracy: 0.5728 - val_loss: 0.7317 - val_accuracy: 0.5230\n",
            "Epoch 319/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7020 - accuracy: 0.5704 - val_loss: 0.7314 - val_accuracy: 0.5230\n",
            "Epoch 320/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7017 - accuracy: 0.5704 - val_loss: 0.7311 - val_accuracy: 0.5230\n",
            "Epoch 321/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7014 - accuracy: 0.5704 - val_loss: 0.7308 - val_accuracy: 0.5230\n",
            "Epoch 322/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7011 - accuracy: 0.5704 - val_loss: 0.7306 - val_accuracy: 0.5230\n",
            "Epoch 323/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7008 - accuracy: 0.5704 - val_loss: 0.7303 - val_accuracy: 0.5230\n",
            "Epoch 324/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.7005 - accuracy: 0.5679 - val_loss: 0.7300 - val_accuracy: 0.5230\n",
            "Epoch 325/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7002 - accuracy: 0.5679 - val_loss: 0.7297 - val_accuracy: 0.5230\n",
            "Epoch 326/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6999 - accuracy: 0.5679 - val_loss: 0.7294 - val_accuracy: 0.5230\n",
            "Epoch 327/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6996 - accuracy: 0.5679 - val_loss: 0.7291 - val_accuracy: 0.5230\n",
            "Epoch 328/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6993 - accuracy: 0.5679 - val_loss: 0.7288 - val_accuracy: 0.5287\n",
            "Epoch 329/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6990 - accuracy: 0.5679 - val_loss: 0.7285 - val_accuracy: 0.5287\n",
            "Epoch 330/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6988 - accuracy: 0.5679 - val_loss: 0.7283 - val_accuracy: 0.5287\n",
            "Epoch 331/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6985 - accuracy: 0.5679 - val_loss: 0.7280 - val_accuracy: 0.5287\n",
            "Epoch 332/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6982 - accuracy: 0.5679 - val_loss: 0.7277 - val_accuracy: 0.5287\n",
            "Epoch 333/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6979 - accuracy: 0.5679 - val_loss: 0.7274 - val_accuracy: 0.5345\n",
            "Epoch 334/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6976 - accuracy: 0.5654 - val_loss: 0.7272 - val_accuracy: 0.5345\n",
            "Epoch 335/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6973 - accuracy: 0.5654 - val_loss: 0.7269 - val_accuracy: 0.5345\n",
            "Epoch 336/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6970 - accuracy: 0.5654 - val_loss: 0.7266 - val_accuracy: 0.5345\n",
            "Epoch 337/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6968 - accuracy: 0.5654 - val_loss: 0.7263 - val_accuracy: 0.5345\n",
            "Epoch 338/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6965 - accuracy: 0.5654 - val_loss: 0.7260 - val_accuracy: 0.5345\n",
            "Epoch 339/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6962 - accuracy: 0.5654 - val_loss: 0.7258 - val_accuracy: 0.5345\n",
            "Epoch 340/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6959 - accuracy: 0.5654 - val_loss: 0.7255 - val_accuracy: 0.5345\n",
            "Epoch 341/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6956 - accuracy: 0.5654 - val_loss: 0.7252 - val_accuracy: 0.5345\n",
            "Epoch 342/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6954 - accuracy: 0.5654 - val_loss: 0.7250 - val_accuracy: 0.5345\n",
            "Epoch 343/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6951 - accuracy: 0.5654 - val_loss: 0.7247 - val_accuracy: 0.5345\n",
            "Epoch 344/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6948 - accuracy: 0.5654 - val_loss: 0.7244 - val_accuracy: 0.5345\n",
            "Epoch 345/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6946 - accuracy: 0.5654 - val_loss: 0.7242 - val_accuracy: 0.5345\n",
            "Epoch 346/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6943 - accuracy: 0.5654 - val_loss: 0.7239 - val_accuracy: 0.5345\n",
            "Epoch 347/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6940 - accuracy: 0.5654 - val_loss: 0.7236 - val_accuracy: 0.5345\n",
            "Epoch 348/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6938 - accuracy: 0.5654 - val_loss: 0.7234 - val_accuracy: 0.5345\n",
            "Epoch 349/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.5679 - val_loss: 0.7231 - val_accuracy: 0.5345\n",
            "Epoch 350/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.5654 - val_loss: 0.7229 - val_accuracy: 0.5345\n",
            "Epoch 351/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6929 - accuracy: 0.5654 - val_loss: 0.7226 - val_accuracy: 0.5345\n",
            "Epoch 352/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5654 - val_loss: 0.7223 - val_accuracy: 0.5345\n",
            "Epoch 353/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6924 - accuracy: 0.5630 - val_loss: 0.7221 - val_accuracy: 0.5345\n",
            "Epoch 354/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6921 - accuracy: 0.5654 - val_loss: 0.7218 - val_accuracy: 0.5345\n",
            "Epoch 355/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6919 - accuracy: 0.5654 - val_loss: 0.7216 - val_accuracy: 0.5287\n",
            "Epoch 356/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6916 - accuracy: 0.5654 - val_loss: 0.7213 - val_accuracy: 0.5287\n",
            "Epoch 357/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6914 - accuracy: 0.5654 - val_loss: 0.7211 - val_accuracy: 0.5287\n",
            "Epoch 358/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6911 - accuracy: 0.5654 - val_loss: 0.7208 - val_accuracy: 0.5287\n",
            "Epoch 359/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6908 - accuracy: 0.5654 - val_loss: 0.7205 - val_accuracy: 0.5230\n",
            "Epoch 360/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6906 - accuracy: 0.5654 - val_loss: 0.7203 - val_accuracy: 0.5230\n",
            "Epoch 361/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6903 - accuracy: 0.5654 - val_loss: 0.7200 - val_accuracy: 0.5230\n",
            "Epoch 362/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6901 - accuracy: 0.5654 - val_loss: 0.7198 - val_accuracy: 0.5230\n",
            "Epoch 363/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6898 - accuracy: 0.5654 - val_loss: 0.7195 - val_accuracy: 0.5230\n",
            "Epoch 364/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6895 - accuracy: 0.5679 - val_loss: 0.7193 - val_accuracy: 0.5230\n",
            "Epoch 365/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6893 - accuracy: 0.5679 - val_loss: 0.7190 - val_accuracy: 0.5230\n",
            "Epoch 366/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6890 - accuracy: 0.5704 - val_loss: 0.7188 - val_accuracy: 0.5230\n",
            "Epoch 367/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6888 - accuracy: 0.5704 - val_loss: 0.7185 - val_accuracy: 0.5230\n",
            "Epoch 368/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6885 - accuracy: 0.5704 - val_loss: 0.7183 - val_accuracy: 0.5230\n",
            "Epoch 369/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6883 - accuracy: 0.5704 - val_loss: 0.7180 - val_accuracy: 0.5230\n",
            "Epoch 370/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6880 - accuracy: 0.5704 - val_loss: 0.7178 - val_accuracy: 0.5230\n",
            "Epoch 371/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6878 - accuracy: 0.5704 - val_loss: 0.7175 - val_accuracy: 0.5230\n",
            "Epoch 372/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6875 - accuracy: 0.5704 - val_loss: 0.7172 - val_accuracy: 0.5230\n",
            "Epoch 373/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6873 - accuracy: 0.5704 - val_loss: 0.7170 - val_accuracy: 0.5230\n",
            "Epoch 374/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6870 - accuracy: 0.5728 - val_loss: 0.7167 - val_accuracy: 0.5230\n",
            "Epoch 375/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6867 - accuracy: 0.5728 - val_loss: 0.7165 - val_accuracy: 0.5230\n",
            "Epoch 376/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6865 - accuracy: 0.5753 - val_loss: 0.7163 - val_accuracy: 0.5230\n",
            "Epoch 377/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6863 - accuracy: 0.5778 - val_loss: 0.7160 - val_accuracy: 0.5230\n",
            "Epoch 378/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6860 - accuracy: 0.5778 - val_loss: 0.7158 - val_accuracy: 0.5230\n",
            "Epoch 379/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6858 - accuracy: 0.5778 - val_loss: 0.7155 - val_accuracy: 0.5230\n",
            "Epoch 380/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6855 - accuracy: 0.5778 - val_loss: 0.7153 - val_accuracy: 0.5230\n",
            "Epoch 381/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6853 - accuracy: 0.5778 - val_loss: 0.7150 - val_accuracy: 0.5230\n",
            "Epoch 382/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6850 - accuracy: 0.5802 - val_loss: 0.7148 - val_accuracy: 0.5230\n",
            "Epoch 383/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6848 - accuracy: 0.5827 - val_loss: 0.7145 - val_accuracy: 0.5230\n",
            "Epoch 384/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6845 - accuracy: 0.5827 - val_loss: 0.7143 - val_accuracy: 0.5230\n",
            "Epoch 385/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6843 - accuracy: 0.5827 - val_loss: 0.7140 - val_accuracy: 0.5230\n",
            "Epoch 386/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6840 - accuracy: 0.5827 - val_loss: 0.7138 - val_accuracy: 0.5230\n",
            "Epoch 387/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6838 - accuracy: 0.5827 - val_loss: 0.7135 - val_accuracy: 0.5230\n",
            "Epoch 388/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6836 - accuracy: 0.5852 - val_loss: 0.7133 - val_accuracy: 0.5230\n",
            "Epoch 389/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6833 - accuracy: 0.5852 - val_loss: 0.7130 - val_accuracy: 0.5230\n",
            "Epoch 390/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6831 - accuracy: 0.5852 - val_loss: 0.7127 - val_accuracy: 0.5230\n",
            "Epoch 391/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6828 - accuracy: 0.5852 - val_loss: 0.7125 - val_accuracy: 0.5230\n",
            "Epoch 392/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6826 - accuracy: 0.5852 - val_loss: 0.7123 - val_accuracy: 0.5230\n",
            "Epoch 393/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6823 - accuracy: 0.5852 - val_loss: 0.7120 - val_accuracy: 0.5230\n",
            "Epoch 394/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6821 - accuracy: 0.5877 - val_loss: 0.7118 - val_accuracy: 0.5230\n",
            "Epoch 395/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6819 - accuracy: 0.5877 - val_loss: 0.7115 - val_accuracy: 0.5230\n",
            "Epoch 396/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6816 - accuracy: 0.5877 - val_loss: 0.7113 - val_accuracy: 0.5230\n",
            "Epoch 397/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6814 - accuracy: 0.5877 - val_loss: 0.7110 - val_accuracy: 0.5230\n",
            "Epoch 398/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6811 - accuracy: 0.5877 - val_loss: 0.7108 - val_accuracy: 0.5230\n",
            "Epoch 399/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6809 - accuracy: 0.5877 - val_loss: 0.7105 - val_accuracy: 0.5287\n",
            "Epoch 400/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6807 - accuracy: 0.5852 - val_loss: 0.7103 - val_accuracy: 0.5287\n",
            "Epoch 401/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6804 - accuracy: 0.5852 - val_loss: 0.7101 - val_accuracy: 0.5287\n",
            "Epoch 402/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6802 - accuracy: 0.5852 - val_loss: 0.7098 - val_accuracy: 0.5287\n",
            "Epoch 403/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6799 - accuracy: 0.5852 - val_loss: 0.7096 - val_accuracy: 0.5287\n",
            "Epoch 404/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6797 - accuracy: 0.5852 - val_loss: 0.7093 - val_accuracy: 0.5287\n",
            "Epoch 405/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6795 - accuracy: 0.5852 - val_loss: 0.7091 - val_accuracy: 0.5287\n",
            "Epoch 406/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6792 - accuracy: 0.5852 - val_loss: 0.7088 - val_accuracy: 0.5287\n",
            "Epoch 407/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6790 - accuracy: 0.5827 - val_loss: 0.7086 - val_accuracy: 0.5287\n",
            "Epoch 408/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6788 - accuracy: 0.5802 - val_loss: 0.7084 - val_accuracy: 0.5287\n",
            "Epoch 409/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6785 - accuracy: 0.5778 - val_loss: 0.7081 - val_accuracy: 0.5287\n",
            "Epoch 410/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6783 - accuracy: 0.5778 - val_loss: 0.7079 - val_accuracy: 0.5287\n",
            "Epoch 411/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6781 - accuracy: 0.5778 - val_loss: 0.7077 - val_accuracy: 0.5287\n",
            "Epoch 412/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6779 - accuracy: 0.5778 - val_loss: 0.7074 - val_accuracy: 0.5287\n",
            "Epoch 413/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6776 - accuracy: 0.5778 - val_loss: 0.7072 - val_accuracy: 0.5287\n",
            "Epoch 414/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6774 - accuracy: 0.5802 - val_loss: 0.7070 - val_accuracy: 0.5287\n",
            "Epoch 415/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6772 - accuracy: 0.5802 - val_loss: 0.7067 - val_accuracy: 0.5287\n",
            "Epoch 416/500\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.6770 - accuracy: 0.5802 - val_loss: 0.7065 - val_accuracy: 0.5287\n",
            "Epoch 417/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6767 - accuracy: 0.5827 - val_loss: 0.7063 - val_accuracy: 0.5345\n",
            "Epoch 418/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6765 - accuracy: 0.5827 - val_loss: 0.7060 - val_accuracy: 0.5345\n",
            "Epoch 419/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6763 - accuracy: 0.5827 - val_loss: 0.7058 - val_accuracy: 0.5345\n",
            "Epoch 420/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6761 - accuracy: 0.5852 - val_loss: 0.7056 - val_accuracy: 0.5345\n",
            "Epoch 421/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6758 - accuracy: 0.5852 - val_loss: 0.7053 - val_accuracy: 0.5287\n",
            "Epoch 422/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6756 - accuracy: 0.5852 - val_loss: 0.7051 - val_accuracy: 0.5287\n",
            "Epoch 423/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6754 - accuracy: 0.5852 - val_loss: 0.7049 - val_accuracy: 0.5287\n",
            "Epoch 424/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6752 - accuracy: 0.5852 - val_loss: 0.7046 - val_accuracy: 0.5287\n",
            "Epoch 425/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6749 - accuracy: 0.5877 - val_loss: 0.7044 - val_accuracy: 0.5345\n",
            "Epoch 426/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6747 - accuracy: 0.5877 - val_loss: 0.7042 - val_accuracy: 0.5345\n",
            "Epoch 427/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6745 - accuracy: 0.5877 - val_loss: 0.7040 - val_accuracy: 0.5345\n",
            "Epoch 428/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6743 - accuracy: 0.5901 - val_loss: 0.7037 - val_accuracy: 0.5345\n",
            "Epoch 429/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6741 - accuracy: 0.5926 - val_loss: 0.7035 - val_accuracy: 0.5345\n",
            "Epoch 430/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6738 - accuracy: 0.5926 - val_loss: 0.7033 - val_accuracy: 0.5345\n",
            "Epoch 431/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6736 - accuracy: 0.5926 - val_loss: 0.7031 - val_accuracy: 0.5345\n",
            "Epoch 432/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6734 - accuracy: 0.5926 - val_loss: 0.7028 - val_accuracy: 0.5345\n",
            "Epoch 433/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6732 - accuracy: 0.5951 - val_loss: 0.7026 - val_accuracy: 0.5345\n",
            "Epoch 434/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6730 - accuracy: 0.5951 - val_loss: 0.7024 - val_accuracy: 0.5345\n",
            "Epoch 435/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6728 - accuracy: 0.5951 - val_loss: 0.7022 - val_accuracy: 0.5402\n",
            "Epoch 436/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6726 - accuracy: 0.5951 - val_loss: 0.7019 - val_accuracy: 0.5402\n",
            "Epoch 437/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6724 - accuracy: 0.5975 - val_loss: 0.7017 - val_accuracy: 0.5402\n",
            "Epoch 438/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6721 - accuracy: 0.5975 - val_loss: 0.7015 - val_accuracy: 0.5402\n",
            "Epoch 439/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6719 - accuracy: 0.5975 - val_loss: 0.7013 - val_accuracy: 0.5402\n",
            "Epoch 440/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6717 - accuracy: 0.5975 - val_loss: 0.7010 - val_accuracy: 0.5402\n",
            "Epoch 441/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6715 - accuracy: 0.5975 - val_loss: 0.7008 - val_accuracy: 0.5402\n",
            "Epoch 442/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6713 - accuracy: 0.5975 - val_loss: 0.7006 - val_accuracy: 0.5402\n",
            "Epoch 443/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6711 - accuracy: 0.6000 - val_loss: 0.7004 - val_accuracy: 0.5402\n",
            "Epoch 444/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6709 - accuracy: 0.6000 - val_loss: 0.7002 - val_accuracy: 0.5402\n",
            "Epoch 445/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6707 - accuracy: 0.6000 - val_loss: 0.6999 - val_accuracy: 0.5402\n",
            "Epoch 446/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6705 - accuracy: 0.6000 - val_loss: 0.6997 - val_accuracy: 0.5402\n",
            "Epoch 447/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6703 - accuracy: 0.6025 - val_loss: 0.6995 - val_accuracy: 0.5402\n",
            "Epoch 448/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6701 - accuracy: 0.6025 - val_loss: 0.6993 - val_accuracy: 0.5402\n",
            "Epoch 449/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6699 - accuracy: 0.6025 - val_loss: 0.6991 - val_accuracy: 0.5402\n",
            "Epoch 450/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6697 - accuracy: 0.6025 - val_loss: 0.6989 - val_accuracy: 0.5402\n",
            "Epoch 451/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6695 - accuracy: 0.6000 - val_loss: 0.6986 - val_accuracy: 0.5402\n",
            "Epoch 452/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6693 - accuracy: 0.6000 - val_loss: 0.6984 - val_accuracy: 0.5402\n",
            "Epoch 453/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6690 - accuracy: 0.6000 - val_loss: 0.6982 - val_accuracy: 0.5402\n",
            "Epoch 454/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6688 - accuracy: 0.6000 - val_loss: 0.6980 - val_accuracy: 0.5402\n",
            "Epoch 455/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6686 - accuracy: 0.6000 - val_loss: 0.6978 - val_accuracy: 0.5402\n",
            "Epoch 456/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6684 - accuracy: 0.6000 - val_loss: 0.6976 - val_accuracy: 0.5402\n",
            "Epoch 457/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6682 - accuracy: 0.6025 - val_loss: 0.6974 - val_accuracy: 0.5402\n",
            "Epoch 458/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6680 - accuracy: 0.6025 - val_loss: 0.6971 - val_accuracy: 0.5402\n",
            "Epoch 459/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6678 - accuracy: 0.6025 - val_loss: 0.6969 - val_accuracy: 0.5402\n",
            "Epoch 460/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6676 - accuracy: 0.6025 - val_loss: 0.6967 - val_accuracy: 0.5402\n",
            "Epoch 461/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6674 - accuracy: 0.6025 - val_loss: 0.6965 - val_accuracy: 0.5402\n",
            "Epoch 462/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6672 - accuracy: 0.6025 - val_loss: 0.6963 - val_accuracy: 0.5402\n",
            "Epoch 463/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6670 - accuracy: 0.6025 - val_loss: 0.6961 - val_accuracy: 0.5402\n",
            "Epoch 464/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6668 - accuracy: 0.6025 - val_loss: 0.6959 - val_accuracy: 0.5402\n",
            "Epoch 465/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6666 - accuracy: 0.6025 - val_loss: 0.6956 - val_accuracy: 0.5402\n",
            "Epoch 466/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6664 - accuracy: 0.6025 - val_loss: 0.6954 - val_accuracy: 0.5402\n",
            "Epoch 467/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6662 - accuracy: 0.6025 - val_loss: 0.6952 - val_accuracy: 0.5402\n",
            "Epoch 468/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6660 - accuracy: 0.6025 - val_loss: 0.6950 - val_accuracy: 0.5402\n",
            "Epoch 469/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6658 - accuracy: 0.6025 - val_loss: 0.6948 - val_accuracy: 0.5402\n",
            "Epoch 470/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6656 - accuracy: 0.6049 - val_loss: 0.6946 - val_accuracy: 0.5402\n",
            "Epoch 471/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6654 - accuracy: 0.6049 - val_loss: 0.6944 - val_accuracy: 0.5402\n",
            "Epoch 472/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6652 - accuracy: 0.6049 - val_loss: 0.6942 - val_accuracy: 0.5402\n",
            "Epoch 473/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6650 - accuracy: 0.6049 - val_loss: 0.6940 - val_accuracy: 0.5402\n",
            "Epoch 474/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6648 - accuracy: 0.6049 - val_loss: 0.6938 - val_accuracy: 0.5402\n",
            "Epoch 475/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6646 - accuracy: 0.6049 - val_loss: 0.6936 - val_accuracy: 0.5402\n",
            "Epoch 476/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6644 - accuracy: 0.6049 - val_loss: 0.6934 - val_accuracy: 0.5402\n",
            "Epoch 477/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6642 - accuracy: 0.6049 - val_loss: 0.6932 - val_accuracy: 0.5402\n",
            "Epoch 478/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6640 - accuracy: 0.6049 - val_loss: 0.6930 - val_accuracy: 0.5402\n",
            "Epoch 479/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6638 - accuracy: 0.6074 - val_loss: 0.6928 - val_accuracy: 0.5460\n",
            "Epoch 480/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6636 - accuracy: 0.6074 - val_loss: 0.6925 - val_accuracy: 0.5460\n",
            "Epoch 481/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6634 - accuracy: 0.6074 - val_loss: 0.6923 - val_accuracy: 0.5460\n",
            "Epoch 482/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6633 - accuracy: 0.6074 - val_loss: 0.6921 - val_accuracy: 0.5460\n",
            "Epoch 483/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6631 - accuracy: 0.6074 - val_loss: 0.6919 - val_accuracy: 0.5460\n",
            "Epoch 484/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6629 - accuracy: 0.6074 - val_loss: 0.6917 - val_accuracy: 0.5460\n",
            "Epoch 485/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6627 - accuracy: 0.6074 - val_loss: 0.6916 - val_accuracy: 0.5460\n",
            "Epoch 486/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6625 - accuracy: 0.6074 - val_loss: 0.6914 - val_accuracy: 0.5460\n",
            "Epoch 487/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6623 - accuracy: 0.6074 - val_loss: 0.6912 - val_accuracy: 0.5460\n",
            "Epoch 488/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6621 - accuracy: 0.6074 - val_loss: 0.6910 - val_accuracy: 0.5460\n",
            "Epoch 489/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6619 - accuracy: 0.6074 - val_loss: 0.6908 - val_accuracy: 0.5460\n",
            "Epoch 490/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6617 - accuracy: 0.6074 - val_loss: 0.6906 - val_accuracy: 0.5460\n",
            "Epoch 491/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6615 - accuracy: 0.6074 - val_loss: 0.6904 - val_accuracy: 0.5460\n",
            "Epoch 492/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6613 - accuracy: 0.6074 - val_loss: 0.6902 - val_accuracy: 0.5460\n",
            "Epoch 493/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6611 - accuracy: 0.6074 - val_loss: 0.6900 - val_accuracy: 0.5460\n",
            "Epoch 494/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6610 - accuracy: 0.6099 - val_loss: 0.6898 - val_accuracy: 0.5460\n",
            "Epoch 495/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6608 - accuracy: 0.6099 - val_loss: 0.6896 - val_accuracy: 0.5402\n",
            "Epoch 496/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6606 - accuracy: 0.6099 - val_loss: 0.6894 - val_accuracy: 0.5402\n",
            "Epoch 497/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6604 - accuracy: 0.6099 - val_loss: 0.6892 - val_accuracy: 0.5402\n",
            "Epoch 498/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6602 - accuracy: 0.6099 - val_loss: 0.6890 - val_accuracy: 0.5402\n",
            "Epoch 499/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6600 - accuracy: 0.6099 - val_loss: 0.6888 - val_accuracy: 0.5402\n",
            "Epoch 500/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6598 - accuracy: 0.6099 - val_loss: 0.6886 - val_accuracy: 0.5402\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ch-g02FcF-hi",
        "outputId": "1583532b-9ba0-4e7b-c844-55344140a083",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "r1.history['loss']"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0219088792800903,\n",
              " 1.0090638399124146,\n",
              " 0.9998471736907959,\n",
              " 0.9919780492782593,\n",
              " 0.9852553606033325,\n",
              " 0.9791911840438843,\n",
              " 0.9737368226051331,\n",
              " 0.9687354564666748,\n",
              " 0.9640779495239258,\n",
              " 0.9597268104553223,\n",
              " 0.955597460269928,\n",
              " 0.9517224431037903,\n",
              " 0.9479592442512512,\n",
              " 0.9444898962974548,\n",
              " 0.9411635398864746,\n",
              " 0.9378938674926758,\n",
              " 0.9347620606422424,\n",
              " 0.9317145943641663,\n",
              " 0.9287408590316772,\n",
              " 0.9258702397346497,\n",
              " 0.923150360584259,\n",
              " 0.9205153584480286,\n",
              " 0.917919933795929,\n",
              " 0.9153596758842468,\n",
              " 0.9129055738449097,\n",
              " 0.9104911088943481,\n",
              " 0.908149003982544,\n",
              " 0.9058539271354675,\n",
              " 0.9036480188369751,\n",
              " 0.9014266133308411,\n",
              " 0.8993245959281921,\n",
              " 0.8972846269607544,\n",
              " 0.895247220993042,\n",
              " 0.8932920098304749,\n",
              " 0.8913725018501282,\n",
              " 0.8894838690757751,\n",
              " 0.8876040577888489,\n",
              " 0.8857340216636658,\n",
              " 0.8839150667190552,\n",
              " 0.8821452856063843,\n",
              " 0.8803808093070984,\n",
              " 0.8786327838897705,\n",
              " 0.8769205212593079,\n",
              " 0.8751928210258484,\n",
              " 0.8735251426696777,\n",
              " 0.8719165921211243,\n",
              " 0.870333731174469,\n",
              " 0.8687469959259033,\n",
              " 0.8672430515289307,\n",
              " 0.8657634854316711,\n",
              " 0.8642904162406921,\n",
              " 0.8628148436546326,\n",
              " 0.8613647222518921,\n",
              " 0.8599609136581421,\n",
              " 0.8585167527198792,\n",
              " 0.857148289680481,\n",
              " 0.855748176574707,\n",
              " 0.8544086813926697,\n",
              " 0.8530798554420471,\n",
              " 0.851767897605896,\n",
              " 0.850487470626831,\n",
              " 0.8492211103439331,\n",
              " 0.8479899764060974,\n",
              " 0.8467694520950317,\n",
              " 0.8455371856689453,\n",
              " 0.8443445563316345,\n",
              " 0.8431630730628967,\n",
              " 0.8420061469078064,\n",
              " 0.8408310413360596,\n",
              " 0.8396742343902588,\n",
              " 0.8385311961174011,\n",
              " 0.8373935222625732,\n",
              " 0.8362709879875183,\n",
              " 0.8351616859436035,\n",
              " 0.8340681791305542,\n",
              " 0.8329028487205505,\n",
              " 0.8317968249320984,\n",
              " 0.830658495426178,\n",
              " 0.8295596837997437,\n",
              " 0.8284804821014404,\n",
              " 0.827402651309967,\n",
              " 0.8263455629348755,\n",
              " 0.8252993822097778,\n",
              " 0.8242859840393066,\n",
              " 0.8232704401016235,\n",
              " 0.8222102522850037,\n",
              " 0.8212080001831055,\n",
              " 0.8202112317085266,\n",
              " 0.8192217946052551,\n",
              " 0.8182542324066162,\n",
              " 0.8172397017478943,\n",
              " 0.8162497282028198,\n",
              " 0.8152845501899719,\n",
              " 0.8143436908721924,\n",
              " 0.8133981823921204,\n",
              " 0.8124832510948181,\n",
              " 0.8115598559379578,\n",
              " 0.8106104731559753,\n",
              " 0.8097161054611206,\n",
              " 0.8088250160217285,\n",
              " 0.8079720139503479,\n",
              " 0.8071007132530212,\n",
              " 0.8062651753425598,\n",
              " 0.8054285645484924,\n",
              " 0.8045947551727295,\n",
              " 0.8037735819816589,\n",
              " 0.8029542565345764,\n",
              " 0.802180290222168,\n",
              " 0.8013827800750732,\n",
              " 0.8006064295768738,\n",
              " 0.7998417615890503,\n",
              " 0.7990646362304688,\n",
              " 0.7983155250549316,\n",
              " 0.7975643873214722,\n",
              " 0.7968145608901978,\n",
              " 0.7960760593414307,\n",
              " 0.7953287959098816,\n",
              " 0.7945947647094727,\n",
              " 0.7938786745071411,\n",
              " 0.7931615710258484,\n",
              " 0.7924619913101196,\n",
              " 0.7917460799217224,\n",
              " 0.791035532951355,\n",
              " 0.7903516292572021,\n",
              " 0.7896562814712524,\n",
              " 0.7889655232429504,\n",
              " 0.7882748246192932,\n",
              " 0.7876090407371521,\n",
              " 0.7869331240653992,\n",
              " 0.7862612009048462,\n",
              " 0.7856028079986572,\n",
              " 0.7849416732788086,\n",
              " 0.7842873930931091,\n",
              " 0.7836223244667053,\n",
              " 0.7829607129096985,\n",
              " 0.7823199033737183,\n",
              " 0.7816817760467529,\n",
              " 0.7810327410697937,\n",
              " 0.7804007530212402,\n",
              " 0.7797721028327942,\n",
              " 0.7791440486907959,\n",
              " 0.7785265445709229,\n",
              " 0.7779060006141663,\n",
              " 0.7772881984710693,\n",
              " 0.7766741514205933,\n",
              " 0.7760490775108337,\n",
              " 0.7754420042037964,\n",
              " 0.7748333215713501,\n",
              " 0.7742366790771484,\n",
              " 0.7736297249794006,\n",
              " 0.7730351090431213,\n",
              " 0.7724407315254211,\n",
              " 0.771854043006897,\n",
              " 0.7712541818618774,\n",
              " 0.7706774473190308,\n",
              " 0.7700812220573425,\n",
              " 0.769512414932251,\n",
              " 0.7689528465270996,\n",
              " 0.7683805227279663,\n",
              " 0.7678102850914001,\n",
              " 0.7672467827796936,\n",
              " 0.7666857838630676,\n",
              " 0.7661327123641968,\n",
              " 0.76556396484375,\n",
              " 0.7650090456008911,\n",
              " 0.7644598484039307,\n",
              " 0.7639119625091553,\n",
              " 0.7633639574050903,\n",
              " 0.7628171443939209,\n",
              " 0.7622865438461304,\n",
              " 0.7617689967155457,\n",
              " 0.7612276077270508,\n",
              " 0.7606984376907349,\n",
              " 0.7601785659790039,\n",
              " 0.759661853313446,\n",
              " 0.7591392993927002,\n",
              " 0.7586262226104736,\n",
              " 0.758110523223877,\n",
              " 0.7575947046279907,\n",
              " 0.7570896744728088,\n",
              " 0.7565917372703552,\n",
              " 0.7560952305793762,\n",
              " 0.7555994391441345,\n",
              " 0.7551013827323914,\n",
              " 0.7546107769012451,\n",
              " 0.7541186809539795,\n",
              " 0.7536278367042542,\n",
              " 0.7531421184539795,\n",
              " 0.7526618838310242,\n",
              " 0.7521795630455017,\n",
              " 0.751690685749054,\n",
              " 0.7512075901031494,\n",
              " 0.7507261037826538,\n",
              " 0.7502549886703491,\n",
              " 0.7497689723968506,\n",
              " 0.7492864727973938,\n",
              " 0.7488048672676086,\n",
              " 0.7483255863189697,\n",
              " 0.7478520274162292,\n",
              " 0.7473774552345276,\n",
              " 0.7469133734703064,\n",
              " 0.7464445233345032,\n",
              " 0.7459721565246582,\n",
              " 0.7455088496208191,\n",
              " 0.7450488209724426,\n",
              " 0.7445897459983826,\n",
              " 0.7441202998161316,\n",
              " 0.7436652183532715,\n",
              " 0.7432159185409546,\n",
              " 0.742770254611969,\n",
              " 0.7423220872879028,\n",
              " 0.7418743371963501,\n",
              " 0.7414407730102539,\n",
              " 0.7410135269165039,\n",
              " 0.7405667304992676,\n",
              " 0.7401333451271057,\n",
              " 0.7396915555000305,\n",
              " 0.7392241954803467,\n",
              " 0.7387900948524475,\n",
              " 0.7383500337600708,\n",
              " 0.7379083037376404,\n",
              " 0.737472653388977,\n",
              " 0.7370383143424988,\n",
              " 0.7365988492965698,\n",
              " 0.7361645102500916,\n",
              " 0.7357259392738342,\n",
              " 0.7353058457374573,\n",
              " 0.7348798513412476,\n",
              " 0.7344556450843811,\n",
              " 0.7340182065963745,\n",
              " 0.7335878014564514,\n",
              " 0.7331621050834656,\n",
              " 0.7327305674552917,\n",
              " 0.7323026657104492,\n",
              " 0.7318597435951233,\n",
              " 0.7314369678497314,\n",
              " 0.7310118079185486,\n",
              " 0.7305914759635925,\n",
              " 0.7301669716835022,\n",
              " 0.7297475337982178,\n",
              " 0.729331374168396,\n",
              " 0.7289299368858337,\n",
              " 0.7285230755805969,\n",
              " 0.7281205654144287,\n",
              " 0.7277110815048218,\n",
              " 0.7273086309432983,\n",
              " 0.7269095778465271,\n",
              " 0.7265121936798096,\n",
              " 0.7261050939559937,\n",
              " 0.7257052063941956,\n",
              " 0.7253130674362183,\n",
              " 0.7249224781990051,\n",
              " 0.7245275378227234,\n",
              " 0.7241288423538208,\n",
              " 0.723734974861145,\n",
              " 0.7233486771583557,\n",
              " 0.7229560613632202,\n",
              " 0.7225684523582458,\n",
              " 0.722176194190979,\n",
              " 0.721790611743927,\n",
              " 0.7214070558547974,\n",
              " 0.7210245728492737,\n",
              " 0.7206482887268066,\n",
              " 0.7202666997909546,\n",
              " 0.7198857069015503,\n",
              " 0.719505786895752,\n",
              " 0.7191380858421326,\n",
              " 0.7187771201133728,\n",
              " 0.7184126377105713,\n",
              " 0.7180492281913757,\n",
              " 0.7176876664161682,\n",
              " 0.717334508895874,\n",
              " 0.7169776558876038,\n",
              " 0.7166177034378052,\n",
              " 0.7162543535232544,\n",
              " 0.7159083485603333,\n",
              " 0.7155579328536987,\n",
              " 0.7152150273323059,\n",
              " 0.714869499206543,\n",
              " 0.714518129825592,\n",
              " 0.7141740918159485,\n",
              " 0.7138344645500183,\n",
              " 0.7135025858879089,\n",
              " 0.7131621837615967,\n",
              " 0.7128289937973022,\n",
              " 0.712494432926178,\n",
              " 0.7121667265892029,\n",
              " 0.7118313312530518,\n",
              " 0.7114914059638977,\n",
              " 0.711159884929657,\n",
              " 0.7108327746391296,\n",
              " 0.7105029225349426,\n",
              " 0.7101776599884033,\n",
              " 0.7098524570465088,\n",
              " 0.7095156908035278,\n",
              " 0.7091894149780273,\n",
              " 0.7088643312454224,\n",
              " 0.7085394859313965,\n",
              " 0.7082164883613586,\n",
              " 0.7078953385353088,\n",
              " 0.7075739502906799,\n",
              " 0.7072539329528809,\n",
              " 0.7069373726844788,\n",
              " 0.7066267132759094,\n",
              " 0.7063105702400208,\n",
              " 0.7059972882270813,\n",
              " 0.7056856751441956,\n",
              " 0.7053722739219666,\n",
              " 0.705059289932251,\n",
              " 0.7047542333602905,\n",
              " 0.7044482827186584,\n",
              " 0.7041410207748413,\n",
              " 0.7038372159004211,\n",
              " 0.7035341858863831,\n",
              " 0.7032307982444763,\n",
              " 0.7029286623001099,\n",
              " 0.7026224136352539,\n",
              " 0.7023177742958069,\n",
              " 0.7020158171653748,\n",
              " 0.7017089128494263,\n",
              " 0.7014052271842957,\n",
              " 0.7011046409606934,\n",
              " 0.7008094787597656,\n",
              " 0.7005172371864319,\n",
              " 0.7002083659172058,\n",
              " 0.6999210119247437,\n",
              " 0.6996286511421204,\n",
              " 0.6993422508239746,\n",
              " 0.6990393996238708,\n",
              " 0.6987500786781311,\n",
              " 0.6984654068946838,\n",
              " 0.6981827616691589,\n",
              " 0.6978997588157654,\n",
              " 0.6976169943809509,\n",
              " 0.6973316073417664,\n",
              " 0.6970343589782715,\n",
              " 0.6967542767524719,\n",
              " 0.69647616147995,\n",
              " 0.6961943507194519,\n",
              " 0.6959212422370911,\n",
              " 0.6956456899642944,\n",
              " 0.6953710317611694,\n",
              " 0.6950958371162415,\n",
              " 0.6948181390762329,\n",
              " 0.694550096988678,\n",
              " 0.6942823529243469,\n",
              " 0.6940192580223083,\n",
              " 0.6937509179115295,\n",
              " 0.6934819221496582,\n",
              " 0.6932128667831421,\n",
              " 0.6929447650909424,\n",
              " 0.6926774978637695,\n",
              " 0.6924124360084534,\n",
              " 0.6921491622924805,\n",
              " 0.6918851733207703,\n",
              " 0.6916243433952332,\n",
              " 0.6913632750511169,\n",
              " 0.6910998821258545,\n",
              " 0.6908372640609741,\n",
              " 0.690578043460846,\n",
              " 0.690318763256073,\n",
              " 0.6900639533996582,\n",
              " 0.6898031830787659,\n",
              " 0.6895410418510437,\n",
              " 0.6892834901809692,\n",
              " 0.6890252828598022,\n",
              " 0.6887725591659546,\n",
              " 0.6885148286819458,\n",
              " 0.6882661581039429,\n",
              " 0.6880130767822266,\n",
              " 0.6877573132514954,\n",
              " 0.6875026226043701,\n",
              " 0.6872501969337463,\n",
              " 0.6869950890541077,\n",
              " 0.6867499947547913,\n",
              " 0.6865056753158569,\n",
              " 0.6862602829933167,\n",
              " 0.6860142946243286,\n",
              " 0.6857753396034241,\n",
              " 0.6855272650718689,\n",
              " 0.6852795481681824,\n",
              " 0.6850293278694153,\n",
              " 0.684779167175293,\n",
              " 0.6845308542251587,\n",
              " 0.6842871904373169,\n",
              " 0.6840471625328064,\n",
              " 0.6838081479072571,\n",
              " 0.6835634112358093,\n",
              " 0.6833153963088989,\n",
              " 0.6830591559410095,\n",
              " 0.6828148365020752,\n",
              " 0.6825752258300781,\n",
              " 0.6823302507400513,\n",
              " 0.6820880174636841,\n",
              " 0.6818527579307556,\n",
              " 0.6816086173057556,\n",
              " 0.6813741326332092,\n",
              " 0.6811366081237793,\n",
              " 0.6808979511260986,\n",
              " 0.6806612014770508,\n",
              " 0.6804213523864746,\n",
              " 0.6801831722259521,\n",
              " 0.6799479722976685,\n",
              " 0.6797075271606445,\n",
              " 0.6794769167900085,\n",
              " 0.6792396306991577,\n",
              " 0.6789992451667786,\n",
              " 0.6787699460983276,\n",
              " 0.6785414814949036,\n",
              " 0.6783038377761841,\n",
              " 0.6780753135681152,\n",
              " 0.6778512001037598,\n",
              " 0.67762690782547,\n",
              " 0.677405059337616,\n",
              " 0.677182674407959,\n",
              " 0.6769626140594482,\n",
              " 0.6767401099205017,\n",
              " 0.6765098571777344,\n",
              " 0.6762888431549072,\n",
              " 0.6760667562484741,\n",
              " 0.6758478879928589,\n",
              " 0.6756197214126587,\n",
              " 0.675391674041748,\n",
              " 0.6751689314842224,\n",
              " 0.674946665763855,\n",
              " 0.6747205853462219,\n",
              " 0.6744976043701172,\n",
              " 0.674278974533081,\n",
              " 0.674064040184021,\n",
              " 0.6738438606262207,\n",
              " 0.6736333966255188,\n",
              " 0.6734176278114319,\n",
              " 0.6732032299041748,\n",
              " 0.6729876399040222,\n",
              " 0.6727763414382935,\n",
              " 0.6725645661354065,\n",
              " 0.6723536252975464,\n",
              " 0.6721435785293579,\n",
              " 0.6719334125518799,\n",
              " 0.6717212200164795,\n",
              " 0.671511709690094,\n",
              " 0.671302080154419,\n",
              " 0.6710980534553528,\n",
              " 0.6708869934082031,\n",
              " 0.6706827878952026,\n",
              " 0.6704779863357544,\n",
              " 0.6702709794044495,\n",
              " 0.6700684428215027,\n",
              " 0.6698646545410156,\n",
              " 0.6696597337722778,\n",
              " 0.6694563031196594,\n",
              " 0.6692507266998291,\n",
              " 0.6690446734428406,\n",
              " 0.6688408255577087,\n",
              " 0.6686392426490784,\n",
              " 0.6684351563453674,\n",
              " 0.6682320237159729,\n",
              " 0.6680337190628052,\n",
              " 0.6678319573402405,\n",
              " 0.6676194667816162,\n",
              " 0.6674135327339172,\n",
              " 0.6672125458717346,\n",
              " 0.6670116782188416,\n",
              " 0.6668082475662231,\n",
              " 0.6666103601455688,\n",
              " 0.6664091348648071,\n",
              " 0.6662116050720215,\n",
              " 0.6660116314888,\n",
              " 0.6658113598823547,\n",
              " 0.6656129956245422,\n",
              " 0.6654175519943237,\n",
              " 0.6652209758758545,\n",
              " 0.6650213003158569,\n",
              " 0.6648262143135071,\n",
              " 0.6646284461021423,\n",
              " 0.6644318699836731,\n",
              " 0.6642282009124756,\n",
              " 0.6640354990959167,\n",
              " 0.6638381481170654,\n",
              " 0.6636427640914917,\n",
              " 0.6634460687637329,\n",
              " 0.663250744342804,\n",
              " 0.6630603671073914,\n",
              " 0.6628700494766235,\n",
              " 0.6626738905906677,\n",
              " 0.6624847650527954,\n",
              " 0.6622878313064575,\n",
              " 0.6620994210243225,\n",
              " 0.6619092226028442,\n",
              " 0.661716639995575,\n",
              " 0.6615275740623474,\n",
              " 0.6613318920135498,\n",
              " 0.6611441373825073,\n",
              " 0.6609551310539246,\n",
              " 0.6607668399810791,\n",
              " 0.6605801582336426,\n",
              " 0.6603901386260986,\n",
              " 0.6601970195770264,\n",
              " 0.6600077152252197,\n",
              " 0.6598153114318848]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9mudApSGKf0",
        "outputId": "0a6f9f90-14bb-4339-a053-a33581b5f60f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model2 = Sequential([\n",
        "    Dense(8, input_shape=(10,), activation='relu'),\n",
        "    Dense(5, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model2.summary()\n",
        "model2.compile(optimizer='RMSprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "r2=model2.fit(X_train, y_train, epochs=500,validation_data=(X_test,y_test))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_14 (Dense)             (None, 8)                 88        \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 5)                 45        \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 1)                 6         \n",
            "=================================================================\n",
            "Total params: 139\n",
            "Trainable params: 139\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "13/13 [==============================] - 0s 11ms/step - loss: 0.7006 - accuracy: 0.5284 - val_loss: 0.6780 - val_accuracy: 0.5632\n",
            "Epoch 2/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6801 - accuracy: 0.6049 - val_loss: 0.6591 - val_accuracy: 0.6092\n",
            "Epoch 3/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6638 - accuracy: 0.6198 - val_loss: 0.6428 - val_accuracy: 0.6897\n",
            "Epoch 4/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6501 - accuracy: 0.6494 - val_loss: 0.6298 - val_accuracy: 0.6954\n",
            "Epoch 5/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6380 - accuracy: 0.6716 - val_loss: 0.6165 - val_accuracy: 0.7069\n",
            "Epoch 6/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6263 - accuracy: 0.6889 - val_loss: 0.6049 - val_accuracy: 0.7184\n",
            "Epoch 7/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6152 - accuracy: 0.7086 - val_loss: 0.5939 - val_accuracy: 0.7184\n",
            "Epoch 8/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6046 - accuracy: 0.7210 - val_loss: 0.5824 - val_accuracy: 0.7126\n",
            "Epoch 9/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5943 - accuracy: 0.7235 - val_loss: 0.5727 - val_accuracy: 0.7126\n",
            "Epoch 10/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5850 - accuracy: 0.7111 - val_loss: 0.5647 - val_accuracy: 0.7126\n",
            "Epoch 11/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5764 - accuracy: 0.7086 - val_loss: 0.5573 - val_accuracy: 0.7069\n",
            "Epoch 12/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5688 - accuracy: 0.7037 - val_loss: 0.5503 - val_accuracy: 0.7069\n",
            "Epoch 13/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5612 - accuracy: 0.7136 - val_loss: 0.5446 - val_accuracy: 0.7069\n",
            "Epoch 14/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5544 - accuracy: 0.7111 - val_loss: 0.5398 - val_accuracy: 0.7069\n",
            "Epoch 15/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5483 - accuracy: 0.7111 - val_loss: 0.5347 - val_accuracy: 0.7069\n",
            "Epoch 16/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5428 - accuracy: 0.7111 - val_loss: 0.5302 - val_accuracy: 0.7126\n",
            "Epoch 17/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5376 - accuracy: 0.7111 - val_loss: 0.5258 - val_accuracy: 0.7126\n",
            "Epoch 18/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5331 - accuracy: 0.7136 - val_loss: 0.5227 - val_accuracy: 0.7126\n",
            "Epoch 19/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5295 - accuracy: 0.7136 - val_loss: 0.5200 - val_accuracy: 0.7126\n",
            "Epoch 20/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5259 - accuracy: 0.7185 - val_loss: 0.5175 - val_accuracy: 0.7126\n",
            "Epoch 21/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5234 - accuracy: 0.7111 - val_loss: 0.5155 - val_accuracy: 0.7241\n",
            "Epoch 22/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5203 - accuracy: 0.7160 - val_loss: 0.5134 - val_accuracy: 0.7241\n",
            "Epoch 23/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5180 - accuracy: 0.7160 - val_loss: 0.5117 - val_accuracy: 0.7241\n",
            "Epoch 24/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5159 - accuracy: 0.7185 - val_loss: 0.5104 - val_accuracy: 0.7299\n",
            "Epoch 25/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5137 - accuracy: 0.7210 - val_loss: 0.5090 - val_accuracy: 0.7414\n",
            "Epoch 26/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5122 - accuracy: 0.7185 - val_loss: 0.5078 - val_accuracy: 0.7241\n",
            "Epoch 27/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5104 - accuracy: 0.7160 - val_loss: 0.5068 - val_accuracy: 0.7356\n",
            "Epoch 28/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5091 - accuracy: 0.7210 - val_loss: 0.5059 - val_accuracy: 0.7299\n",
            "Epoch 29/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5078 - accuracy: 0.7210 - val_loss: 0.5052 - val_accuracy: 0.7299\n",
            "Epoch 30/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5068 - accuracy: 0.7185 - val_loss: 0.5047 - val_accuracy: 0.7299\n",
            "Epoch 31/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5056 - accuracy: 0.7160 - val_loss: 0.5040 - val_accuracy: 0.7356\n",
            "Epoch 32/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7160 - val_loss: 0.5036 - val_accuracy: 0.7414\n",
            "Epoch 33/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5035 - accuracy: 0.7160 - val_loss: 0.5031 - val_accuracy: 0.7414\n",
            "Epoch 34/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5025 - accuracy: 0.7185 - val_loss: 0.5028 - val_accuracy: 0.7414\n",
            "Epoch 35/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5014 - accuracy: 0.7160 - val_loss: 0.5024 - val_accuracy: 0.7414\n",
            "Epoch 36/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5007 - accuracy: 0.7136 - val_loss: 0.5021 - val_accuracy: 0.7414\n",
            "Epoch 37/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5000 - accuracy: 0.7185 - val_loss: 0.5017 - val_accuracy: 0.7414\n",
            "Epoch 38/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4991 - accuracy: 0.7160 - val_loss: 0.5015 - val_accuracy: 0.7414\n",
            "Epoch 39/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4985 - accuracy: 0.7185 - val_loss: 0.5012 - val_accuracy: 0.7414\n",
            "Epoch 40/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4978 - accuracy: 0.7235 - val_loss: 0.5009 - val_accuracy: 0.7414\n",
            "Epoch 41/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4971 - accuracy: 0.7259 - val_loss: 0.5008 - val_accuracy: 0.7414\n",
            "Epoch 42/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4963 - accuracy: 0.7210 - val_loss: 0.5005 - val_accuracy: 0.7414\n",
            "Epoch 43/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4958 - accuracy: 0.7284 - val_loss: 0.5003 - val_accuracy: 0.7414\n",
            "Epoch 44/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4948 - accuracy: 0.7309 - val_loss: 0.5002 - val_accuracy: 0.7414\n",
            "Epoch 45/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4940 - accuracy: 0.7284 - val_loss: 0.5000 - val_accuracy: 0.7414\n",
            "Epoch 46/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4937 - accuracy: 0.7309 - val_loss: 0.4999 - val_accuracy: 0.7414\n",
            "Epoch 47/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4929 - accuracy: 0.7259 - val_loss: 0.4995 - val_accuracy: 0.7414\n",
            "Epoch 48/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4923 - accuracy: 0.7235 - val_loss: 0.4991 - val_accuracy: 0.7414\n",
            "Epoch 49/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4921 - accuracy: 0.7259 - val_loss: 0.4991 - val_accuracy: 0.7414\n",
            "Epoch 50/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4913 - accuracy: 0.7284 - val_loss: 0.4989 - val_accuracy: 0.7414\n",
            "Epoch 51/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4908 - accuracy: 0.7309 - val_loss: 0.4986 - val_accuracy: 0.7414\n",
            "Epoch 52/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4903 - accuracy: 0.7309 - val_loss: 0.4987 - val_accuracy: 0.7414\n",
            "Epoch 53/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4899 - accuracy: 0.7309 - val_loss: 0.4986 - val_accuracy: 0.7414\n",
            "Epoch 54/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4893 - accuracy: 0.7309 - val_loss: 0.4984 - val_accuracy: 0.7414\n",
            "Epoch 55/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4889 - accuracy: 0.7309 - val_loss: 0.4981 - val_accuracy: 0.7414\n",
            "Epoch 56/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4886 - accuracy: 0.7309 - val_loss: 0.4979 - val_accuracy: 0.7414\n",
            "Epoch 57/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4882 - accuracy: 0.7309 - val_loss: 0.4982 - val_accuracy: 0.7356\n",
            "Epoch 58/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4877 - accuracy: 0.7284 - val_loss: 0.4982 - val_accuracy: 0.7356\n",
            "Epoch 59/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4873 - accuracy: 0.7309 - val_loss: 0.4981 - val_accuracy: 0.7356\n",
            "Epoch 60/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4868 - accuracy: 0.7309 - val_loss: 0.4982 - val_accuracy: 0.7356\n",
            "Epoch 61/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4864 - accuracy: 0.7333 - val_loss: 0.4983 - val_accuracy: 0.7299\n",
            "Epoch 62/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4859 - accuracy: 0.7383 - val_loss: 0.4983 - val_accuracy: 0.7299\n",
            "Epoch 63/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4853 - accuracy: 0.7358 - val_loss: 0.4983 - val_accuracy: 0.7241\n",
            "Epoch 64/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4850 - accuracy: 0.7383 - val_loss: 0.4983 - val_accuracy: 0.7241\n",
            "Epoch 65/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4847 - accuracy: 0.7383 - val_loss: 0.4982 - val_accuracy: 0.7241\n",
            "Epoch 66/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.7383 - val_loss: 0.4983 - val_accuracy: 0.7299\n",
            "Epoch 67/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4837 - accuracy: 0.7333 - val_loss: 0.4982 - val_accuracy: 0.7241\n",
            "Epoch 68/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4832 - accuracy: 0.7358 - val_loss: 0.4982 - val_accuracy: 0.7241\n",
            "Epoch 69/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4826 - accuracy: 0.7383 - val_loss: 0.4982 - val_accuracy: 0.7241\n",
            "Epoch 70/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4825 - accuracy: 0.7432 - val_loss: 0.4986 - val_accuracy: 0.7184\n",
            "Epoch 71/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4819 - accuracy: 0.7358 - val_loss: 0.4982 - val_accuracy: 0.7184\n",
            "Epoch 72/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4816 - accuracy: 0.7383 - val_loss: 0.4981 - val_accuracy: 0.7184\n",
            "Epoch 73/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4809 - accuracy: 0.7383 - val_loss: 0.4984 - val_accuracy: 0.7184\n",
            "Epoch 74/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4804 - accuracy: 0.7383 - val_loss: 0.4984 - val_accuracy: 0.7241\n",
            "Epoch 75/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4801 - accuracy: 0.7457 - val_loss: 0.4985 - val_accuracy: 0.7241\n",
            "Epoch 76/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4795 - accuracy: 0.7358 - val_loss: 0.4985 - val_accuracy: 0.7184\n",
            "Epoch 77/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4790 - accuracy: 0.7407 - val_loss: 0.4985 - val_accuracy: 0.7184\n",
            "Epoch 78/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4788 - accuracy: 0.7358 - val_loss: 0.4981 - val_accuracy: 0.7184\n",
            "Epoch 79/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4781 - accuracy: 0.7457 - val_loss: 0.4983 - val_accuracy: 0.7241\n",
            "Epoch 80/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4778 - accuracy: 0.7383 - val_loss: 0.4983 - val_accuracy: 0.7184\n",
            "Epoch 81/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4774 - accuracy: 0.7481 - val_loss: 0.4987 - val_accuracy: 0.7126\n",
            "Epoch 82/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4770 - accuracy: 0.7481 - val_loss: 0.4987 - val_accuracy: 0.7126\n",
            "Epoch 83/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4765 - accuracy: 0.7481 - val_loss: 0.4987 - val_accuracy: 0.7126\n",
            "Epoch 84/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4760 - accuracy: 0.7432 - val_loss: 0.4982 - val_accuracy: 0.7184\n",
            "Epoch 85/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4758 - accuracy: 0.7481 - val_loss: 0.4984 - val_accuracy: 0.7126\n",
            "Epoch 86/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4756 - accuracy: 0.7457 - val_loss: 0.4984 - val_accuracy: 0.7184\n",
            "Epoch 87/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4750 - accuracy: 0.7457 - val_loss: 0.4989 - val_accuracy: 0.7069\n",
            "Epoch 88/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4747 - accuracy: 0.7457 - val_loss: 0.4989 - val_accuracy: 0.7126\n",
            "Epoch 89/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4742 - accuracy: 0.7432 - val_loss: 0.4990 - val_accuracy: 0.7069\n",
            "Epoch 90/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4738 - accuracy: 0.7432 - val_loss: 0.4988 - val_accuracy: 0.7069\n",
            "Epoch 91/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4736 - accuracy: 0.7457 - val_loss: 0.4989 - val_accuracy: 0.7069\n",
            "Epoch 92/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4734 - accuracy: 0.7481 - val_loss: 0.4995 - val_accuracy: 0.7069\n",
            "Epoch 93/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4727 - accuracy: 0.7432 - val_loss: 0.4994 - val_accuracy: 0.7069\n",
            "Epoch 94/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4724 - accuracy: 0.7457 - val_loss: 0.4994 - val_accuracy: 0.7069\n",
            "Epoch 95/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4724 - accuracy: 0.7457 - val_loss: 0.4994 - val_accuracy: 0.7069\n",
            "Epoch 96/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4724 - accuracy: 0.7432 - val_loss: 0.4994 - val_accuracy: 0.7069\n",
            "Epoch 97/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4716 - accuracy: 0.7457 - val_loss: 0.4997 - val_accuracy: 0.7069\n",
            "Epoch 98/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4713 - accuracy: 0.7481 - val_loss: 0.4996 - val_accuracy: 0.7069\n",
            "Epoch 99/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4711 - accuracy: 0.7506 - val_loss: 0.4994 - val_accuracy: 0.7069\n",
            "Epoch 100/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4708 - accuracy: 0.7506 - val_loss: 0.4995 - val_accuracy: 0.7069\n",
            "Epoch 101/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4706 - accuracy: 0.7457 - val_loss: 0.5000 - val_accuracy: 0.7069\n",
            "Epoch 102/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4702 - accuracy: 0.7432 - val_loss: 0.5006 - val_accuracy: 0.7069\n",
            "Epoch 103/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4697 - accuracy: 0.7457 - val_loss: 0.5001 - val_accuracy: 0.7069\n",
            "Epoch 104/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4699 - accuracy: 0.7457 - val_loss: 0.5001 - val_accuracy: 0.7069\n",
            "Epoch 105/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4693 - accuracy: 0.7481 - val_loss: 0.5002 - val_accuracy: 0.7069\n",
            "Epoch 106/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4691 - accuracy: 0.7506 - val_loss: 0.5005 - val_accuracy: 0.7126\n",
            "Epoch 107/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4688 - accuracy: 0.7481 - val_loss: 0.5002 - val_accuracy: 0.7069\n",
            "Epoch 108/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4686 - accuracy: 0.7506 - val_loss: 0.5002 - val_accuracy: 0.7069\n",
            "Epoch 109/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4684 - accuracy: 0.7481 - val_loss: 0.5001 - val_accuracy: 0.7069\n",
            "Epoch 110/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4680 - accuracy: 0.7506 - val_loss: 0.5006 - val_accuracy: 0.7069\n",
            "Epoch 111/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4677 - accuracy: 0.7556 - val_loss: 0.5008 - val_accuracy: 0.7069\n",
            "Epoch 112/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7506 - val_loss: 0.5007 - val_accuracy: 0.7126\n",
            "Epoch 113/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7506 - val_loss: 0.5006 - val_accuracy: 0.7126\n",
            "Epoch 114/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4674 - accuracy: 0.7506 - val_loss: 0.5008 - val_accuracy: 0.7126\n",
            "Epoch 115/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4666 - accuracy: 0.7531 - val_loss: 0.5005 - val_accuracy: 0.7126\n",
            "Epoch 116/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4666 - accuracy: 0.7580 - val_loss: 0.5005 - val_accuracy: 0.7126\n",
            "Epoch 117/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4664 - accuracy: 0.7580 - val_loss: 0.5003 - val_accuracy: 0.7126\n",
            "Epoch 118/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4661 - accuracy: 0.7605 - val_loss: 0.5008 - val_accuracy: 0.7126\n",
            "Epoch 119/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4656 - accuracy: 0.7556 - val_loss: 0.5012 - val_accuracy: 0.7126\n",
            "Epoch 120/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4661 - accuracy: 0.7556 - val_loss: 0.5010 - val_accuracy: 0.7184\n",
            "Epoch 121/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4653 - accuracy: 0.7556 - val_loss: 0.5008 - val_accuracy: 0.7126\n",
            "Epoch 122/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4652 - accuracy: 0.7605 - val_loss: 0.5012 - val_accuracy: 0.7184\n",
            "Epoch 123/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4650 - accuracy: 0.7630 - val_loss: 0.5015 - val_accuracy: 0.7184\n",
            "Epoch 124/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4647 - accuracy: 0.7506 - val_loss: 0.5013 - val_accuracy: 0.7184\n",
            "Epoch 125/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4645 - accuracy: 0.7654 - val_loss: 0.5013 - val_accuracy: 0.7184\n",
            "Epoch 126/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4639 - accuracy: 0.7630 - val_loss: 0.5016 - val_accuracy: 0.7184\n",
            "Epoch 127/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4639 - accuracy: 0.7580 - val_loss: 0.5013 - val_accuracy: 0.7184\n",
            "Epoch 128/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.7605 - val_loss: 0.5011 - val_accuracy: 0.7184\n",
            "Epoch 129/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4631 - accuracy: 0.7605 - val_loss: 0.5009 - val_accuracy: 0.7184\n",
            "Epoch 130/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.7630 - val_loss: 0.5011 - val_accuracy: 0.7184\n",
            "Epoch 131/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.7679 - val_loss: 0.5012 - val_accuracy: 0.7184\n",
            "Epoch 132/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4621 - accuracy: 0.7654 - val_loss: 0.5013 - val_accuracy: 0.7184\n",
            "Epoch 133/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4623 - accuracy: 0.7556 - val_loss: 0.5012 - val_accuracy: 0.7184\n",
            "Epoch 134/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.7605 - val_loss: 0.5008 - val_accuracy: 0.7241\n",
            "Epoch 135/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.7654 - val_loss: 0.5016 - val_accuracy: 0.7241\n",
            "Epoch 136/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4609 - accuracy: 0.7605 - val_loss: 0.5015 - val_accuracy: 0.7241\n",
            "Epoch 137/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7630 - val_loss: 0.5014 - val_accuracy: 0.7241\n",
            "Epoch 138/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4605 - accuracy: 0.7630 - val_loss: 0.5011 - val_accuracy: 0.7241\n",
            "Epoch 139/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.7630 - val_loss: 0.5008 - val_accuracy: 0.7241\n",
            "Epoch 140/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.7654 - val_loss: 0.5015 - val_accuracy: 0.7241\n",
            "Epoch 141/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7679 - val_loss: 0.5015 - val_accuracy: 0.7241\n",
            "Epoch 142/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7679 - val_loss: 0.5019 - val_accuracy: 0.7069\n",
            "Epoch 143/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.7605 - val_loss: 0.5014 - val_accuracy: 0.7241\n",
            "Epoch 144/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.7630 - val_loss: 0.5013 - val_accuracy: 0.7241\n",
            "Epoch 145/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7654 - val_loss: 0.5013 - val_accuracy: 0.7241\n",
            "Epoch 146/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4583 - accuracy: 0.7580 - val_loss: 0.5011 - val_accuracy: 0.7184\n",
            "Epoch 147/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4582 - accuracy: 0.7679 - val_loss: 0.5017 - val_accuracy: 0.7069\n",
            "Epoch 148/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.7630 - val_loss: 0.5026 - val_accuracy: 0.7011\n",
            "Epoch 149/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7605 - val_loss: 0.5011 - val_accuracy: 0.7184\n",
            "Epoch 150/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4574 - accuracy: 0.7704 - val_loss: 0.5023 - val_accuracy: 0.7011\n",
            "Epoch 151/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4577 - accuracy: 0.7580 - val_loss: 0.5022 - val_accuracy: 0.7011\n",
            "Epoch 152/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4572 - accuracy: 0.7605 - val_loss: 0.5021 - val_accuracy: 0.7011\n",
            "Epoch 153/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4568 - accuracy: 0.7654 - val_loss: 0.5029 - val_accuracy: 0.7011\n",
            "Epoch 154/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4564 - accuracy: 0.7605 - val_loss: 0.5030 - val_accuracy: 0.7011\n",
            "Epoch 155/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4567 - accuracy: 0.7556 - val_loss: 0.5030 - val_accuracy: 0.7011\n",
            "Epoch 156/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4563 - accuracy: 0.7580 - val_loss: 0.5023 - val_accuracy: 0.6954\n",
            "Epoch 157/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4561 - accuracy: 0.7654 - val_loss: 0.5034 - val_accuracy: 0.7011\n",
            "Epoch 158/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4559 - accuracy: 0.7605 - val_loss: 0.5029 - val_accuracy: 0.7011\n",
            "Epoch 159/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4555 - accuracy: 0.7654 - val_loss: 0.5026 - val_accuracy: 0.7011\n",
            "Epoch 160/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4553 - accuracy: 0.7630 - val_loss: 0.5034 - val_accuracy: 0.7011\n",
            "Epoch 161/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4555 - accuracy: 0.7630 - val_loss: 0.5040 - val_accuracy: 0.7011\n",
            "Epoch 162/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4554 - accuracy: 0.7605 - val_loss: 0.5038 - val_accuracy: 0.7011\n",
            "Epoch 163/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4549 - accuracy: 0.7630 - val_loss: 0.5050 - val_accuracy: 0.7011\n",
            "Epoch 164/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4547 - accuracy: 0.7605 - val_loss: 0.5049 - val_accuracy: 0.7011\n",
            "Epoch 165/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4545 - accuracy: 0.7556 - val_loss: 0.5047 - val_accuracy: 0.7011\n",
            "Epoch 166/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4545 - accuracy: 0.7580 - val_loss: 0.5041 - val_accuracy: 0.7011\n",
            "Epoch 167/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4541 - accuracy: 0.7605 - val_loss: 0.5051 - val_accuracy: 0.7011\n",
            "Epoch 168/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4542 - accuracy: 0.7605 - val_loss: 0.5055 - val_accuracy: 0.7011\n",
            "Epoch 169/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4540 - accuracy: 0.7580 - val_loss: 0.5057 - val_accuracy: 0.7011\n",
            "Epoch 170/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4541 - accuracy: 0.7556 - val_loss: 0.5057 - val_accuracy: 0.7011\n",
            "Epoch 171/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4532 - accuracy: 0.7605 - val_loss: 0.5055 - val_accuracy: 0.7011\n",
            "Epoch 172/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4534 - accuracy: 0.7605 - val_loss: 0.5052 - val_accuracy: 0.7011\n",
            "Epoch 173/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4532 - accuracy: 0.7580 - val_loss: 0.5049 - val_accuracy: 0.7011\n",
            "Epoch 174/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4530 - accuracy: 0.7605 - val_loss: 0.5058 - val_accuracy: 0.7011\n",
            "Epoch 175/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4528 - accuracy: 0.7630 - val_loss: 0.5056 - val_accuracy: 0.7011\n",
            "Epoch 176/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4525 - accuracy: 0.7556 - val_loss: 0.5061 - val_accuracy: 0.7011\n",
            "Epoch 177/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4524 - accuracy: 0.7580 - val_loss: 0.5061 - val_accuracy: 0.7011\n",
            "Epoch 178/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4525 - accuracy: 0.7605 - val_loss: 0.5068 - val_accuracy: 0.6954\n",
            "Epoch 179/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4524 - accuracy: 0.7630 - val_loss: 0.5066 - val_accuracy: 0.7011\n",
            "Epoch 180/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4521 - accuracy: 0.7605 - val_loss: 0.5061 - val_accuracy: 0.6954\n",
            "Epoch 181/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4517 - accuracy: 0.7605 - val_loss: 0.5055 - val_accuracy: 0.7069\n",
            "Epoch 182/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4524 - accuracy: 0.7580 - val_loss: 0.5060 - val_accuracy: 0.6954\n",
            "Epoch 183/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4515 - accuracy: 0.7605 - val_loss: 0.5063 - val_accuracy: 0.6954\n",
            "Epoch 184/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4509 - accuracy: 0.7630 - val_loss: 0.5061 - val_accuracy: 0.7011\n",
            "Epoch 185/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.7580 - val_loss: 0.5062 - val_accuracy: 0.7069\n",
            "Epoch 186/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4510 - accuracy: 0.7580 - val_loss: 0.5065 - val_accuracy: 0.7011\n",
            "Epoch 187/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.7605 - val_loss: 0.5070 - val_accuracy: 0.7011\n",
            "Epoch 188/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4510 - accuracy: 0.7580 - val_loss: 0.5074 - val_accuracy: 0.6897\n",
            "Epoch 189/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.7580 - val_loss: 0.5074 - val_accuracy: 0.6897\n",
            "Epoch 190/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.7580 - val_loss: 0.5073 - val_accuracy: 0.6954\n",
            "Epoch 191/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.7605 - val_loss: 0.5068 - val_accuracy: 0.7011\n",
            "Epoch 192/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.7580 - val_loss: 0.5067 - val_accuracy: 0.7069\n",
            "Epoch 193/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4498 - accuracy: 0.7580 - val_loss: 0.5069 - val_accuracy: 0.7069\n",
            "Epoch 194/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.7580 - val_loss: 0.5068 - val_accuracy: 0.7069\n",
            "Epoch 195/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4496 - accuracy: 0.7580 - val_loss: 0.5061 - val_accuracy: 0.7184\n",
            "Epoch 196/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4502 - accuracy: 0.7605 - val_loss: 0.5082 - val_accuracy: 0.6954\n",
            "Epoch 197/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4497 - accuracy: 0.7580 - val_loss: 0.5078 - val_accuracy: 0.7069\n",
            "Epoch 198/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.7580 - val_loss: 0.5080 - val_accuracy: 0.7011\n",
            "Epoch 199/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.7580 - val_loss: 0.5088 - val_accuracy: 0.6954\n",
            "Epoch 200/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.7580 - val_loss: 0.5092 - val_accuracy: 0.6897\n",
            "Epoch 201/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.7580 - val_loss: 0.5089 - val_accuracy: 0.6954\n",
            "Epoch 202/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4490 - accuracy: 0.7580 - val_loss: 0.5087 - val_accuracy: 0.6954\n",
            "Epoch 203/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.7580 - val_loss: 0.5093 - val_accuracy: 0.6897\n",
            "Epoch 204/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4484 - accuracy: 0.7605 - val_loss: 0.5088 - val_accuracy: 0.7011\n",
            "Epoch 205/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4483 - accuracy: 0.7580 - val_loss: 0.5100 - val_accuracy: 0.6954\n",
            "Epoch 206/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.7580 - val_loss: 0.5091 - val_accuracy: 0.7011\n",
            "Epoch 207/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4480 - accuracy: 0.7630 - val_loss: 0.5085 - val_accuracy: 0.7126\n",
            "Epoch 208/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4478 - accuracy: 0.7580 - val_loss: 0.5096 - val_accuracy: 0.6954\n",
            "Epoch 209/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4475 - accuracy: 0.7605 - val_loss: 0.5100 - val_accuracy: 0.6897\n",
            "Epoch 210/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4476 - accuracy: 0.7630 - val_loss: 0.5106 - val_accuracy: 0.6897\n",
            "Epoch 211/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4472 - accuracy: 0.7630 - val_loss: 0.5105 - val_accuracy: 0.6954\n",
            "Epoch 212/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.7630 - val_loss: 0.5110 - val_accuracy: 0.6954\n",
            "Epoch 213/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4470 - accuracy: 0.7630 - val_loss: 0.5111 - val_accuracy: 0.6897\n",
            "Epoch 214/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4466 - accuracy: 0.7580 - val_loss: 0.5114 - val_accuracy: 0.6897\n",
            "Epoch 215/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4470 - accuracy: 0.7605 - val_loss: 0.5113 - val_accuracy: 0.6897\n",
            "Epoch 216/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4465 - accuracy: 0.7630 - val_loss: 0.5117 - val_accuracy: 0.6782\n",
            "Epoch 217/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4460 - accuracy: 0.7605 - val_loss: 0.5103 - val_accuracy: 0.6954\n",
            "Epoch 218/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.7679 - val_loss: 0.5115 - val_accuracy: 0.6897\n",
            "Epoch 219/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4460 - accuracy: 0.7630 - val_loss: 0.5112 - val_accuracy: 0.6897\n",
            "Epoch 220/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4455 - accuracy: 0.7630 - val_loss: 0.5104 - val_accuracy: 0.7184\n",
            "Epoch 221/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4455 - accuracy: 0.7679 - val_loss: 0.5101 - val_accuracy: 0.7069\n",
            "Epoch 222/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.7654 - val_loss: 0.5116 - val_accuracy: 0.6897\n",
            "Epoch 223/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.7630 - val_loss: 0.5104 - val_accuracy: 0.7184\n",
            "Epoch 224/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.7679 - val_loss: 0.5108 - val_accuracy: 0.7126\n",
            "Epoch 225/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4447 - accuracy: 0.7654 - val_loss: 0.5116 - val_accuracy: 0.6897\n",
            "Epoch 226/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.4444 - accuracy: 0.7654 - val_loss: 0.5105 - val_accuracy: 0.7126\n",
            "Epoch 227/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4440 - accuracy: 0.7679 - val_loss: 0.5113 - val_accuracy: 0.7069\n",
            "Epoch 228/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4439 - accuracy: 0.7654 - val_loss: 0.5107 - val_accuracy: 0.7126\n",
            "Epoch 229/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4441 - accuracy: 0.7679 - val_loss: 0.5113 - val_accuracy: 0.7126\n",
            "Epoch 230/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4434 - accuracy: 0.7679 - val_loss: 0.5106 - val_accuracy: 0.7241\n",
            "Epoch 231/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4435 - accuracy: 0.7654 - val_loss: 0.5124 - val_accuracy: 0.6954\n",
            "Epoch 232/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.7679 - val_loss: 0.5116 - val_accuracy: 0.7184\n",
            "Epoch 233/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4432 - accuracy: 0.7654 - val_loss: 0.5116 - val_accuracy: 0.7184\n",
            "Epoch 234/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.7654 - val_loss: 0.5109 - val_accuracy: 0.7184\n",
            "Epoch 235/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.7654 - val_loss: 0.5107 - val_accuracy: 0.7184\n",
            "Epoch 236/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.7654 - val_loss: 0.5117 - val_accuracy: 0.7126\n",
            "Epoch 237/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.7654 - val_loss: 0.5118 - val_accuracy: 0.7126\n",
            "Epoch 238/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.7654 - val_loss: 0.5107 - val_accuracy: 0.7184\n",
            "Epoch 239/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4417 - accuracy: 0.7654 - val_loss: 0.5116 - val_accuracy: 0.7184\n",
            "Epoch 240/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.7679 - val_loss: 0.5111 - val_accuracy: 0.7184\n",
            "Epoch 241/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.7654 - val_loss: 0.5117 - val_accuracy: 0.7126\n",
            "Epoch 242/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4404 - accuracy: 0.7630 - val_loss: 0.5139 - val_accuracy: 0.6954\n",
            "Epoch 243/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.7704 - val_loss: 0.5125 - val_accuracy: 0.7069\n",
            "Epoch 244/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.7654 - val_loss: 0.5134 - val_accuracy: 0.6897\n",
            "Epoch 245/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7654 - val_loss: 0.5125 - val_accuracy: 0.7069\n",
            "Epoch 246/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.7654 - val_loss: 0.5141 - val_accuracy: 0.6897\n",
            "Epoch 247/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.7630 - val_loss: 0.5136 - val_accuracy: 0.6897\n",
            "Epoch 248/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.7630 - val_loss: 0.5134 - val_accuracy: 0.7011\n",
            "Epoch 249/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4398 - accuracy: 0.7679 - val_loss: 0.5131 - val_accuracy: 0.7069\n",
            "Epoch 250/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4398 - accuracy: 0.7630 - val_loss: 0.5124 - val_accuracy: 0.7126\n",
            "Epoch 251/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4398 - accuracy: 0.7654 - val_loss: 0.5122 - val_accuracy: 0.7126\n",
            "Epoch 252/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4392 - accuracy: 0.7704 - val_loss: 0.5124 - val_accuracy: 0.7126\n",
            "Epoch 253/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4390 - accuracy: 0.7679 - val_loss: 0.5136 - val_accuracy: 0.7069\n",
            "Epoch 254/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4390 - accuracy: 0.7679 - val_loss: 0.5145 - val_accuracy: 0.7069\n",
            "Epoch 255/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.7654 - val_loss: 0.5135 - val_accuracy: 0.7069\n",
            "Epoch 256/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4381 - accuracy: 0.7679 - val_loss: 0.5138 - val_accuracy: 0.7069\n",
            "Epoch 257/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4382 - accuracy: 0.7654 - val_loss: 0.5136 - val_accuracy: 0.7069\n",
            "Epoch 258/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4383 - accuracy: 0.7679 - val_loss: 0.5130 - val_accuracy: 0.7126\n",
            "Epoch 259/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.7679 - val_loss: 0.5138 - val_accuracy: 0.7069\n",
            "Epoch 260/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.7630 - val_loss: 0.5146 - val_accuracy: 0.7011\n",
            "Epoch 261/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.7679 - val_loss: 0.5134 - val_accuracy: 0.7126\n",
            "Epoch 262/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7679 - val_loss: 0.5143 - val_accuracy: 0.7069\n",
            "Epoch 263/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7704 - val_loss: 0.5139 - val_accuracy: 0.7126\n",
            "Epoch 264/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7654 - val_loss: 0.5147 - val_accuracy: 0.7069\n",
            "Epoch 265/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4369 - accuracy: 0.7654 - val_loss: 0.5137 - val_accuracy: 0.7126\n",
            "Epoch 266/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4369 - accuracy: 0.7679 - val_loss: 0.5124 - val_accuracy: 0.7184\n",
            "Epoch 267/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4371 - accuracy: 0.7654 - val_loss: 0.5138 - val_accuracy: 0.7126\n",
            "Epoch 268/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4365 - accuracy: 0.7654 - val_loss: 0.5142 - val_accuracy: 0.7126\n",
            "Epoch 269/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4364 - accuracy: 0.7654 - val_loss: 0.5142 - val_accuracy: 0.7069\n",
            "Epoch 270/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.7704 - val_loss: 0.5143 - val_accuracy: 0.7126\n",
            "Epoch 271/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4363 - accuracy: 0.7630 - val_loss: 0.5142 - val_accuracy: 0.7126\n",
            "Epoch 272/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4362 - accuracy: 0.7630 - val_loss: 0.5143 - val_accuracy: 0.7126\n",
            "Epoch 273/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4360 - accuracy: 0.7654 - val_loss: 0.5150 - val_accuracy: 0.7126\n",
            "Epoch 274/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.7654 - val_loss: 0.5143 - val_accuracy: 0.7126\n",
            "Epoch 275/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.7679 - val_loss: 0.5145 - val_accuracy: 0.7069\n",
            "Epoch 276/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.7630 - val_loss: 0.5148 - val_accuracy: 0.7126\n",
            "Epoch 277/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4360 - accuracy: 0.7605 - val_loss: 0.5159 - val_accuracy: 0.7069\n",
            "Epoch 278/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7654 - val_loss: 0.5149 - val_accuracy: 0.7126\n",
            "Epoch 279/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7654 - val_loss: 0.5160 - val_accuracy: 0.7069\n",
            "Epoch 280/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4348 - accuracy: 0.7630 - val_loss: 0.5174 - val_accuracy: 0.7069\n",
            "Epoch 281/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7630 - val_loss: 0.5175 - val_accuracy: 0.6954\n",
            "Epoch 282/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4347 - accuracy: 0.7630 - val_loss: 0.5165 - val_accuracy: 0.7069\n",
            "Epoch 283/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.7679 - val_loss: 0.5171 - val_accuracy: 0.7069\n",
            "Epoch 284/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4344 - accuracy: 0.7605 - val_loss: 0.5165 - val_accuracy: 0.7126\n",
            "Epoch 285/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4344 - accuracy: 0.7654 - val_loss: 0.5166 - val_accuracy: 0.7126\n",
            "Epoch 286/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.7630 - val_loss: 0.5176 - val_accuracy: 0.7011\n",
            "Epoch 287/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4347 - accuracy: 0.7679 - val_loss: 0.5178 - val_accuracy: 0.7069\n",
            "Epoch 288/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4338 - accuracy: 0.7679 - val_loss: 0.5178 - val_accuracy: 0.7069\n",
            "Epoch 289/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4337 - accuracy: 0.7679 - val_loss: 0.5167 - val_accuracy: 0.7126\n",
            "Epoch 290/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4338 - accuracy: 0.7679 - val_loss: 0.5168 - val_accuracy: 0.7126\n",
            "Epoch 291/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4339 - accuracy: 0.7679 - val_loss: 0.5177 - val_accuracy: 0.7126\n",
            "Epoch 292/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4336 - accuracy: 0.7654 - val_loss: 0.5173 - val_accuracy: 0.7126\n",
            "Epoch 293/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4331 - accuracy: 0.7679 - val_loss: 0.5185 - val_accuracy: 0.7069\n",
            "Epoch 294/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4331 - accuracy: 0.7679 - val_loss: 0.5159 - val_accuracy: 0.7184\n",
            "Epoch 295/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4331 - accuracy: 0.7654 - val_loss: 0.5167 - val_accuracy: 0.7126\n",
            "Epoch 296/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4335 - accuracy: 0.7679 - val_loss: 0.5172 - val_accuracy: 0.7126\n",
            "Epoch 297/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4326 - accuracy: 0.7654 - val_loss: 0.5185 - val_accuracy: 0.7069\n",
            "Epoch 298/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4326 - accuracy: 0.7654 - val_loss: 0.5181 - val_accuracy: 0.7126\n",
            "Epoch 299/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.7654 - val_loss: 0.5183 - val_accuracy: 0.7126\n",
            "Epoch 300/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.4326 - accuracy: 0.7654 - val_loss: 0.5170 - val_accuracy: 0.7126\n",
            "Epoch 301/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4326 - accuracy: 0.7654 - val_loss: 0.5172 - val_accuracy: 0.7126\n",
            "Epoch 302/500\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.4323 - accuracy: 0.7630 - val_loss: 0.5181 - val_accuracy: 0.7126\n",
            "Epoch 303/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4322 - accuracy: 0.7654 - val_loss: 0.5187 - val_accuracy: 0.7126\n",
            "Epoch 304/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4320 - accuracy: 0.7654 - val_loss: 0.5189 - val_accuracy: 0.7069\n",
            "Epoch 305/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4315 - accuracy: 0.7654 - val_loss: 0.5187 - val_accuracy: 0.7069\n",
            "Epoch 306/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4324 - accuracy: 0.7679 - val_loss: 0.5190 - val_accuracy: 0.7126\n",
            "Epoch 307/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.7679 - val_loss: 0.5185 - val_accuracy: 0.7126\n",
            "Epoch 308/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4313 - accuracy: 0.7679 - val_loss: 0.5192 - val_accuracy: 0.7126\n",
            "Epoch 309/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.7630 - val_loss: 0.5175 - val_accuracy: 0.7126\n",
            "Epoch 310/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4309 - accuracy: 0.7654 - val_loss: 0.5194 - val_accuracy: 0.7126\n",
            "Epoch 311/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.7679 - val_loss: 0.5183 - val_accuracy: 0.7126\n",
            "Epoch 312/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.7654 - val_loss: 0.5188 - val_accuracy: 0.7126\n",
            "Epoch 313/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4305 - accuracy: 0.7679 - val_loss: 0.5175 - val_accuracy: 0.7126\n",
            "Epoch 314/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4308 - accuracy: 0.7654 - val_loss: 0.5201 - val_accuracy: 0.7011\n",
            "Epoch 315/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4303 - accuracy: 0.7654 - val_loss: 0.5196 - val_accuracy: 0.7011\n",
            "Epoch 316/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4304 - accuracy: 0.7654 - val_loss: 0.5199 - val_accuracy: 0.7126\n",
            "Epoch 317/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4303 - accuracy: 0.7654 - val_loss: 0.5187 - val_accuracy: 0.7126\n",
            "Epoch 318/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4299 - accuracy: 0.7679 - val_loss: 0.5194 - val_accuracy: 0.7126\n",
            "Epoch 319/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4299 - accuracy: 0.7654 - val_loss: 0.5187 - val_accuracy: 0.7126\n",
            "Epoch 320/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4296 - accuracy: 0.7630 - val_loss: 0.5177 - val_accuracy: 0.7126\n",
            "Epoch 321/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4296 - accuracy: 0.7654 - val_loss: 0.5194 - val_accuracy: 0.7126\n",
            "Epoch 322/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4295 - accuracy: 0.7679 - val_loss: 0.5199 - val_accuracy: 0.7126\n",
            "Epoch 323/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.7654 - val_loss: 0.5203 - val_accuracy: 0.7126\n",
            "Epoch 324/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4288 - accuracy: 0.7704 - val_loss: 0.5198 - val_accuracy: 0.7069\n",
            "Epoch 325/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.7679 - val_loss: 0.5194 - val_accuracy: 0.7011\n",
            "Epoch 326/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.7654 - val_loss: 0.5200 - val_accuracy: 0.7069\n",
            "Epoch 327/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4286 - accuracy: 0.7704 - val_loss: 0.5197 - val_accuracy: 0.7069\n",
            "Epoch 328/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.7654 - val_loss: 0.5201 - val_accuracy: 0.7011\n",
            "Epoch 329/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4281 - accuracy: 0.7654 - val_loss: 0.5204 - val_accuracy: 0.7011\n",
            "Epoch 330/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4281 - accuracy: 0.7679 - val_loss: 0.5201 - val_accuracy: 0.7069\n",
            "Epoch 331/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.7704 - val_loss: 0.5200 - val_accuracy: 0.7069\n",
            "Epoch 332/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.7704 - val_loss: 0.5197 - val_accuracy: 0.7069\n",
            "Epoch 333/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.7679 - val_loss: 0.5200 - val_accuracy: 0.7069\n",
            "Epoch 334/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4275 - accuracy: 0.7728 - val_loss: 0.5208 - val_accuracy: 0.7011\n",
            "Epoch 335/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4270 - accuracy: 0.7654 - val_loss: 0.5219 - val_accuracy: 0.7011\n",
            "Epoch 336/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4270 - accuracy: 0.7728 - val_loss: 0.5210 - val_accuracy: 0.6954\n",
            "Epoch 337/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4268 - accuracy: 0.7728 - val_loss: 0.5204 - val_accuracy: 0.7011\n",
            "Epoch 338/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4261 - accuracy: 0.7704 - val_loss: 0.5186 - val_accuracy: 0.7126\n",
            "Epoch 339/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.7630 - val_loss: 0.5199 - val_accuracy: 0.7011\n",
            "Epoch 340/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4264 - accuracy: 0.7679 - val_loss: 0.5200 - val_accuracy: 0.7069\n",
            "Epoch 341/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4260 - accuracy: 0.7679 - val_loss: 0.5201 - val_accuracy: 0.7069\n",
            "Epoch 342/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4255 - accuracy: 0.7728 - val_loss: 0.5200 - val_accuracy: 0.7126\n",
            "Epoch 343/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4260 - accuracy: 0.7704 - val_loss: 0.5206 - val_accuracy: 0.7069\n",
            "Epoch 344/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4263 - accuracy: 0.7679 - val_loss: 0.5210 - val_accuracy: 0.7069\n",
            "Epoch 345/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4253 - accuracy: 0.7704 - val_loss: 0.5223 - val_accuracy: 0.6954\n",
            "Epoch 346/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4249 - accuracy: 0.7728 - val_loss: 0.5206 - val_accuracy: 0.7011\n",
            "Epoch 347/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4248 - accuracy: 0.7704 - val_loss: 0.5192 - val_accuracy: 0.7184\n",
            "Epoch 348/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4250 - accuracy: 0.7630 - val_loss: 0.5200 - val_accuracy: 0.7011\n",
            "Epoch 349/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4248 - accuracy: 0.7728 - val_loss: 0.5205 - val_accuracy: 0.7011\n",
            "Epoch 350/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4245 - accuracy: 0.7704 - val_loss: 0.5202 - val_accuracy: 0.7011\n",
            "Epoch 351/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4244 - accuracy: 0.7679 - val_loss: 0.5196 - val_accuracy: 0.7069\n",
            "Epoch 352/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4242 - accuracy: 0.7654 - val_loss: 0.5221 - val_accuracy: 0.7011\n",
            "Epoch 353/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4240 - accuracy: 0.7654 - val_loss: 0.5210 - val_accuracy: 0.7126\n",
            "Epoch 354/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4239 - accuracy: 0.7753 - val_loss: 0.5211 - val_accuracy: 0.7011\n",
            "Epoch 355/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4235 - accuracy: 0.7704 - val_loss: 0.5200 - val_accuracy: 0.7069\n",
            "Epoch 356/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.7704 - val_loss: 0.5200 - val_accuracy: 0.7069\n",
            "Epoch 357/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4236 - accuracy: 0.7704 - val_loss: 0.5197 - val_accuracy: 0.7126\n",
            "Epoch 358/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4231 - accuracy: 0.7704 - val_loss: 0.5194 - val_accuracy: 0.7126\n",
            "Epoch 359/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4232 - accuracy: 0.7704 - val_loss: 0.5192 - val_accuracy: 0.7184\n",
            "Epoch 360/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4226 - accuracy: 0.7753 - val_loss: 0.5200 - val_accuracy: 0.7126\n",
            "Epoch 361/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4232 - accuracy: 0.7753 - val_loss: 0.5203 - val_accuracy: 0.7126\n",
            "Epoch 362/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4229 - accuracy: 0.7728 - val_loss: 0.5195 - val_accuracy: 0.7126\n",
            "Epoch 363/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4226 - accuracy: 0.7679 - val_loss: 0.5209 - val_accuracy: 0.7011\n",
            "Epoch 364/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.7728 - val_loss: 0.5198 - val_accuracy: 0.7126\n",
            "Epoch 365/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.7728 - val_loss: 0.5193 - val_accuracy: 0.7126\n",
            "Epoch 366/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4216 - accuracy: 0.7704 - val_loss: 0.5186 - val_accuracy: 0.7241\n",
            "Epoch 367/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4216 - accuracy: 0.7753 - val_loss: 0.5169 - val_accuracy: 0.7299\n",
            "Epoch 368/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4218 - accuracy: 0.7704 - val_loss: 0.5167 - val_accuracy: 0.7356\n",
            "Epoch 369/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.7679 - val_loss: 0.5172 - val_accuracy: 0.7299\n",
            "Epoch 370/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.7654 - val_loss: 0.5178 - val_accuracy: 0.7126\n",
            "Epoch 371/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4209 - accuracy: 0.7728 - val_loss: 0.5187 - val_accuracy: 0.7126\n",
            "Epoch 372/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.7704 - val_loss: 0.5173 - val_accuracy: 0.7184\n",
            "Epoch 373/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.7704 - val_loss: 0.5173 - val_accuracy: 0.7241\n",
            "Epoch 374/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4213 - accuracy: 0.7728 - val_loss: 0.5182 - val_accuracy: 0.7126\n",
            "Epoch 375/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4199 - accuracy: 0.7704 - val_loss: 0.5174 - val_accuracy: 0.7184\n",
            "Epoch 376/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.7704 - val_loss: 0.5166 - val_accuracy: 0.7299\n",
            "Epoch 377/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4192 - accuracy: 0.7728 - val_loss: 0.5182 - val_accuracy: 0.7241\n",
            "Epoch 378/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.7679 - val_loss: 0.5182 - val_accuracy: 0.7184\n",
            "Epoch 379/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4192 - accuracy: 0.7753 - val_loss: 0.5186 - val_accuracy: 0.7241\n",
            "Epoch 380/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.7753 - val_loss: 0.5192 - val_accuracy: 0.7184\n",
            "Epoch 381/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4188 - accuracy: 0.7753 - val_loss: 0.5186 - val_accuracy: 0.7241\n",
            "Epoch 382/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4189 - accuracy: 0.7704 - val_loss: 0.5189 - val_accuracy: 0.7241\n",
            "Epoch 383/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4186 - accuracy: 0.7753 - val_loss: 0.5187 - val_accuracy: 0.7184\n",
            "Epoch 384/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4184 - accuracy: 0.7728 - val_loss: 0.5190 - val_accuracy: 0.7241\n",
            "Epoch 385/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4182 - accuracy: 0.7753 - val_loss: 0.5199 - val_accuracy: 0.7126\n",
            "Epoch 386/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4181 - accuracy: 0.7802 - val_loss: 0.5186 - val_accuracy: 0.7241\n",
            "Epoch 387/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4176 - accuracy: 0.7753 - val_loss: 0.5181 - val_accuracy: 0.7184\n",
            "Epoch 388/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4177 - accuracy: 0.7753 - val_loss: 0.5185 - val_accuracy: 0.7184\n",
            "Epoch 389/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4174 - accuracy: 0.7728 - val_loss: 0.5191 - val_accuracy: 0.7184\n",
            "Epoch 390/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4173 - accuracy: 0.7802 - val_loss: 0.5186 - val_accuracy: 0.7184\n",
            "Epoch 391/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4168 - accuracy: 0.7802 - val_loss: 0.5189 - val_accuracy: 0.7184\n",
            "Epoch 392/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4171 - accuracy: 0.7802 - val_loss: 0.5190 - val_accuracy: 0.7184\n",
            "Epoch 393/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4163 - accuracy: 0.7778 - val_loss: 0.5172 - val_accuracy: 0.7126\n",
            "Epoch 394/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4166 - accuracy: 0.7778 - val_loss: 0.5169 - val_accuracy: 0.7126\n",
            "Epoch 395/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4161 - accuracy: 0.7802 - val_loss: 0.5169 - val_accuracy: 0.7184\n",
            "Epoch 396/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4161 - accuracy: 0.7728 - val_loss: 0.5185 - val_accuracy: 0.7184\n",
            "Epoch 397/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4159 - accuracy: 0.7802 - val_loss: 0.5165 - val_accuracy: 0.7241\n",
            "Epoch 398/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4159 - accuracy: 0.7778 - val_loss: 0.5164 - val_accuracy: 0.7184\n",
            "Epoch 399/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4154 - accuracy: 0.7827 - val_loss: 0.5175 - val_accuracy: 0.7126\n",
            "Epoch 400/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4155 - accuracy: 0.7802 - val_loss: 0.5172 - val_accuracy: 0.7184\n",
            "Epoch 401/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.7778 - val_loss: 0.5183 - val_accuracy: 0.7241\n",
            "Epoch 402/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4143 - accuracy: 0.7802 - val_loss: 0.5188 - val_accuracy: 0.7184\n",
            "Epoch 403/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4148 - accuracy: 0.7827 - val_loss: 0.5182 - val_accuracy: 0.7184\n",
            "Epoch 404/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4141 - accuracy: 0.7852 - val_loss: 0.5200 - val_accuracy: 0.7241\n",
            "Epoch 405/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4142 - accuracy: 0.7852 - val_loss: 0.5194 - val_accuracy: 0.7184\n",
            "Epoch 406/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4144 - accuracy: 0.7802 - val_loss: 0.5192 - val_accuracy: 0.7241\n",
            "Epoch 407/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4135 - accuracy: 0.7827 - val_loss: 0.5195 - val_accuracy: 0.7184\n",
            "Epoch 408/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4136 - accuracy: 0.7852 - val_loss: 0.5194 - val_accuracy: 0.7184\n",
            "Epoch 409/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4129 - accuracy: 0.7852 - val_loss: 0.5186 - val_accuracy: 0.7241\n",
            "Epoch 410/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.4130 - accuracy: 0.7827 - val_loss: 0.5175 - val_accuracy: 0.7184\n",
            "Epoch 411/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4124 - accuracy: 0.7852 - val_loss: 0.5182 - val_accuracy: 0.7241\n",
            "Epoch 412/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4121 - accuracy: 0.7778 - val_loss: 0.5196 - val_accuracy: 0.7184\n",
            "Epoch 413/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4127 - accuracy: 0.7852 - val_loss: 0.5187 - val_accuracy: 0.7241\n",
            "Epoch 414/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4118 - accuracy: 0.7778 - val_loss: 0.5202 - val_accuracy: 0.7184\n",
            "Epoch 415/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4120 - accuracy: 0.7877 - val_loss: 0.5197 - val_accuracy: 0.7241\n",
            "Epoch 416/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4117 - accuracy: 0.7827 - val_loss: 0.5186 - val_accuracy: 0.7241\n",
            "Epoch 417/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4113 - accuracy: 0.7827 - val_loss: 0.5187 - val_accuracy: 0.7184\n",
            "Epoch 418/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4118 - accuracy: 0.7827 - val_loss: 0.5193 - val_accuracy: 0.7184\n",
            "Epoch 419/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.7827 - val_loss: 0.5181 - val_accuracy: 0.7241\n",
            "Epoch 420/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4109 - accuracy: 0.7852 - val_loss: 0.5187 - val_accuracy: 0.7184\n",
            "Epoch 421/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4107 - accuracy: 0.7827 - val_loss: 0.5183 - val_accuracy: 0.7241\n",
            "Epoch 422/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.7852 - val_loss: 0.5203 - val_accuracy: 0.7241\n",
            "Epoch 423/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4102 - accuracy: 0.7827 - val_loss: 0.5197 - val_accuracy: 0.7184\n",
            "Epoch 424/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.7852 - val_loss: 0.5197 - val_accuracy: 0.7184\n",
            "Epoch 425/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.4094 - accuracy: 0.7877 - val_loss: 0.5184 - val_accuracy: 0.7241\n",
            "Epoch 426/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4098 - accuracy: 0.7802 - val_loss: 0.5196 - val_accuracy: 0.7184\n",
            "Epoch 427/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4090 - accuracy: 0.7877 - val_loss: 0.5211 - val_accuracy: 0.7184\n",
            "Epoch 428/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4092 - accuracy: 0.7852 - val_loss: 0.5209 - val_accuracy: 0.7241\n",
            "Epoch 429/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4088 - accuracy: 0.7877 - val_loss: 0.5220 - val_accuracy: 0.7241\n",
            "Epoch 430/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4086 - accuracy: 0.7852 - val_loss: 0.5207 - val_accuracy: 0.7184\n",
            "Epoch 431/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4086 - accuracy: 0.7852 - val_loss: 0.5195 - val_accuracy: 0.7184\n",
            "Epoch 432/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4080 - accuracy: 0.7877 - val_loss: 0.5195 - val_accuracy: 0.7241\n",
            "Epoch 433/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4080 - accuracy: 0.7827 - val_loss: 0.5213 - val_accuracy: 0.7184\n",
            "Epoch 434/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4074 - accuracy: 0.7852 - val_loss: 0.5197 - val_accuracy: 0.7184\n",
            "Epoch 435/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4080 - accuracy: 0.7852 - val_loss: 0.5201 - val_accuracy: 0.7184\n",
            "Epoch 436/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4071 - accuracy: 0.7877 - val_loss: 0.5201 - val_accuracy: 0.7356\n",
            "Epoch 437/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4066 - accuracy: 0.7877 - val_loss: 0.5218 - val_accuracy: 0.7241\n",
            "Epoch 438/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4069 - accuracy: 0.7877 - val_loss: 0.5221 - val_accuracy: 0.7241\n",
            "Epoch 439/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.7852 - val_loss: 0.5210 - val_accuracy: 0.7414\n",
            "Epoch 440/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4073 - accuracy: 0.7827 - val_loss: 0.5211 - val_accuracy: 0.7356\n",
            "Epoch 441/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.7852 - val_loss: 0.5206 - val_accuracy: 0.7414\n",
            "Epoch 442/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4059 - accuracy: 0.7877 - val_loss: 0.5218 - val_accuracy: 0.7299\n",
            "Epoch 443/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.7877 - val_loss: 0.5218 - val_accuracy: 0.7414\n",
            "Epoch 444/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4061 - accuracy: 0.7852 - val_loss: 0.5226 - val_accuracy: 0.7241\n",
            "Epoch 445/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4050 - accuracy: 0.7852 - val_loss: 0.5208 - val_accuracy: 0.7471\n",
            "Epoch 446/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4059 - accuracy: 0.7877 - val_loss: 0.5221 - val_accuracy: 0.7471\n",
            "Epoch 447/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4049 - accuracy: 0.7852 - val_loss: 0.5217 - val_accuracy: 0.7414\n",
            "Epoch 448/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4054 - accuracy: 0.7827 - val_loss: 0.5222 - val_accuracy: 0.7414\n",
            "Epoch 449/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4049 - accuracy: 0.7877 - val_loss: 0.5232 - val_accuracy: 0.7356\n",
            "Epoch 450/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4045 - accuracy: 0.7877 - val_loss: 0.5221 - val_accuracy: 0.7414\n",
            "Epoch 451/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4042 - accuracy: 0.7901 - val_loss: 0.5238 - val_accuracy: 0.7241\n",
            "Epoch 452/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4047 - accuracy: 0.7877 - val_loss: 0.5258 - val_accuracy: 0.7184\n",
            "Epoch 453/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4041 - accuracy: 0.7877 - val_loss: 0.5262 - val_accuracy: 0.7184\n",
            "Epoch 454/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4040 - accuracy: 0.7901 - val_loss: 0.5269 - val_accuracy: 0.7184\n",
            "Epoch 455/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4032 - accuracy: 0.7877 - val_loss: 0.5242 - val_accuracy: 0.7414\n",
            "Epoch 456/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4042 - accuracy: 0.7877 - val_loss: 0.5263 - val_accuracy: 0.7184\n",
            "Epoch 457/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4034 - accuracy: 0.7901 - val_loss: 0.5278 - val_accuracy: 0.7184\n",
            "Epoch 458/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4031 - accuracy: 0.7877 - val_loss: 0.5262 - val_accuracy: 0.7299\n",
            "Epoch 459/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4034 - accuracy: 0.7901 - val_loss: 0.5259 - val_accuracy: 0.7299\n",
            "Epoch 460/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4031 - accuracy: 0.7877 - val_loss: 0.5262 - val_accuracy: 0.7184\n",
            "Epoch 461/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4034 - accuracy: 0.7852 - val_loss: 0.5273 - val_accuracy: 0.7184\n",
            "Epoch 462/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.4029 - accuracy: 0.7877 - val_loss: 0.5269 - val_accuracy: 0.7299\n",
            "Epoch 463/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4022 - accuracy: 0.7901 - val_loss: 0.5271 - val_accuracy: 0.7299\n",
            "Epoch 464/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4021 - accuracy: 0.7852 - val_loss: 0.5283 - val_accuracy: 0.7184\n",
            "Epoch 465/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4023 - accuracy: 0.7877 - val_loss: 0.5271 - val_accuracy: 0.7299\n",
            "Epoch 466/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4026 - accuracy: 0.7901 - val_loss: 0.5274 - val_accuracy: 0.7356\n",
            "Epoch 467/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4024 - accuracy: 0.7901 - val_loss: 0.5279 - val_accuracy: 0.7299\n",
            "Epoch 468/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4014 - accuracy: 0.7877 - val_loss: 0.5267 - val_accuracy: 0.7356\n",
            "Epoch 469/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.4010 - accuracy: 0.7926 - val_loss: 0.5291 - val_accuracy: 0.7184\n",
            "Epoch 470/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4013 - accuracy: 0.7901 - val_loss: 0.5270 - val_accuracy: 0.7356\n",
            "Epoch 471/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4012 - accuracy: 0.7926 - val_loss: 0.5289 - val_accuracy: 0.7184\n",
            "Epoch 472/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4013 - accuracy: 0.7901 - val_loss: 0.5307 - val_accuracy: 0.7126\n",
            "Epoch 473/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4012 - accuracy: 0.7852 - val_loss: 0.5299 - val_accuracy: 0.7184\n",
            "Epoch 474/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4007 - accuracy: 0.7926 - val_loss: 0.5306 - val_accuracy: 0.7184\n",
            "Epoch 475/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4014 - accuracy: 0.7901 - val_loss: 0.5287 - val_accuracy: 0.7356\n",
            "Epoch 476/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4007 - accuracy: 0.7901 - val_loss: 0.5260 - val_accuracy: 0.7414\n",
            "Epoch 477/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4007 - accuracy: 0.7901 - val_loss: 0.5282 - val_accuracy: 0.7299\n",
            "Epoch 478/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4002 - accuracy: 0.7901 - val_loss: 0.5290 - val_accuracy: 0.7299\n",
            "Epoch 479/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3998 - accuracy: 0.7852 - val_loss: 0.5285 - val_accuracy: 0.7414\n",
            "Epoch 480/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4005 - accuracy: 0.7926 - val_loss: 0.5296 - val_accuracy: 0.7414\n",
            "Epoch 481/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4001 - accuracy: 0.7877 - val_loss: 0.5298 - val_accuracy: 0.7414\n",
            "Epoch 482/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.4001 - accuracy: 0.7901 - val_loss: 0.5306 - val_accuracy: 0.7241\n",
            "Epoch 483/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3996 - accuracy: 0.7877 - val_loss: 0.5321 - val_accuracy: 0.7184\n",
            "Epoch 484/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.7852 - val_loss: 0.5297 - val_accuracy: 0.7414\n",
            "Epoch 485/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3991 - accuracy: 0.7926 - val_loss: 0.5328 - val_accuracy: 0.7184\n",
            "Epoch 486/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.3994 - accuracy: 0.7852 - val_loss: 0.5310 - val_accuracy: 0.7414\n",
            "Epoch 487/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3998 - accuracy: 0.7926 - val_loss: 0.5323 - val_accuracy: 0.7356\n",
            "Epoch 488/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3990 - accuracy: 0.7852 - val_loss: 0.5309 - val_accuracy: 0.7414\n",
            "Epoch 489/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.3984 - accuracy: 0.7926 - val_loss: 0.5300 - val_accuracy: 0.7414\n",
            "Epoch 490/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.4001 - accuracy: 0.7877 - val_loss: 0.5311 - val_accuracy: 0.7414\n",
            "Epoch 491/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3987 - accuracy: 0.7926 - val_loss: 0.5316 - val_accuracy: 0.7299\n",
            "Epoch 492/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3985 - accuracy: 0.7926 - val_loss: 0.5338 - val_accuracy: 0.7241\n",
            "Epoch 493/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3981 - accuracy: 0.7877 - val_loss: 0.5337 - val_accuracy: 0.7241\n",
            "Epoch 494/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3983 - accuracy: 0.7926 - val_loss: 0.5354 - val_accuracy: 0.7126\n",
            "Epoch 495/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3987 - accuracy: 0.7877 - val_loss: 0.5347 - val_accuracy: 0.7241\n",
            "Epoch 496/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3983 - accuracy: 0.7877 - val_loss: 0.5329 - val_accuracy: 0.7414\n",
            "Epoch 497/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3979 - accuracy: 0.7852 - val_loss: 0.5328 - val_accuracy: 0.7414\n",
            "Epoch 498/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3976 - accuracy: 0.7901 - val_loss: 0.5347 - val_accuracy: 0.7241\n",
            "Epoch 499/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3978 - accuracy: 0.7901 - val_loss: 0.5331 - val_accuracy: 0.7414\n",
            "Epoch 500/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3976 - accuracy: 0.7901 - val_loss: 0.5350 - val_accuracy: 0.7241\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9rtJcw3GiMS",
        "outputId": "77e636e3-ea5e-42fd-ebda-06e9223694ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "r2.history['loss']"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7006009221076965,\n",
              " 0.680129885673523,\n",
              " 0.6638040542602539,\n",
              " 0.6500915288925171,\n",
              " 0.637951135635376,\n",
              " 0.6262570023536682,\n",
              " 0.6151567101478577,\n",
              " 0.6045784950256348,\n",
              " 0.5943148136138916,\n",
              " 0.5849649906158447,\n",
              " 0.576422929763794,\n",
              " 0.5687977075576782,\n",
              " 0.5611630082130432,\n",
              " 0.5544055700302124,\n",
              " 0.5482984185218811,\n",
              " 0.5428214073181152,\n",
              " 0.537647008895874,\n",
              " 0.5331476330757141,\n",
              " 0.5295146703720093,\n",
              " 0.525907576084137,\n",
              " 0.5234111547470093,\n",
              " 0.5203256607055664,\n",
              " 0.5180269479751587,\n",
              " 0.5158696174621582,\n",
              " 0.513710618019104,\n",
              " 0.5122330188751221,\n",
              " 0.5104495882987976,\n",
              " 0.509089469909668,\n",
              " 0.5078045725822449,\n",
              " 0.5068491697311401,\n",
              " 0.5055793523788452,\n",
              " 0.5045527219772339,\n",
              " 0.5035415291786194,\n",
              " 0.5024545788764954,\n",
              " 0.5014068484306335,\n",
              " 0.5006566643714905,\n",
              " 0.49995312094688416,\n",
              " 0.4991392195224762,\n",
              " 0.49846187233924866,\n",
              " 0.4977789521217346,\n",
              " 0.4970758259296417,\n",
              " 0.49629056453704834,\n",
              " 0.4957831799983978,\n",
              " 0.49483686685562134,\n",
              " 0.4940362870693207,\n",
              " 0.4936746060848236,\n",
              " 0.492922306060791,\n",
              " 0.49232491850852966,\n",
              " 0.49207764863967896,\n",
              " 0.4912528991699219,\n",
              " 0.490800142288208,\n",
              " 0.49034565687179565,\n",
              " 0.48994457721710205,\n",
              " 0.48933154344558716,\n",
              " 0.48887431621551514,\n",
              " 0.4886440932750702,\n",
              " 0.48819777369499207,\n",
              " 0.4877472221851349,\n",
              " 0.48726972937583923,\n",
              " 0.4868025779724121,\n",
              " 0.4863598346710205,\n",
              " 0.4859448969364166,\n",
              " 0.48534438014030457,\n",
              " 0.4849826395511627,\n",
              " 0.48469623923301697,\n",
              " 0.48417001962661743,\n",
              " 0.4837297201156616,\n",
              " 0.4831627607345581,\n",
              " 0.48263677954673767,\n",
              " 0.482469767332077,\n",
              " 0.48188021779060364,\n",
              " 0.4815613627433777,\n",
              " 0.4809325933456421,\n",
              " 0.48044297099113464,\n",
              " 0.4800904095172882,\n",
              " 0.47949841618537903,\n",
              " 0.4790298342704773,\n",
              " 0.4788440763950348,\n",
              " 0.4780591130256653,\n",
              " 0.477834552526474,\n",
              " 0.47738462686538696,\n",
              " 0.47697433829307556,\n",
              " 0.47650808095932007,\n",
              " 0.4760091006755829,\n",
              " 0.4758179187774658,\n",
              " 0.47557467222213745,\n",
              " 0.4749811589717865,\n",
              " 0.47474461793899536,\n",
              " 0.4742109775543213,\n",
              " 0.47381290793418884,\n",
              " 0.4735720753669739,\n",
              " 0.47337284684181213,\n",
              " 0.47269207239151,\n",
              " 0.47242793440818787,\n",
              " 0.4723515510559082,\n",
              " 0.4723651707172394,\n",
              " 0.47161877155303955,\n",
              " 0.4713474214076996,\n",
              " 0.4711366891860962,\n",
              " 0.4708211123943329,\n",
              " 0.47059330344200134,\n",
              " 0.47016939520835876,\n",
              " 0.46972769498825073,\n",
              " 0.4699449837207794,\n",
              " 0.4693412780761719,\n",
              " 0.4691438674926758,\n",
              " 0.46883559226989746,\n",
              " 0.46859878301620483,\n",
              " 0.46843692660331726,\n",
              " 0.46798616647720337,\n",
              " 0.4677099585533142,\n",
              " 0.4672400951385498,\n",
              " 0.467231810092926,\n",
              " 0.4673853814601898,\n",
              " 0.46662020683288574,\n",
              " 0.4666443169116974,\n",
              " 0.4663548171520233,\n",
              " 0.4661353826522827,\n",
              " 0.46560153365135193,\n",
              " 0.46608173847198486,\n",
              " 0.46532920002937317,\n",
              " 0.46520307660102844,\n",
              " 0.46501222252845764,\n",
              " 0.46473854780197144,\n",
              " 0.4645118713378906,\n",
              " 0.46394550800323486,\n",
              " 0.4638690650463104,\n",
              " 0.46332916617393494,\n",
              " 0.4631046950817108,\n",
              " 0.46276018023490906,\n",
              " 0.462770938873291,\n",
              " 0.4620923399925232,\n",
              " 0.46231889724731445,\n",
              " 0.461734801530838,\n",
              " 0.46139246225357056,\n",
              " 0.4609081745147705,\n",
              " 0.46121886372566223,\n",
              " 0.4605273902416229,\n",
              " 0.4601461589336395,\n",
              " 0.46010613441467285,\n",
              " 0.459743469953537,\n",
              " 0.4597119688987732,\n",
              " 0.4591076970100403,\n",
              " 0.45882946252822876,\n",
              " 0.45861032605171204,\n",
              " 0.45831844210624695,\n",
              " 0.4581822454929352,\n",
              " 0.45806175470352173,\n",
              " 0.45752009749412537,\n",
              " 0.45744091272354126,\n",
              " 0.4576512575149536,\n",
              " 0.4571561813354492,\n",
              " 0.45676177740097046,\n",
              " 0.45639604330062866,\n",
              " 0.4567452073097229,\n",
              " 0.4562738537788391,\n",
              " 0.45609280467033386,\n",
              " 0.45586127042770386,\n",
              " 0.4555034041404724,\n",
              " 0.4553227126598358,\n",
              " 0.4555380046367645,\n",
              " 0.4553881883621216,\n",
              " 0.4549272656440735,\n",
              " 0.4546615779399872,\n",
              " 0.45445626974105835,\n",
              " 0.45445960760116577,\n",
              " 0.4541145861148834,\n",
              " 0.4541509449481964,\n",
              " 0.45402827858924866,\n",
              " 0.45412760972976685,\n",
              " 0.453245609998703,\n",
              " 0.4533544182777405,\n",
              " 0.45323485136032104,\n",
              " 0.45296722650527954,\n",
              " 0.45276781916618347,\n",
              " 0.4524962902069092,\n",
              " 0.45238134264945984,\n",
              " 0.4524592161178589,\n",
              " 0.45239338278770447,\n",
              " 0.45208626985549927,\n",
              " 0.45169341564178467,\n",
              " 0.45240941643714905,\n",
              " 0.4515257179737091,\n",
              " 0.4509403705596924,\n",
              " 0.45130184292793274,\n",
              " 0.4510014057159424,\n",
              " 0.4511047303676605,\n",
              " 0.4509853720664978,\n",
              " 0.45048704743385315,\n",
              " 0.4505198299884796,\n",
              " 0.4501228332519531,\n",
              " 0.4506586194038391,\n",
              " 0.44979721307754517,\n",
              " 0.45007553696632385,\n",
              " 0.44955429434776306,\n",
              " 0.45022666454315186,\n",
              " 0.44974878430366516,\n",
              " 0.4494587779045105,\n",
              " 0.44882434606552124,\n",
              " 0.4489363729953766,\n",
              " 0.4488321542739868,\n",
              " 0.44895139336586,\n",
              " 0.44849005341529846,\n",
              " 0.4484485387802124,\n",
              " 0.44833827018737793,\n",
              " 0.44768285751342773,\n",
              " 0.44802626967430115,\n",
              " 0.44777557253837585,\n",
              " 0.44748610258102417,\n",
              " 0.4476071894168854,\n",
              " 0.447185218334198,\n",
              " 0.4477095901966095,\n",
              " 0.44701382517814636,\n",
              " 0.44662564992904663,\n",
              " 0.4469691216945648,\n",
              " 0.44651123881340027,\n",
              " 0.4459916055202484,\n",
              " 0.44581541419029236,\n",
              " 0.4459540843963623,\n",
              " 0.4455361068248749,\n",
              " 0.44547131657600403,\n",
              " 0.44497600197792053,\n",
              " 0.4449291527271271,\n",
              " 0.44475510716438293,\n",
              " 0.4447384178638458,\n",
              " 0.4443647265434265,\n",
              " 0.4439546465873718,\n",
              " 0.44392892718315125,\n",
              " 0.4441324770450592,\n",
              " 0.44337478280067444,\n",
              " 0.44350001215934753,\n",
              " 0.44292816519737244,\n",
              " 0.44317489862442017,\n",
              " 0.44284310936927795,\n",
              " 0.4427327513694763,\n",
              " 0.4426150619983673,\n",
              " 0.4418594241142273,\n",
              " 0.44205358624458313,\n",
              " 0.44174668192863464,\n",
              " 0.4412934184074402,\n",
              " 0.44137898087501526,\n",
              " 0.4404202401638031,\n",
              " 0.44127634167671204,\n",
              " 0.44066357612609863,\n",
              " 0.44047850370407104,\n",
              " 0.4400450587272644,\n",
              " 0.4401730000972748,\n",
              " 0.44024553894996643,\n",
              " 0.4397642910480499,\n",
              " 0.4397819936275482,\n",
              " 0.43979012966156006,\n",
              " 0.4391528367996216,\n",
              " 0.43904176354408264,\n",
              " 0.4390222132205963,\n",
              " 0.43859195709228516,\n",
              " 0.43812599778175354,\n",
              " 0.4381873309612274,\n",
              " 0.4382684528827667,\n",
              " 0.43826037645339966,\n",
              " 0.4374781847000122,\n",
              " 0.4374924898147583,\n",
              " 0.437435507774353,\n",
              " 0.43743520975112915,\n",
              " 0.43740740418434143,\n",
              " 0.43691879510879517,\n",
              " 0.436933696269989,\n",
              " 0.4371316432952881,\n",
              " 0.436542272567749,\n",
              " 0.436368852853775,\n",
              " 0.43655267357826233,\n",
              " 0.43626290559768677,\n",
              " 0.4362332820892334,\n",
              " 0.4360330402851105,\n",
              " 0.43543577194213867,\n",
              " 0.4355960488319397,\n",
              " 0.43553414940834045,\n",
              " 0.435955286026001,\n",
              " 0.43499210476875305,\n",
              " 0.4350261688232422,\n",
              " 0.4348461329936981,\n",
              " 0.4350862503051758,\n",
              " 0.4346623122692108,\n",
              " 0.43464505672454834,\n",
              " 0.43443214893341064,\n",
              " 0.4343622028827667,\n",
              " 0.43406134843826294,\n",
              " 0.43466925621032715,\n",
              " 0.4338303506374359,\n",
              " 0.43372711539268494,\n",
              " 0.4338383376598358,\n",
              " 0.43389925360679626,\n",
              " 0.43361955881118774,\n",
              " 0.4331173598766327,\n",
              " 0.4331080913543701,\n",
              " 0.4331016540527344,\n",
              " 0.4334569573402405,\n",
              " 0.4325684607028961,\n",
              " 0.4326085150241852,\n",
              " 0.4330301880836487,\n",
              " 0.43261462450027466,\n",
              " 0.4325745701789856,\n",
              " 0.4323054850101471,\n",
              " 0.4321509599685669,\n",
              " 0.432024210691452,\n",
              " 0.43148764967918396,\n",
              " 0.43244704604148865,\n",
              " 0.43230873346328735,\n",
              " 0.43127721548080444,\n",
              " 0.4309903383255005,\n",
              " 0.4308522641658783,\n",
              " 0.4311937093734741,\n",
              " 0.4310247600078583,\n",
              " 0.430525004863739,\n",
              " 0.43076077103614807,\n",
              " 0.4302988648414612,\n",
              " 0.43038544058799744,\n",
              " 0.4302748739719391,\n",
              " 0.429890900850296,\n",
              " 0.4298771619796753,\n",
              " 0.42962756752967834,\n",
              " 0.4296264350414276,\n",
              " 0.4295407831668854,\n",
              " 0.4297546446323395,\n",
              " 0.4287833869457245,\n",
              " 0.4287368655204773,\n",
              " 0.4286936819553375,\n",
              " 0.428602397441864,\n",
              " 0.42850273847579956,\n",
              " 0.4280884861946106,\n",
              " 0.42812296748161316,\n",
              " 0.4277074635028839,\n",
              " 0.42762354016304016,\n",
              " 0.4276559054851532,\n",
              " 0.4275134801864624,\n",
              " 0.42704540491104126,\n",
              " 0.4269862771034241,\n",
              " 0.42683884501457214,\n",
              " 0.4261000156402588,\n",
              " 0.4265457093715668,\n",
              " 0.42638418078422546,\n",
              " 0.42598608136177063,\n",
              " 0.4254531264305115,\n",
              " 0.4260402023792267,\n",
              " 0.42625418305397034,\n",
              " 0.4253249168395996,\n",
              " 0.42494189739227295,\n",
              " 0.42479318380355835,\n",
              " 0.42500731348991394,\n",
              " 0.42482537031173706,\n",
              " 0.424464613199234,\n",
              " 0.4244256019592285,\n",
              " 0.4242419898509979,\n",
              " 0.4240351915359497,\n",
              " 0.4238720238208771,\n",
              " 0.42352795600891113,\n",
              " 0.42386290431022644,\n",
              " 0.4235590100288391,\n",
              " 0.4230605661869049,\n",
              " 0.4231896996498108,\n",
              " 0.42259716987609863,\n",
              " 0.42316046357154846,\n",
              " 0.42286166548728943,\n",
              " 0.422562837600708,\n",
              " 0.4221201241016388,\n",
              " 0.42213186621665955,\n",
              " 0.4215978980064392,\n",
              " 0.42159873247146606,\n",
              " 0.4217807352542877,\n",
              " 0.4212072193622589,\n",
              " 0.42097344994544983,\n",
              " 0.42091041803359985,\n",
              " 0.4208090305328369,\n",
              " 0.42053455114364624,\n",
              " 0.42131689190864563,\n",
              " 0.41991284489631653,\n",
              " 0.41986221075057983,\n",
              " 0.41916537284851074,\n",
              " 0.4195309579372406,\n",
              " 0.41917508840560913,\n",
              " 0.41926705837249756,\n",
              " 0.41875630617141724,\n",
              " 0.418874055147171,\n",
              " 0.4186347723007202,\n",
              " 0.41840994358062744,\n",
              " 0.41820770502090454,\n",
              " 0.4180668294429779,\n",
              " 0.4176279604434967,\n",
              " 0.41767430305480957,\n",
              " 0.41744449734687805,\n",
              " 0.4172811508178711,\n",
              " 0.416835755109787,\n",
              " 0.4170624613761902,\n",
              " 0.41627949476242065,\n",
              " 0.4165787398815155,\n",
              " 0.41611358523368835,\n",
              " 0.4161013662815094,\n",
              " 0.41589540243148804,\n",
              " 0.41591840982437134,\n",
              " 0.4154120981693268,\n",
              " 0.4155046343803406,\n",
              " 0.41523510217666626,\n",
              " 0.41433942317962646,\n",
              " 0.414754718542099,\n",
              " 0.41406112909317017,\n",
              " 0.4141751229763031,\n",
              " 0.41437339782714844,\n",
              " 0.4134521186351776,\n",
              " 0.4135790169239044,\n",
              " 0.41285082697868347,\n",
              " 0.41299861669540405,\n",
              " 0.4124167859554291,\n",
              " 0.4120653569698334,\n",
              " 0.4127146899700165,\n",
              " 0.4118242859840393,\n",
              " 0.4119575321674347,\n",
              " 0.4117080867290497,\n",
              " 0.41133004426956177,\n",
              " 0.4117674231529236,\n",
              " 0.41051530838012695,\n",
              " 0.4108591079711914,\n",
              " 0.41070741415023804,\n",
              " 0.41055673360824585,\n",
              " 0.41022226214408875,\n",
              " 0.4103362262248993,\n",
              " 0.4093902111053467,\n",
              " 0.4097593426704407,\n",
              " 0.40899932384490967,\n",
              " 0.4091569781303406,\n",
              " 0.4088386297225952,\n",
              " 0.40863093733787537,\n",
              " 0.4085957705974579,\n",
              " 0.40797898173332214,\n",
              " 0.4080415964126587,\n",
              " 0.40737634897232056,\n",
              " 0.40800443291664124,\n",
              " 0.4070553481578827,\n",
              " 0.4066206216812134,\n",
              " 0.40687334537506104,\n",
              " 0.40649333596229553,\n",
              " 0.4072851538658142,\n",
              " 0.40645772218704224,\n",
              " 0.40593835711479187,\n",
              " 0.40638408064842224,\n",
              " 0.4061450958251953,\n",
              " 0.40503665804862976,\n",
              " 0.4058907926082611,\n",
              " 0.40490883588790894,\n",
              " 0.40535473823547363,\n",
              " 0.40486863255500793,\n",
              " 0.4045106768608093,\n",
              " 0.40424638986587524,\n",
              " 0.4046596586704254,\n",
              " 0.4041421115398407,\n",
              " 0.4040396511554718,\n",
              " 0.4032149612903595,\n",
              " 0.4042309522628784,\n",
              " 0.4033810496330261,\n",
              " 0.40309709310531616,\n",
              " 0.40339261293411255,\n",
              " 0.4031091630458832,\n",
              " 0.40341147780418396,\n",
              " 0.402919203042984,\n",
              " 0.4022115170955658,\n",
              " 0.40208250284194946,\n",
              " 0.40231242775917053,\n",
              " 0.40264710783958435,\n",
              " 0.402351438999176,\n",
              " 0.40138107538223267,\n",
              " 0.4010375738143921,\n",
              " 0.40126296877861023,\n",
              " 0.40118998289108276,\n",
              " 0.4013187885284424,\n",
              " 0.40124136209487915,\n",
              " 0.4006902873516083,\n",
              " 0.4014018476009369,\n",
              " 0.40074530243873596,\n",
              " 0.4006825387477875,\n",
              " 0.40023073554039,\n",
              " 0.39979130029678345,\n",
              " 0.40054991841316223,\n",
              " 0.4001273214817047,\n",
              " 0.40006765723228455,\n",
              " 0.3996255397796631,\n",
              " 0.3998691141605377,\n",
              " 0.3990587294101715,\n",
              " 0.39943233132362366,\n",
              " 0.3998371958732605,\n",
              " 0.39904722571372986,\n",
              " 0.39840513467788696,\n",
              " 0.40013253688812256,\n",
              " 0.39866307377815247,\n",
              " 0.3985083997249603,\n",
              " 0.3981342315673828,\n",
              " 0.3982597589492798,\n",
              " 0.39870449900627136,\n",
              " 0.3982726037502289,\n",
              " 0.39790135622024536,\n",
              " 0.39760127663612366,\n",
              " 0.39782989025115967,\n",
              " 0.3976270854473114]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aveWnQeCGvht",
        "outputId": "af3b00c2-f08c-4980-93c7-f743e19bfca8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model3 = Sequential([\n",
        "    Dense(8, input_shape=(10,), activation='relu'),\n",
        "    Dense(5, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model3.summary()\n",
        "model3.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "r3=model3.fit(X_train, y_train, epochs=500,validation_data=(X_test,y_test))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_20 (Dense)             (None, 8)                 88        \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 5)                 45        \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 1)                 6         \n",
            "=================================================================\n",
            "Total params: 139\n",
            "Trainable params: 139\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "13/13 [==============================] - 0s 12ms/step - loss: 0.7456 - accuracy: 0.4444 - val_loss: 0.7156 - val_accuracy: 0.4885\n",
            "Epoch 2/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7179 - accuracy: 0.4889 - val_loss: 0.6911 - val_accuracy: 0.5517\n",
            "Epoch 3/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6914 - accuracy: 0.5728 - val_loss: 0.6715 - val_accuracy: 0.5402\n",
            "Epoch 4/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6706 - accuracy: 0.6198 - val_loss: 0.6530 - val_accuracy: 0.5747\n",
            "Epoch 5/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6529 - accuracy: 0.6321 - val_loss: 0.6366 - val_accuracy: 0.6264\n",
            "Epoch 6/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6371 - accuracy: 0.6617 - val_loss: 0.6230 - val_accuracy: 0.6437\n",
            "Epoch 7/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6247 - accuracy: 0.6642 - val_loss: 0.6114 - val_accuracy: 0.6724\n",
            "Epoch 8/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6142 - accuracy: 0.6716 - val_loss: 0.6008 - val_accuracy: 0.6954\n",
            "Epoch 9/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6043 - accuracy: 0.6889 - val_loss: 0.5910 - val_accuracy: 0.7126\n",
            "Epoch 10/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5951 - accuracy: 0.7062 - val_loss: 0.5824 - val_accuracy: 0.7184\n",
            "Epoch 11/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5869 - accuracy: 0.7111 - val_loss: 0.5751 - val_accuracy: 0.7241\n",
            "Epoch 12/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5795 - accuracy: 0.7136 - val_loss: 0.5681 - val_accuracy: 0.7241\n",
            "Epoch 13/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5729 - accuracy: 0.7111 - val_loss: 0.5621 - val_accuracy: 0.7241\n",
            "Epoch 14/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5673 - accuracy: 0.7136 - val_loss: 0.5566 - val_accuracy: 0.7241\n",
            "Epoch 15/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5625 - accuracy: 0.7136 - val_loss: 0.5516 - val_accuracy: 0.7299\n",
            "Epoch 16/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5583 - accuracy: 0.7111 - val_loss: 0.5478 - val_accuracy: 0.7299\n",
            "Epoch 17/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5545 - accuracy: 0.7111 - val_loss: 0.5448 - val_accuracy: 0.7299\n",
            "Epoch 18/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5511 - accuracy: 0.7111 - val_loss: 0.5420 - val_accuracy: 0.7299\n",
            "Epoch 19/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5475 - accuracy: 0.7136 - val_loss: 0.5399 - val_accuracy: 0.7241\n",
            "Epoch 20/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5444 - accuracy: 0.7136 - val_loss: 0.5372 - val_accuracy: 0.7241\n",
            "Epoch 21/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5412 - accuracy: 0.7160 - val_loss: 0.5352 - val_accuracy: 0.7126\n",
            "Epoch 22/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5384 - accuracy: 0.7210 - val_loss: 0.5337 - val_accuracy: 0.7126\n",
            "Epoch 23/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5361 - accuracy: 0.7235 - val_loss: 0.5321 - val_accuracy: 0.7126\n",
            "Epoch 24/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5337 - accuracy: 0.7235 - val_loss: 0.5312 - val_accuracy: 0.7069\n",
            "Epoch 25/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5313 - accuracy: 0.7235 - val_loss: 0.5296 - val_accuracy: 0.7126\n",
            "Epoch 26/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5293 - accuracy: 0.7235 - val_loss: 0.5285 - val_accuracy: 0.7011\n",
            "Epoch 27/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5275 - accuracy: 0.7235 - val_loss: 0.5281 - val_accuracy: 0.7011\n",
            "Epoch 28/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5256 - accuracy: 0.7235 - val_loss: 0.5274 - val_accuracy: 0.7011\n",
            "Epoch 29/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5239 - accuracy: 0.7235 - val_loss: 0.5259 - val_accuracy: 0.7011\n",
            "Epoch 30/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5222 - accuracy: 0.7235 - val_loss: 0.5251 - val_accuracy: 0.7011\n",
            "Epoch 31/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5208 - accuracy: 0.7185 - val_loss: 0.5251 - val_accuracy: 0.7011\n",
            "Epoch 32/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5190 - accuracy: 0.7185 - val_loss: 0.5243 - val_accuracy: 0.7011\n",
            "Epoch 33/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5176 - accuracy: 0.7185 - val_loss: 0.5238 - val_accuracy: 0.7011\n",
            "Epoch 34/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5162 - accuracy: 0.7160 - val_loss: 0.5236 - val_accuracy: 0.7011\n",
            "Epoch 35/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5148 - accuracy: 0.7210 - val_loss: 0.5230 - val_accuracy: 0.7011\n",
            "Epoch 36/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5136 - accuracy: 0.7185 - val_loss: 0.5230 - val_accuracy: 0.6897\n",
            "Epoch 37/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5125 - accuracy: 0.7210 - val_loss: 0.5232 - val_accuracy: 0.7011\n",
            "Epoch 38/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5111 - accuracy: 0.7235 - val_loss: 0.5228 - val_accuracy: 0.6954\n",
            "Epoch 39/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5101 - accuracy: 0.7210 - val_loss: 0.5222 - val_accuracy: 0.6897\n",
            "Epoch 40/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5088 - accuracy: 0.7235 - val_loss: 0.5226 - val_accuracy: 0.6954\n",
            "Epoch 41/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5079 - accuracy: 0.7259 - val_loss: 0.5222 - val_accuracy: 0.6954\n",
            "Epoch 42/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5070 - accuracy: 0.7235 - val_loss: 0.5222 - val_accuracy: 0.7011\n",
            "Epoch 43/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5062 - accuracy: 0.7235 - val_loss: 0.5220 - val_accuracy: 0.7011\n",
            "Epoch 44/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.7259 - val_loss: 0.5218 - val_accuracy: 0.6954\n",
            "Epoch 45/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5043 - accuracy: 0.7210 - val_loss: 0.5217 - val_accuracy: 0.7011\n",
            "Epoch 46/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5035 - accuracy: 0.7210 - val_loss: 0.5216 - val_accuracy: 0.6954\n",
            "Epoch 47/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5028 - accuracy: 0.7210 - val_loss: 0.5213 - val_accuracy: 0.6954\n",
            "Epoch 48/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5018 - accuracy: 0.7160 - val_loss: 0.5208 - val_accuracy: 0.6897\n",
            "Epoch 49/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5013 - accuracy: 0.7210 - val_loss: 0.5207 - val_accuracy: 0.7011\n",
            "Epoch 50/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5001 - accuracy: 0.7235 - val_loss: 0.5203 - val_accuracy: 0.7011\n",
            "Epoch 51/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4994 - accuracy: 0.7259 - val_loss: 0.5198 - val_accuracy: 0.7011\n",
            "Epoch 52/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4985 - accuracy: 0.7259 - val_loss: 0.5194 - val_accuracy: 0.6954\n",
            "Epoch 53/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4979 - accuracy: 0.7284 - val_loss: 0.5194 - val_accuracy: 0.7069\n",
            "Epoch 54/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4969 - accuracy: 0.7259 - val_loss: 0.5186 - val_accuracy: 0.6954\n",
            "Epoch 55/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4960 - accuracy: 0.7259 - val_loss: 0.5188 - val_accuracy: 0.6897\n",
            "Epoch 56/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4954 - accuracy: 0.7284 - val_loss: 0.5188 - val_accuracy: 0.6954\n",
            "Epoch 57/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4946 - accuracy: 0.7284 - val_loss: 0.5185 - val_accuracy: 0.7011\n",
            "Epoch 58/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4939 - accuracy: 0.7284 - val_loss: 0.5186 - val_accuracy: 0.7011\n",
            "Epoch 59/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4930 - accuracy: 0.7309 - val_loss: 0.5189 - val_accuracy: 0.7011\n",
            "Epoch 60/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4928 - accuracy: 0.7309 - val_loss: 0.5189 - val_accuracy: 0.7126\n",
            "Epoch 61/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4916 - accuracy: 0.7309 - val_loss: 0.5191 - val_accuracy: 0.7126\n",
            "Epoch 62/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4912 - accuracy: 0.7333 - val_loss: 0.5193 - val_accuracy: 0.7011\n",
            "Epoch 63/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4905 - accuracy: 0.7333 - val_loss: 0.5190 - val_accuracy: 0.7011\n",
            "Epoch 64/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4898 - accuracy: 0.7358 - val_loss: 0.5189 - val_accuracy: 0.6954\n",
            "Epoch 65/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4895 - accuracy: 0.7481 - val_loss: 0.5198 - val_accuracy: 0.6954\n",
            "Epoch 66/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4885 - accuracy: 0.7531 - val_loss: 0.5198 - val_accuracy: 0.6897\n",
            "Epoch 67/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4879 - accuracy: 0.7506 - val_loss: 0.5199 - val_accuracy: 0.6954\n",
            "Epoch 68/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4868 - accuracy: 0.7506 - val_loss: 0.5199 - val_accuracy: 0.7011\n",
            "Epoch 69/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4864 - accuracy: 0.7457 - val_loss: 0.5207 - val_accuracy: 0.7069\n",
            "Epoch 70/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4859 - accuracy: 0.7457 - val_loss: 0.5206 - val_accuracy: 0.7069\n",
            "Epoch 71/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4855 - accuracy: 0.7506 - val_loss: 0.5214 - val_accuracy: 0.7011\n",
            "Epoch 72/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4846 - accuracy: 0.7531 - val_loss: 0.5216 - val_accuracy: 0.7011\n",
            "Epoch 73/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7506 - val_loss: 0.5213 - val_accuracy: 0.6954\n",
            "Epoch 74/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4834 - accuracy: 0.7506 - val_loss: 0.5218 - val_accuracy: 0.7069\n",
            "Epoch 75/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4832 - accuracy: 0.7531 - val_loss: 0.5224 - val_accuracy: 0.7069\n",
            "Epoch 76/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4822 - accuracy: 0.7506 - val_loss: 0.5220 - val_accuracy: 0.7011\n",
            "Epoch 77/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4816 - accuracy: 0.7506 - val_loss: 0.5224 - val_accuracy: 0.7069\n",
            "Epoch 78/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4813 - accuracy: 0.7481 - val_loss: 0.5223 - val_accuracy: 0.7069\n",
            "Epoch 79/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4806 - accuracy: 0.7506 - val_loss: 0.5228 - val_accuracy: 0.7069\n",
            "Epoch 80/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4802 - accuracy: 0.7481 - val_loss: 0.5239 - val_accuracy: 0.7126\n",
            "Epoch 81/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4794 - accuracy: 0.7481 - val_loss: 0.5234 - val_accuracy: 0.7069\n",
            "Epoch 82/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4791 - accuracy: 0.7506 - val_loss: 0.5233 - val_accuracy: 0.7011\n",
            "Epoch 83/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4782 - accuracy: 0.7531 - val_loss: 0.5242 - val_accuracy: 0.7126\n",
            "Epoch 84/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4778 - accuracy: 0.7531 - val_loss: 0.5245 - val_accuracy: 0.7126\n",
            "Epoch 85/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4773 - accuracy: 0.7531 - val_loss: 0.5244 - val_accuracy: 0.7126\n",
            "Epoch 86/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4770 - accuracy: 0.7457 - val_loss: 0.5257 - val_accuracy: 0.7011\n",
            "Epoch 87/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4765 - accuracy: 0.7481 - val_loss: 0.5265 - val_accuracy: 0.7011\n",
            "Epoch 88/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4755 - accuracy: 0.7506 - val_loss: 0.5254 - val_accuracy: 0.7011\n",
            "Epoch 89/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4750 - accuracy: 0.7481 - val_loss: 0.5254 - val_accuracy: 0.6954\n",
            "Epoch 90/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4747 - accuracy: 0.7481 - val_loss: 0.5258 - val_accuracy: 0.6954\n",
            "Epoch 91/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4740 - accuracy: 0.7481 - val_loss: 0.5263 - val_accuracy: 0.6954\n",
            "Epoch 92/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4734 - accuracy: 0.7580 - val_loss: 0.5272 - val_accuracy: 0.7011\n",
            "Epoch 93/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4730 - accuracy: 0.7654 - val_loss: 0.5264 - val_accuracy: 0.6839\n",
            "Epoch 94/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4721 - accuracy: 0.7630 - val_loss: 0.5276 - val_accuracy: 0.6954\n",
            "Epoch 95/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4716 - accuracy: 0.7605 - val_loss: 0.5275 - val_accuracy: 0.6897\n",
            "Epoch 96/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4712 - accuracy: 0.7580 - val_loss: 0.5278 - val_accuracy: 0.6897\n",
            "Epoch 97/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4708 - accuracy: 0.7605 - val_loss: 0.5281 - val_accuracy: 0.6839\n",
            "Epoch 98/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4702 - accuracy: 0.7556 - val_loss: 0.5294 - val_accuracy: 0.6839\n",
            "Epoch 99/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4700 - accuracy: 0.7556 - val_loss: 0.5297 - val_accuracy: 0.6782\n",
            "Epoch 100/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4694 - accuracy: 0.7630 - val_loss: 0.5291 - val_accuracy: 0.6782\n",
            "Epoch 101/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4688 - accuracy: 0.7580 - val_loss: 0.5294 - val_accuracy: 0.6839\n",
            "Epoch 102/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4684 - accuracy: 0.7630 - val_loss: 0.5311 - val_accuracy: 0.6839\n",
            "Epoch 103/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4681 - accuracy: 0.7556 - val_loss: 0.5307 - val_accuracy: 0.6782\n",
            "Epoch 104/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4673 - accuracy: 0.7531 - val_loss: 0.5311 - val_accuracy: 0.6782\n",
            "Epoch 105/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4675 - accuracy: 0.7605 - val_loss: 0.5325 - val_accuracy: 0.6839\n",
            "Epoch 106/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4670 - accuracy: 0.7580 - val_loss: 0.5320 - val_accuracy: 0.6782\n",
            "Epoch 107/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4663 - accuracy: 0.7630 - val_loss: 0.5332 - val_accuracy: 0.6839\n",
            "Epoch 108/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4660 - accuracy: 0.7556 - val_loss: 0.5339 - val_accuracy: 0.6782\n",
            "Epoch 109/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4656 - accuracy: 0.7605 - val_loss: 0.5339 - val_accuracy: 0.6724\n",
            "Epoch 110/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4652 - accuracy: 0.7605 - val_loss: 0.5342 - val_accuracy: 0.6782\n",
            "Epoch 111/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4653 - accuracy: 0.7630 - val_loss: 0.5341 - val_accuracy: 0.6782\n",
            "Epoch 112/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4647 - accuracy: 0.7630 - val_loss: 0.5350 - val_accuracy: 0.6724\n",
            "Epoch 113/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4644 - accuracy: 0.7630 - val_loss: 0.5348 - val_accuracy: 0.6782\n",
            "Epoch 114/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4640 - accuracy: 0.7605 - val_loss: 0.5377 - val_accuracy: 0.6897\n",
            "Epoch 115/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4637 - accuracy: 0.7605 - val_loss: 0.5364 - val_accuracy: 0.6782\n",
            "Epoch 116/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4640 - accuracy: 0.7556 - val_loss: 0.5382 - val_accuracy: 0.6897\n",
            "Epoch 117/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4634 - accuracy: 0.7605 - val_loss: 0.5358 - val_accuracy: 0.6782\n",
            "Epoch 118/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4631 - accuracy: 0.7580 - val_loss: 0.5373 - val_accuracy: 0.6782\n",
            "Epoch 119/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.7580 - val_loss: 0.5382 - val_accuracy: 0.6782\n",
            "Epoch 120/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4621 - accuracy: 0.7630 - val_loss: 0.5377 - val_accuracy: 0.6782\n",
            "Epoch 121/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.7654 - val_loss: 0.5379 - val_accuracy: 0.6782\n",
            "Epoch 122/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4620 - accuracy: 0.7556 - val_loss: 0.5400 - val_accuracy: 0.6839\n",
            "Epoch 123/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.7605 - val_loss: 0.5383 - val_accuracy: 0.6782\n",
            "Epoch 124/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4608 - accuracy: 0.7654 - val_loss: 0.5388 - val_accuracy: 0.6782\n",
            "Epoch 125/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.7630 - val_loss: 0.5407 - val_accuracy: 0.6782\n",
            "Epoch 126/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.7630 - val_loss: 0.5402 - val_accuracy: 0.6782\n",
            "Epoch 127/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7630 - val_loss: 0.5407 - val_accuracy: 0.6782\n",
            "Epoch 128/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7630 - val_loss: 0.5410 - val_accuracy: 0.6782\n",
            "Epoch 129/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.7654 - val_loss: 0.5409 - val_accuracy: 0.6782\n",
            "Epoch 130/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7630 - val_loss: 0.5413 - val_accuracy: 0.6782\n",
            "Epoch 131/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7654 - val_loss: 0.5412 - val_accuracy: 0.6782\n",
            "Epoch 132/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4583 - accuracy: 0.7679 - val_loss: 0.5407 - val_accuracy: 0.6782\n",
            "Epoch 133/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7654 - val_loss: 0.5416 - val_accuracy: 0.6782\n",
            "Epoch 134/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.4580 - accuracy: 0.7654 - val_loss: 0.5424 - val_accuracy: 0.6782\n",
            "Epoch 135/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7679 - val_loss: 0.5405 - val_accuracy: 0.6782\n",
            "Epoch 136/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.7679 - val_loss: 0.5421 - val_accuracy: 0.6782\n",
            "Epoch 137/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4570 - accuracy: 0.7679 - val_loss: 0.5432 - val_accuracy: 0.6782\n",
            "Epoch 138/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4566 - accuracy: 0.7654 - val_loss: 0.5433 - val_accuracy: 0.6782\n",
            "Epoch 139/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4567 - accuracy: 0.7679 - val_loss: 0.5414 - val_accuracy: 0.6782\n",
            "Epoch 140/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4564 - accuracy: 0.7654 - val_loss: 0.5418 - val_accuracy: 0.6782\n",
            "Epoch 141/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4557 - accuracy: 0.7654 - val_loss: 0.5430 - val_accuracy: 0.6782\n",
            "Epoch 142/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4562 - accuracy: 0.7605 - val_loss: 0.5448 - val_accuracy: 0.6782\n",
            "Epoch 143/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4558 - accuracy: 0.7630 - val_loss: 0.5423 - val_accuracy: 0.6782\n",
            "Epoch 144/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4549 - accuracy: 0.7679 - val_loss: 0.5431 - val_accuracy: 0.6782\n",
            "Epoch 145/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4546 - accuracy: 0.7679 - val_loss: 0.5443 - val_accuracy: 0.6782\n",
            "Epoch 146/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4544 - accuracy: 0.7679 - val_loss: 0.5434 - val_accuracy: 0.6782\n",
            "Epoch 147/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4544 - accuracy: 0.7679 - val_loss: 0.5427 - val_accuracy: 0.6782\n",
            "Epoch 148/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4539 - accuracy: 0.7654 - val_loss: 0.5445 - val_accuracy: 0.6782\n",
            "Epoch 149/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4536 - accuracy: 0.7679 - val_loss: 0.5439 - val_accuracy: 0.6782\n",
            "Epoch 150/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4536 - accuracy: 0.7654 - val_loss: 0.5440 - val_accuracy: 0.6724\n",
            "Epoch 151/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4533 - accuracy: 0.7630 - val_loss: 0.5448 - val_accuracy: 0.6782\n",
            "Epoch 152/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4525 - accuracy: 0.7654 - val_loss: 0.5439 - val_accuracy: 0.6782\n",
            "Epoch 153/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4523 - accuracy: 0.7654 - val_loss: 0.5440 - val_accuracy: 0.6724\n",
            "Epoch 154/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4520 - accuracy: 0.7630 - val_loss: 0.5431 - val_accuracy: 0.6782\n",
            "Epoch 155/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4520 - accuracy: 0.7605 - val_loss: 0.5450 - val_accuracy: 0.6782\n",
            "Epoch 156/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4520 - accuracy: 0.7630 - val_loss: 0.5437 - val_accuracy: 0.6724\n",
            "Epoch 157/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4516 - accuracy: 0.7679 - val_loss: 0.5445 - val_accuracy: 0.6782\n",
            "Epoch 158/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.7654 - val_loss: 0.5448 - val_accuracy: 0.6782\n",
            "Epoch 159/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.7654 - val_loss: 0.5437 - val_accuracy: 0.6724\n",
            "Epoch 160/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4508 - accuracy: 0.7605 - val_loss: 0.5440 - val_accuracy: 0.6724\n",
            "Epoch 161/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4503 - accuracy: 0.7605 - val_loss: 0.5442 - val_accuracy: 0.6724\n",
            "Epoch 162/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4503 - accuracy: 0.7654 - val_loss: 0.5434 - val_accuracy: 0.6724\n",
            "Epoch 163/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.7630 - val_loss: 0.5458 - val_accuracy: 0.6782\n",
            "Epoch 164/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.7679 - val_loss: 0.5462 - val_accuracy: 0.6724\n",
            "Epoch 165/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.7654 - val_loss: 0.5448 - val_accuracy: 0.6724\n",
            "Epoch 166/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.7605 - val_loss: 0.5437 - val_accuracy: 0.6724\n",
            "Epoch 167/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.7605 - val_loss: 0.5450 - val_accuracy: 0.6724\n",
            "Epoch 168/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.7630 - val_loss: 0.5455 - val_accuracy: 0.6724\n",
            "Epoch 169/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.7630 - val_loss: 0.5450 - val_accuracy: 0.6724\n",
            "Epoch 170/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.7630 - val_loss: 0.5456 - val_accuracy: 0.6724\n",
            "Epoch 171/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.7630 - val_loss: 0.5455 - val_accuracy: 0.6724\n",
            "Epoch 172/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4474 - accuracy: 0.7580 - val_loss: 0.5457 - val_accuracy: 0.6724\n",
            "Epoch 173/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.7630 - val_loss: 0.5439 - val_accuracy: 0.6724\n",
            "Epoch 174/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.7630 - val_loss: 0.5471 - val_accuracy: 0.6724\n",
            "Epoch 175/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4466 - accuracy: 0.7580 - val_loss: 0.5450 - val_accuracy: 0.6724\n",
            "Epoch 176/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.7605 - val_loss: 0.5453 - val_accuracy: 0.6724\n",
            "Epoch 177/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4462 - accuracy: 0.7580 - val_loss: 0.5459 - val_accuracy: 0.6724\n",
            "Epoch 178/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.7580 - val_loss: 0.5467 - val_accuracy: 0.6724\n",
            "Epoch 179/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4460 - accuracy: 0.7605 - val_loss: 0.5465 - val_accuracy: 0.6724\n",
            "Epoch 180/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.7580 - val_loss: 0.5472 - val_accuracy: 0.6724\n",
            "Epoch 181/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.7605 - val_loss: 0.5465 - val_accuracy: 0.6724\n",
            "Epoch 182/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.7580 - val_loss: 0.5455 - val_accuracy: 0.6724\n",
            "Epoch 183/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4445 - accuracy: 0.7605 - val_loss: 0.5474 - val_accuracy: 0.6724\n",
            "Epoch 184/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4443 - accuracy: 0.7580 - val_loss: 0.5475 - val_accuracy: 0.6724\n",
            "Epoch 185/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4444 - accuracy: 0.7556 - val_loss: 0.5446 - val_accuracy: 0.6724\n",
            "Epoch 186/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.7580 - val_loss: 0.5477 - val_accuracy: 0.6724\n",
            "Epoch 187/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.7605 - val_loss: 0.5473 - val_accuracy: 0.6724\n",
            "Epoch 188/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.7630 - val_loss: 0.5468 - val_accuracy: 0.6724\n",
            "Epoch 189/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.7605 - val_loss: 0.5470 - val_accuracy: 0.6724\n",
            "Epoch 190/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.7654 - val_loss: 0.5479 - val_accuracy: 0.6724\n",
            "Epoch 191/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4422 - accuracy: 0.7605 - val_loss: 0.5473 - val_accuracy: 0.6724\n",
            "Epoch 192/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4420 - accuracy: 0.7605 - val_loss: 0.5489 - val_accuracy: 0.6724\n",
            "Epoch 193/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.7605 - val_loss: 0.5472 - val_accuracy: 0.6724\n",
            "Epoch 194/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4416 - accuracy: 0.7630 - val_loss: 0.5490 - val_accuracy: 0.6724\n",
            "Epoch 195/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4412 - accuracy: 0.7679 - val_loss: 0.5473 - val_accuracy: 0.6724\n",
            "Epoch 196/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4412 - accuracy: 0.7630 - val_loss: 0.5478 - val_accuracy: 0.6724\n",
            "Epoch 197/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4410 - accuracy: 0.7605 - val_loss: 0.5491 - val_accuracy: 0.6724\n",
            "Epoch 198/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4405 - accuracy: 0.7605 - val_loss: 0.5487 - val_accuracy: 0.6724\n",
            "Epoch 199/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.7605 - val_loss: 0.5476 - val_accuracy: 0.6724\n",
            "Epoch 200/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.7580 - val_loss: 0.5506 - val_accuracy: 0.6667\n",
            "Epoch 201/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.7630 - val_loss: 0.5483 - val_accuracy: 0.6724\n",
            "Epoch 202/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4401 - accuracy: 0.7605 - val_loss: 0.5453 - val_accuracy: 0.6724\n",
            "Epoch 203/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.7630 - val_loss: 0.5478 - val_accuracy: 0.6724\n",
            "Epoch 204/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.7580 - val_loss: 0.5482 - val_accuracy: 0.6724\n",
            "Epoch 205/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4390 - accuracy: 0.7605 - val_loss: 0.5491 - val_accuracy: 0.6724\n",
            "Epoch 206/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4388 - accuracy: 0.7654 - val_loss: 0.5491 - val_accuracy: 0.6724\n",
            "Epoch 207/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.7605 - val_loss: 0.5498 - val_accuracy: 0.6667\n",
            "Epoch 208/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.7654 - val_loss: 0.5509 - val_accuracy: 0.6667\n",
            "Epoch 209/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.7630 - val_loss: 0.5503 - val_accuracy: 0.6667\n",
            "Epoch 210/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4376 - accuracy: 0.7630 - val_loss: 0.5486 - val_accuracy: 0.6724\n",
            "Epoch 211/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4378 - accuracy: 0.7630 - val_loss: 0.5474 - val_accuracy: 0.6724\n",
            "Epoch 212/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4376 - accuracy: 0.7630 - val_loss: 0.5486 - val_accuracy: 0.6724\n",
            "Epoch 213/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.7630 - val_loss: 0.5501 - val_accuracy: 0.6667\n",
            "Epoch 214/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.7605 - val_loss: 0.5482 - val_accuracy: 0.6724\n",
            "Epoch 215/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.7580 - val_loss: 0.5489 - val_accuracy: 0.6724\n",
            "Epoch 216/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4367 - accuracy: 0.7630 - val_loss: 0.5455 - val_accuracy: 0.6724\n",
            "Epoch 217/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4358 - accuracy: 0.7630 - val_loss: 0.5472 - val_accuracy: 0.6667\n",
            "Epoch 218/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.7630 - val_loss: 0.5487 - val_accuracy: 0.6724\n",
            "Epoch 219/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7679 - val_loss: 0.5486 - val_accuracy: 0.6667\n",
            "Epoch 220/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7654 - val_loss: 0.5498 - val_accuracy: 0.6667\n",
            "Epoch 221/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.7630 - val_loss: 0.5484 - val_accuracy: 0.6609\n",
            "Epoch 222/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4344 - accuracy: 0.7605 - val_loss: 0.5476 - val_accuracy: 0.6667\n",
            "Epoch 223/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4349 - accuracy: 0.7630 - val_loss: 0.5503 - val_accuracy: 0.6609\n",
            "Epoch 224/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4339 - accuracy: 0.7654 - val_loss: 0.5487 - val_accuracy: 0.6667\n",
            "Epoch 225/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.7654 - val_loss: 0.5489 - val_accuracy: 0.6667\n",
            "Epoch 226/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4345 - accuracy: 0.7679 - val_loss: 0.5481 - val_accuracy: 0.6609\n",
            "Epoch 227/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4334 - accuracy: 0.7654 - val_loss: 0.5477 - val_accuracy: 0.6609\n",
            "Epoch 228/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4328 - accuracy: 0.7654 - val_loss: 0.5477 - val_accuracy: 0.6609\n",
            "Epoch 229/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4331 - accuracy: 0.7654 - val_loss: 0.5483 - val_accuracy: 0.6609\n",
            "Epoch 230/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4326 - accuracy: 0.7654 - val_loss: 0.5475 - val_accuracy: 0.6609\n",
            "Epoch 231/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.7630 - val_loss: 0.5482 - val_accuracy: 0.6609\n",
            "Epoch 232/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4319 - accuracy: 0.7630 - val_loss: 0.5496 - val_accuracy: 0.6609\n",
            "Epoch 233/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4319 - accuracy: 0.7630 - val_loss: 0.5495 - val_accuracy: 0.6609\n",
            "Epoch 234/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4318 - accuracy: 0.7654 - val_loss: 0.5498 - val_accuracy: 0.6609\n",
            "Epoch 235/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4318 - accuracy: 0.7654 - val_loss: 0.5485 - val_accuracy: 0.6609\n",
            "Epoch 236/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4311 - accuracy: 0.7679 - val_loss: 0.5490 - val_accuracy: 0.6609\n",
            "Epoch 237/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.7630 - val_loss: 0.5492 - val_accuracy: 0.6609\n",
            "Epoch 238/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4313 - accuracy: 0.7630 - val_loss: 0.5504 - val_accuracy: 0.6609\n",
            "Epoch 239/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4305 - accuracy: 0.7679 - val_loss: 0.5502 - val_accuracy: 0.6609\n",
            "Epoch 240/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.7630 - val_loss: 0.5484 - val_accuracy: 0.6609\n",
            "Epoch 241/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4302 - accuracy: 0.7630 - val_loss: 0.5489 - val_accuracy: 0.6609\n",
            "Epoch 242/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4299 - accuracy: 0.7654 - val_loss: 0.5495 - val_accuracy: 0.6609\n",
            "Epoch 243/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.7630 - val_loss: 0.5509 - val_accuracy: 0.6609\n",
            "Epoch 244/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4295 - accuracy: 0.7630 - val_loss: 0.5508 - val_accuracy: 0.6609\n",
            "Epoch 245/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4293 - accuracy: 0.7679 - val_loss: 0.5511 - val_accuracy: 0.6609\n",
            "Epoch 246/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4295 - accuracy: 0.7654 - val_loss: 0.5485 - val_accuracy: 0.6609\n",
            "Epoch 247/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4287 - accuracy: 0.7704 - val_loss: 0.5490 - val_accuracy: 0.6609\n",
            "Epoch 248/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4286 - accuracy: 0.7654 - val_loss: 0.5490 - val_accuracy: 0.6609\n",
            "Epoch 249/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.7679 - val_loss: 0.5488 - val_accuracy: 0.6609\n",
            "Epoch 250/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.7654 - val_loss: 0.5498 - val_accuracy: 0.6609\n",
            "Epoch 251/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.7654 - val_loss: 0.5504 - val_accuracy: 0.6667\n",
            "Epoch 252/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4275 - accuracy: 0.7630 - val_loss: 0.5504 - val_accuracy: 0.6667\n",
            "Epoch 253/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4281 - accuracy: 0.7679 - val_loss: 0.5512 - val_accuracy: 0.6667\n",
            "Epoch 254/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4272 - accuracy: 0.7630 - val_loss: 0.5480 - val_accuracy: 0.6667\n",
            "Epoch 255/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4271 - accuracy: 0.7679 - val_loss: 0.5502 - val_accuracy: 0.6667\n",
            "Epoch 256/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.4267 - accuracy: 0.7679 - val_loss: 0.5483 - val_accuracy: 0.6667\n",
            "Epoch 257/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4264 - accuracy: 0.7630 - val_loss: 0.5500 - val_accuracy: 0.6667\n",
            "Epoch 258/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4274 - accuracy: 0.7630 - val_loss: 0.5499 - val_accuracy: 0.6667\n",
            "Epoch 259/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4261 - accuracy: 0.7630 - val_loss: 0.5534 - val_accuracy: 0.6609\n",
            "Epoch 260/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4263 - accuracy: 0.7679 - val_loss: 0.5547 - val_accuracy: 0.6609\n",
            "Epoch 261/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4259 - accuracy: 0.7679 - val_loss: 0.5494 - val_accuracy: 0.6667\n",
            "Epoch 262/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4261 - accuracy: 0.7630 - val_loss: 0.5506 - val_accuracy: 0.6667\n",
            "Epoch 263/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4253 - accuracy: 0.7630 - val_loss: 0.5514 - val_accuracy: 0.6667\n",
            "Epoch 264/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.7654 - val_loss: 0.5522 - val_accuracy: 0.6667\n",
            "Epoch 265/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4256 - accuracy: 0.7679 - val_loss: 0.5511 - val_accuracy: 0.6667\n",
            "Epoch 266/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4252 - accuracy: 0.7654 - val_loss: 0.5545 - val_accuracy: 0.6667\n",
            "Epoch 267/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4248 - accuracy: 0.7630 - val_loss: 0.5510 - val_accuracy: 0.6667\n",
            "Epoch 268/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.7630 - val_loss: 0.5524 - val_accuracy: 0.6667\n",
            "Epoch 269/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4244 - accuracy: 0.7605 - val_loss: 0.5533 - val_accuracy: 0.6667\n",
            "Epoch 270/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.7654 - val_loss: 0.5514 - val_accuracy: 0.6667\n",
            "Epoch 271/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4241 - accuracy: 0.7654 - val_loss: 0.5525 - val_accuracy: 0.6667\n",
            "Epoch 272/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4238 - accuracy: 0.7630 - val_loss: 0.5531 - val_accuracy: 0.6667\n",
            "Epoch 273/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4243 - accuracy: 0.7605 - val_loss: 0.5538 - val_accuracy: 0.6667\n",
            "Epoch 274/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4233 - accuracy: 0.7654 - val_loss: 0.5537 - val_accuracy: 0.6667\n",
            "Epoch 275/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.7605 - val_loss: 0.5522 - val_accuracy: 0.6667\n",
            "Epoch 276/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4237 - accuracy: 0.7630 - val_loss: 0.5551 - val_accuracy: 0.6667\n",
            "Epoch 277/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4226 - accuracy: 0.7630 - val_loss: 0.5537 - val_accuracy: 0.6667\n",
            "Epoch 278/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4230 - accuracy: 0.7630 - val_loss: 0.5542 - val_accuracy: 0.6667\n",
            "Epoch 279/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4226 - accuracy: 0.7654 - val_loss: 0.5544 - val_accuracy: 0.6667\n",
            "Epoch 280/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.7654 - val_loss: 0.5552 - val_accuracy: 0.6667\n",
            "Epoch 281/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.7630 - val_loss: 0.5544 - val_accuracy: 0.6667\n",
            "Epoch 282/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.7605 - val_loss: 0.5546 - val_accuracy: 0.6667\n",
            "Epoch 283/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.7605 - val_loss: 0.5565 - val_accuracy: 0.6667\n",
            "Epoch 284/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.7654 - val_loss: 0.5548 - val_accuracy: 0.6667\n",
            "Epoch 285/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4214 - accuracy: 0.7630 - val_loss: 0.5540 - val_accuracy: 0.6667\n",
            "Epoch 286/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.7630 - val_loss: 0.5540 - val_accuracy: 0.6667\n",
            "Epoch 287/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.7630 - val_loss: 0.5556 - val_accuracy: 0.6667\n",
            "Epoch 288/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4214 - accuracy: 0.7630 - val_loss: 0.5567 - val_accuracy: 0.6667\n",
            "Epoch 289/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4211 - accuracy: 0.7630 - val_loss: 0.5568 - val_accuracy: 0.6667\n",
            "Epoch 290/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4218 - accuracy: 0.7605 - val_loss: 0.5559 - val_accuracy: 0.6667\n",
            "Epoch 291/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4214 - accuracy: 0.7605 - val_loss: 0.5536 - val_accuracy: 0.6667\n",
            "Epoch 292/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.7630 - val_loss: 0.5579 - val_accuracy: 0.6609\n",
            "Epoch 293/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4214 - accuracy: 0.7630 - val_loss: 0.5580 - val_accuracy: 0.6667\n",
            "Epoch 294/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.7605 - val_loss: 0.5544 - val_accuracy: 0.6667\n",
            "Epoch 295/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.7654 - val_loss: 0.5566 - val_accuracy: 0.6667\n",
            "Epoch 296/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4203 - accuracy: 0.7630 - val_loss: 0.5551 - val_accuracy: 0.6724\n",
            "Epoch 297/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.7630 - val_loss: 0.5566 - val_accuracy: 0.6667\n",
            "Epoch 298/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.7580 - val_loss: 0.5582 - val_accuracy: 0.6667\n",
            "Epoch 299/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4192 - accuracy: 0.7605 - val_loss: 0.5562 - val_accuracy: 0.6667\n",
            "Epoch 300/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4194 - accuracy: 0.7580 - val_loss: 0.5563 - val_accuracy: 0.6667\n",
            "Epoch 301/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4197 - accuracy: 0.7654 - val_loss: 0.5561 - val_accuracy: 0.6667\n",
            "Epoch 302/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.7654 - val_loss: 0.5560 - val_accuracy: 0.6724\n",
            "Epoch 303/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4187 - accuracy: 0.7630 - val_loss: 0.5591 - val_accuracy: 0.6609\n",
            "Epoch 304/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.7605 - val_loss: 0.5591 - val_accuracy: 0.6609\n",
            "Epoch 305/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4188 - accuracy: 0.7605 - val_loss: 0.5587 - val_accuracy: 0.6609\n",
            "Epoch 306/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4181 - accuracy: 0.7630 - val_loss: 0.5561 - val_accuracy: 0.6724\n",
            "Epoch 307/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4190 - accuracy: 0.7679 - val_loss: 0.5556 - val_accuracy: 0.6724\n",
            "Epoch 308/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4178 - accuracy: 0.7654 - val_loss: 0.5583 - val_accuracy: 0.6609\n",
            "Epoch 309/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4186 - accuracy: 0.7630 - val_loss: 0.5587 - val_accuracy: 0.6609\n",
            "Epoch 310/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4187 - accuracy: 0.7654 - val_loss: 0.5598 - val_accuracy: 0.6724\n",
            "Epoch 311/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4183 - accuracy: 0.7654 - val_loss: 0.5597 - val_accuracy: 0.6609\n",
            "Epoch 312/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4177 - accuracy: 0.7630 - val_loss: 0.5604 - val_accuracy: 0.6609\n",
            "Epoch 313/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4182 - accuracy: 0.7630 - val_loss: 0.5572 - val_accuracy: 0.6724\n",
            "Epoch 314/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4176 - accuracy: 0.7679 - val_loss: 0.5606 - val_accuracy: 0.6552\n",
            "Epoch 315/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4178 - accuracy: 0.7654 - val_loss: 0.5586 - val_accuracy: 0.6724\n",
            "Epoch 316/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4174 - accuracy: 0.7654 - val_loss: 0.5611 - val_accuracy: 0.6552\n",
            "Epoch 317/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4169 - accuracy: 0.7605 - val_loss: 0.5602 - val_accuracy: 0.6609\n",
            "Epoch 318/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4169 - accuracy: 0.7630 - val_loss: 0.5613 - val_accuracy: 0.6609\n",
            "Epoch 319/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.4166 - accuracy: 0.7605 - val_loss: 0.5614 - val_accuracy: 0.6609\n",
            "Epoch 320/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4170 - accuracy: 0.7630 - val_loss: 0.5616 - val_accuracy: 0.6494\n",
            "Epoch 321/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4165 - accuracy: 0.7605 - val_loss: 0.5605 - val_accuracy: 0.6667\n",
            "Epoch 322/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4172 - accuracy: 0.7630 - val_loss: 0.5633 - val_accuracy: 0.6609\n",
            "Epoch 323/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4160 - accuracy: 0.7630 - val_loss: 0.5623 - val_accuracy: 0.6609\n",
            "Epoch 324/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4160 - accuracy: 0.7654 - val_loss: 0.5609 - val_accuracy: 0.6667\n",
            "Epoch 325/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4161 - accuracy: 0.7630 - val_loss: 0.5609 - val_accuracy: 0.6609\n",
            "Epoch 326/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4156 - accuracy: 0.7654 - val_loss: 0.5623 - val_accuracy: 0.6609\n",
            "Epoch 327/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4156 - accuracy: 0.7630 - val_loss: 0.5628 - val_accuracy: 0.6494\n",
            "Epoch 328/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4153 - accuracy: 0.7654 - val_loss: 0.5634 - val_accuracy: 0.6494\n",
            "Epoch 329/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4150 - accuracy: 0.7630 - val_loss: 0.5616 - val_accuracy: 0.6552\n",
            "Epoch 330/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4152 - accuracy: 0.7630 - val_loss: 0.5620 - val_accuracy: 0.6552\n",
            "Epoch 331/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4155 - accuracy: 0.7704 - val_loss: 0.5631 - val_accuracy: 0.6609\n",
            "Epoch 332/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4151 - accuracy: 0.7630 - val_loss: 0.5633 - val_accuracy: 0.6494\n",
            "Epoch 333/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4148 - accuracy: 0.7654 - val_loss: 0.5630 - val_accuracy: 0.6552\n",
            "Epoch 334/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.4147 - accuracy: 0.7679 - val_loss: 0.5619 - val_accuracy: 0.6609\n",
            "Epoch 335/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4147 - accuracy: 0.7605 - val_loss: 0.5642 - val_accuracy: 0.6494\n",
            "Epoch 336/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4147 - accuracy: 0.7654 - val_loss: 0.5629 - val_accuracy: 0.6552\n",
            "Epoch 337/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.4144 - accuracy: 0.7654 - val_loss: 0.5624 - val_accuracy: 0.6552\n",
            "Epoch 338/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4138 - accuracy: 0.7679 - val_loss: 0.5641 - val_accuracy: 0.6609\n",
            "Epoch 339/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4138 - accuracy: 0.7654 - val_loss: 0.5656 - val_accuracy: 0.6552\n",
            "Epoch 340/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4139 - accuracy: 0.7679 - val_loss: 0.5628 - val_accuracy: 0.6667\n",
            "Epoch 341/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4138 - accuracy: 0.7654 - val_loss: 0.5659 - val_accuracy: 0.6494\n",
            "Epoch 342/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4138 - accuracy: 0.7654 - val_loss: 0.5665 - val_accuracy: 0.6494\n",
            "Epoch 343/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4142 - accuracy: 0.7630 - val_loss: 0.5635 - val_accuracy: 0.6724\n",
            "Epoch 344/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4133 - accuracy: 0.7605 - val_loss: 0.5653 - val_accuracy: 0.6494\n",
            "Epoch 345/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4134 - accuracy: 0.7580 - val_loss: 0.5668 - val_accuracy: 0.6494\n",
            "Epoch 346/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4131 - accuracy: 0.7605 - val_loss: 0.5675 - val_accuracy: 0.6494\n",
            "Epoch 347/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4132 - accuracy: 0.7654 - val_loss: 0.5665 - val_accuracy: 0.6609\n",
            "Epoch 348/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4132 - accuracy: 0.7679 - val_loss: 0.5675 - val_accuracy: 0.6552\n",
            "Epoch 349/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4127 - accuracy: 0.7605 - val_loss: 0.5690 - val_accuracy: 0.6494\n",
            "Epoch 350/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4126 - accuracy: 0.7630 - val_loss: 0.5659 - val_accuracy: 0.6609\n",
            "Epoch 351/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4125 - accuracy: 0.7605 - val_loss: 0.5658 - val_accuracy: 0.6552\n",
            "Epoch 352/500\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.4123 - accuracy: 0.7630 - val_loss: 0.5676 - val_accuracy: 0.6552\n",
            "Epoch 353/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4122 - accuracy: 0.7630 - val_loss: 0.5677 - val_accuracy: 0.6552\n",
            "Epoch 354/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4123 - accuracy: 0.7605 - val_loss: 0.5662 - val_accuracy: 0.6552\n",
            "Epoch 355/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4125 - accuracy: 0.7654 - val_loss: 0.5631 - val_accuracy: 0.6609\n",
            "Epoch 356/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4120 - accuracy: 0.7630 - val_loss: 0.5661 - val_accuracy: 0.6552\n",
            "Epoch 357/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4114 - accuracy: 0.7654 - val_loss: 0.5663 - val_accuracy: 0.6552\n",
            "Epoch 358/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4113 - accuracy: 0.7630 - val_loss: 0.5681 - val_accuracy: 0.6609\n",
            "Epoch 359/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4111 - accuracy: 0.7630 - val_loss: 0.5667 - val_accuracy: 0.6609\n",
            "Epoch 360/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4114 - accuracy: 0.7654 - val_loss: 0.5659 - val_accuracy: 0.6552\n",
            "Epoch 361/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4105 - accuracy: 0.7654 - val_loss: 0.5689 - val_accuracy: 0.6552\n",
            "Epoch 362/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4120 - accuracy: 0.7605 - val_loss: 0.5704 - val_accuracy: 0.6552\n",
            "Epoch 363/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.7580 - val_loss: 0.5668 - val_accuracy: 0.6609\n",
            "Epoch 364/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4106 - accuracy: 0.7630 - val_loss: 0.5657 - val_accuracy: 0.6609\n",
            "Epoch 365/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4099 - accuracy: 0.7679 - val_loss: 0.5662 - val_accuracy: 0.6609\n",
            "Epoch 366/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.7630 - val_loss: 0.5684 - val_accuracy: 0.6609\n",
            "Epoch 367/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.7580 - val_loss: 0.5689 - val_accuracy: 0.6609\n",
            "Epoch 368/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4096 - accuracy: 0.7605 - val_loss: 0.5706 - val_accuracy: 0.6609\n",
            "Epoch 369/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4090 - accuracy: 0.7605 - val_loss: 0.5664 - val_accuracy: 0.6609\n",
            "Epoch 370/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4097 - accuracy: 0.7630 - val_loss: 0.5660 - val_accuracy: 0.6609\n",
            "Epoch 371/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4089 - accuracy: 0.7679 - val_loss: 0.5670 - val_accuracy: 0.6609\n",
            "Epoch 372/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4088 - accuracy: 0.7605 - val_loss: 0.5693 - val_accuracy: 0.6609\n",
            "Epoch 373/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4086 - accuracy: 0.7605 - val_loss: 0.5705 - val_accuracy: 0.6609\n",
            "Epoch 374/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4087 - accuracy: 0.7630 - val_loss: 0.5681 - val_accuracy: 0.6609\n",
            "Epoch 375/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4084 - accuracy: 0.7580 - val_loss: 0.5691 - val_accuracy: 0.6609\n",
            "Epoch 376/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4083 - accuracy: 0.7605 - val_loss: 0.5702 - val_accuracy: 0.6609\n",
            "Epoch 377/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4079 - accuracy: 0.7605 - val_loss: 0.5718 - val_accuracy: 0.6609\n",
            "Epoch 378/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4088 - accuracy: 0.7580 - val_loss: 0.5686 - val_accuracy: 0.6609\n",
            "Epoch 379/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4075 - accuracy: 0.7605 - val_loss: 0.5730 - val_accuracy: 0.6609\n",
            "Epoch 380/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4077 - accuracy: 0.7605 - val_loss: 0.5701 - val_accuracy: 0.6609\n",
            "Epoch 381/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4073 - accuracy: 0.7556 - val_loss: 0.5720 - val_accuracy: 0.6609\n",
            "Epoch 382/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4079 - accuracy: 0.7605 - val_loss: 0.5715 - val_accuracy: 0.6609\n",
            "Epoch 383/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4070 - accuracy: 0.7580 - val_loss: 0.5720 - val_accuracy: 0.6609\n",
            "Epoch 384/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4070 - accuracy: 0.7630 - val_loss: 0.5685 - val_accuracy: 0.6609\n",
            "Epoch 385/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4065 - accuracy: 0.7630 - val_loss: 0.5689 - val_accuracy: 0.6609\n",
            "Epoch 386/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4065 - accuracy: 0.7605 - val_loss: 0.5699 - val_accuracy: 0.6609\n",
            "Epoch 387/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4062 - accuracy: 0.7630 - val_loss: 0.5696 - val_accuracy: 0.6609\n",
            "Epoch 388/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4061 - accuracy: 0.7630 - val_loss: 0.5719 - val_accuracy: 0.6609\n",
            "Epoch 389/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4061 - accuracy: 0.7630 - val_loss: 0.5737 - val_accuracy: 0.6609\n",
            "Epoch 390/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4065 - accuracy: 0.7605 - val_loss: 0.5731 - val_accuracy: 0.6609\n",
            "Epoch 391/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4064 - accuracy: 0.7605 - val_loss: 0.5708 - val_accuracy: 0.6609\n",
            "Epoch 392/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4064 - accuracy: 0.7704 - val_loss: 0.5656 - val_accuracy: 0.6609\n",
            "Epoch 393/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4063 - accuracy: 0.7630 - val_loss: 0.5718 - val_accuracy: 0.6609\n",
            "Epoch 394/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4062 - accuracy: 0.7679 - val_loss: 0.5684 - val_accuracy: 0.6609\n",
            "Epoch 395/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4056 - accuracy: 0.7679 - val_loss: 0.5724 - val_accuracy: 0.6609\n",
            "Epoch 396/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4054 - accuracy: 0.7654 - val_loss: 0.5717 - val_accuracy: 0.6609\n",
            "Epoch 397/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4045 - accuracy: 0.7630 - val_loss: 0.5728 - val_accuracy: 0.6609\n",
            "Epoch 398/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4047 - accuracy: 0.7654 - val_loss: 0.5725 - val_accuracy: 0.6609\n",
            "Epoch 399/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4047 - accuracy: 0.7654 - val_loss: 0.5709 - val_accuracy: 0.6609\n",
            "Epoch 400/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4044 - accuracy: 0.7654 - val_loss: 0.5720 - val_accuracy: 0.6609\n",
            "Epoch 401/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4046 - accuracy: 0.7605 - val_loss: 0.5733 - val_accuracy: 0.6609\n",
            "Epoch 402/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4039 - accuracy: 0.7679 - val_loss: 0.5730 - val_accuracy: 0.6609\n",
            "Epoch 403/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4048 - accuracy: 0.7654 - val_loss: 0.5706 - val_accuracy: 0.6609\n",
            "Epoch 404/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4040 - accuracy: 0.7654 - val_loss: 0.5737 - val_accuracy: 0.6609\n",
            "Epoch 405/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4039 - accuracy: 0.7654 - val_loss: 0.5722 - val_accuracy: 0.6609\n",
            "Epoch 406/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4040 - accuracy: 0.7679 - val_loss: 0.5722 - val_accuracy: 0.6609\n",
            "Epoch 407/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4029 - accuracy: 0.7654 - val_loss: 0.5712 - val_accuracy: 0.6609\n",
            "Epoch 408/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4035 - accuracy: 0.7654 - val_loss: 0.5739 - val_accuracy: 0.6609\n",
            "Epoch 409/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4029 - accuracy: 0.7654 - val_loss: 0.5748 - val_accuracy: 0.6609\n",
            "Epoch 410/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4029 - accuracy: 0.7679 - val_loss: 0.5714 - val_accuracy: 0.6609\n",
            "Epoch 411/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4023 - accuracy: 0.7630 - val_loss: 0.5732 - val_accuracy: 0.6609\n",
            "Epoch 412/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4028 - accuracy: 0.7630 - val_loss: 0.5745 - val_accuracy: 0.6609\n",
            "Epoch 413/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4025 - accuracy: 0.7679 - val_loss: 0.5718 - val_accuracy: 0.6609\n",
            "Epoch 414/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4028 - accuracy: 0.7654 - val_loss: 0.5748 - val_accuracy: 0.6667\n",
            "Epoch 415/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4023 - accuracy: 0.7654 - val_loss: 0.5740 - val_accuracy: 0.6609\n",
            "Epoch 416/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4019 - accuracy: 0.7728 - val_loss: 0.5734 - val_accuracy: 0.6609\n",
            "Epoch 417/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4017 - accuracy: 0.7704 - val_loss: 0.5742 - val_accuracy: 0.6667\n",
            "Epoch 418/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4018 - accuracy: 0.7679 - val_loss: 0.5743 - val_accuracy: 0.6609\n",
            "Epoch 419/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4013 - accuracy: 0.7654 - val_loss: 0.5748 - val_accuracy: 0.6609\n",
            "Epoch 420/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4018 - accuracy: 0.7704 - val_loss: 0.5722 - val_accuracy: 0.6609\n",
            "Epoch 421/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4015 - accuracy: 0.7679 - val_loss: 0.5756 - val_accuracy: 0.6609\n",
            "Epoch 422/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4016 - accuracy: 0.7630 - val_loss: 0.5734 - val_accuracy: 0.6609\n",
            "Epoch 423/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4018 - accuracy: 0.7704 - val_loss: 0.5726 - val_accuracy: 0.6609\n",
            "Epoch 424/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4006 - accuracy: 0.7704 - val_loss: 0.5757 - val_accuracy: 0.6609\n",
            "Epoch 425/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4011 - accuracy: 0.7679 - val_loss: 0.5724 - val_accuracy: 0.6667\n",
            "Epoch 426/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4010 - accuracy: 0.7654 - val_loss: 0.5720 - val_accuracy: 0.6667\n",
            "Epoch 427/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4013 - accuracy: 0.7654 - val_loss: 0.5737 - val_accuracy: 0.6667\n",
            "Epoch 428/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4001 - accuracy: 0.7654 - val_loss: 0.5739 - val_accuracy: 0.6552\n",
            "Epoch 429/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4011 - accuracy: 0.7753 - val_loss: 0.5732 - val_accuracy: 0.6609\n",
            "Epoch 430/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4006 - accuracy: 0.7704 - val_loss: 0.5736 - val_accuracy: 0.6667\n",
            "Epoch 431/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3999 - accuracy: 0.7654 - val_loss: 0.5723 - val_accuracy: 0.6724\n",
            "Epoch 432/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3999 - accuracy: 0.7654 - val_loss: 0.5764 - val_accuracy: 0.6552\n",
            "Epoch 433/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4000 - accuracy: 0.7704 - val_loss: 0.5685 - val_accuracy: 0.6782\n",
            "Epoch 434/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.7654 - val_loss: 0.5731 - val_accuracy: 0.6667\n",
            "Epoch 435/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3991 - accuracy: 0.7654 - val_loss: 0.5748 - val_accuracy: 0.6724\n",
            "Epoch 436/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3985 - accuracy: 0.7630 - val_loss: 0.5729 - val_accuracy: 0.6724\n",
            "Epoch 437/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3991 - accuracy: 0.7679 - val_loss: 0.5717 - val_accuracy: 0.6667\n",
            "Epoch 438/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3993 - accuracy: 0.7630 - val_loss: 0.5776 - val_accuracy: 0.6782\n",
            "Epoch 439/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3981 - accuracy: 0.7679 - val_loss: 0.5748 - val_accuracy: 0.6667\n",
            "Epoch 440/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3989 - accuracy: 0.7679 - val_loss: 0.5711 - val_accuracy: 0.6724\n",
            "Epoch 441/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3986 - accuracy: 0.7630 - val_loss: 0.5742 - val_accuracy: 0.6724\n",
            "Epoch 442/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3981 - accuracy: 0.7654 - val_loss: 0.5742 - val_accuracy: 0.6724\n",
            "Epoch 443/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3981 - accuracy: 0.7704 - val_loss: 0.5734 - val_accuracy: 0.6724\n",
            "Epoch 444/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3977 - accuracy: 0.7679 - val_loss: 0.5706 - val_accuracy: 0.6782\n",
            "Epoch 445/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3979 - accuracy: 0.7704 - val_loss: 0.5744 - val_accuracy: 0.6724\n",
            "Epoch 446/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3979 - accuracy: 0.7630 - val_loss: 0.5770 - val_accuracy: 0.6724\n",
            "Epoch 447/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.7630 - val_loss: 0.5742 - val_accuracy: 0.6782\n",
            "Epoch 448/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3976 - accuracy: 0.7704 - val_loss: 0.5712 - val_accuracy: 0.6782\n",
            "Epoch 449/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3974 - accuracy: 0.7704 - val_loss: 0.5737 - val_accuracy: 0.6782\n",
            "Epoch 450/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3973 - accuracy: 0.7704 - val_loss: 0.5741 - val_accuracy: 0.6724\n",
            "Epoch 451/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3973 - accuracy: 0.7679 - val_loss: 0.5731 - val_accuracy: 0.6724\n",
            "Epoch 452/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3969 - accuracy: 0.7679 - val_loss: 0.5719 - val_accuracy: 0.6839\n",
            "Epoch 453/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3981 - accuracy: 0.7728 - val_loss: 0.5744 - val_accuracy: 0.6724\n",
            "Epoch 454/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.7679 - val_loss: 0.5745 - val_accuracy: 0.6782\n",
            "Epoch 455/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3964 - accuracy: 0.7679 - val_loss: 0.5758 - val_accuracy: 0.6667\n",
            "Epoch 456/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3968 - accuracy: 0.7654 - val_loss: 0.5743 - val_accuracy: 0.6782\n",
            "Epoch 457/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3961 - accuracy: 0.7654 - val_loss: 0.5762 - val_accuracy: 0.6724\n",
            "Epoch 458/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.7728 - val_loss: 0.5713 - val_accuracy: 0.6839\n",
            "Epoch 459/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.7704 - val_loss: 0.5775 - val_accuracy: 0.6724\n",
            "Epoch 460/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3956 - accuracy: 0.7728 - val_loss: 0.5745 - val_accuracy: 0.6839\n",
            "Epoch 461/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.7728 - val_loss: 0.5752 - val_accuracy: 0.6782\n",
            "Epoch 462/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3955 - accuracy: 0.7728 - val_loss: 0.5754 - val_accuracy: 0.6839\n",
            "Epoch 463/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3961 - accuracy: 0.7704 - val_loss: 0.5730 - val_accuracy: 0.6782\n",
            "Epoch 464/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3950 - accuracy: 0.7728 - val_loss: 0.5756 - val_accuracy: 0.6782\n",
            "Epoch 465/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.7679 - val_loss: 0.5772 - val_accuracy: 0.6839\n",
            "Epoch 466/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3956 - accuracy: 0.7704 - val_loss: 0.5748 - val_accuracy: 0.6782\n",
            "Epoch 467/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3957 - accuracy: 0.7728 - val_loss: 0.5742 - val_accuracy: 0.6782\n",
            "Epoch 468/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.7704 - val_loss: 0.5778 - val_accuracy: 0.6724\n",
            "Epoch 469/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3947 - accuracy: 0.7679 - val_loss: 0.5778 - val_accuracy: 0.6782\n",
            "Epoch 470/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3943 - accuracy: 0.7704 - val_loss: 0.5763 - val_accuracy: 0.6782\n",
            "Epoch 471/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3941 - accuracy: 0.7704 - val_loss: 0.5781 - val_accuracy: 0.6782\n",
            "Epoch 472/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3940 - accuracy: 0.7704 - val_loss: 0.5769 - val_accuracy: 0.6724\n",
            "Epoch 473/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3940 - accuracy: 0.7728 - val_loss: 0.5753 - val_accuracy: 0.6724\n",
            "Epoch 474/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3937 - accuracy: 0.7728 - val_loss: 0.5794 - val_accuracy: 0.6724\n",
            "Epoch 475/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3935 - accuracy: 0.7728 - val_loss: 0.5806 - val_accuracy: 0.6839\n",
            "Epoch 476/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3936 - accuracy: 0.7679 - val_loss: 0.5798 - val_accuracy: 0.6782\n",
            "Epoch 477/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3934 - accuracy: 0.7728 - val_loss: 0.5780 - val_accuracy: 0.6724\n",
            "Epoch 478/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3933 - accuracy: 0.7704 - val_loss: 0.5818 - val_accuracy: 0.6782\n",
            "Epoch 479/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3944 - accuracy: 0.7679 - val_loss: 0.5786 - val_accuracy: 0.6782\n",
            "Epoch 480/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3928 - accuracy: 0.7753 - val_loss: 0.5784 - val_accuracy: 0.6782\n",
            "Epoch 481/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3929 - accuracy: 0.7728 - val_loss: 0.5776 - val_accuracy: 0.6782\n",
            "Epoch 482/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3931 - accuracy: 0.7679 - val_loss: 0.5829 - val_accuracy: 0.6782\n",
            "Epoch 483/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3934 - accuracy: 0.7728 - val_loss: 0.5795 - val_accuracy: 0.6782\n",
            "Epoch 484/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3929 - accuracy: 0.7728 - val_loss: 0.5775 - val_accuracy: 0.6839\n",
            "Epoch 485/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3923 - accuracy: 0.7728 - val_loss: 0.5810 - val_accuracy: 0.6782\n",
            "Epoch 486/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3924 - accuracy: 0.7704 - val_loss: 0.5809 - val_accuracy: 0.6954\n",
            "Epoch 487/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3929 - accuracy: 0.7704 - val_loss: 0.5840 - val_accuracy: 0.6724\n",
            "Epoch 488/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3919 - accuracy: 0.7753 - val_loss: 0.5766 - val_accuracy: 0.6782\n",
            "Epoch 489/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3922 - accuracy: 0.7753 - val_loss: 0.5775 - val_accuracy: 0.6839\n",
            "Epoch 490/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3915 - accuracy: 0.7753 - val_loss: 0.5803 - val_accuracy: 0.6782\n",
            "Epoch 491/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3920 - accuracy: 0.7753 - val_loss: 0.5843 - val_accuracy: 0.6839\n",
            "Epoch 492/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3917 - accuracy: 0.7679 - val_loss: 0.5780 - val_accuracy: 0.6954\n",
            "Epoch 493/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3923 - accuracy: 0.7704 - val_loss: 0.5837 - val_accuracy: 0.6724\n",
            "Epoch 494/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3904 - accuracy: 0.7778 - val_loss: 0.5798 - val_accuracy: 0.7011\n",
            "Epoch 495/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3913 - accuracy: 0.7728 - val_loss: 0.5790 - val_accuracy: 0.6954\n",
            "Epoch 496/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3904 - accuracy: 0.7728 - val_loss: 0.5807 - val_accuracy: 0.6954\n",
            "Epoch 497/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3906 - accuracy: 0.7728 - val_loss: 0.5818 - val_accuracy: 0.6897\n",
            "Epoch 498/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3908 - accuracy: 0.7704 - val_loss: 0.5842 - val_accuracy: 0.6897\n",
            "Epoch 499/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3904 - accuracy: 0.7753 - val_loss: 0.5783 - val_accuracy: 0.6897\n",
            "Epoch 500/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3904 - accuracy: 0.7753 - val_loss: 0.5823 - val_accuracy: 0.6897\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJ3lEQrNHAX8",
        "outputId": "26152ef8-5d12-4124-c8d4-58a8fdfdd64b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "r3.history['loss']"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7456019520759583,\n",
              " 0.7179459929466248,\n",
              " 0.6914374232292175,\n",
              " 0.6705913543701172,\n",
              " 0.6529135704040527,\n",
              " 0.63713139295578,\n",
              " 0.6246569156646729,\n",
              " 0.6141778826713562,\n",
              " 0.6043241024017334,\n",
              " 0.5951331853866577,\n",
              " 0.5868616104125977,\n",
              " 0.5795316696166992,\n",
              " 0.5728639364242554,\n",
              " 0.5673025846481323,\n",
              " 0.5624678730964661,\n",
              " 0.5583130121231079,\n",
              " 0.554490864276886,\n",
              " 0.5510721206665039,\n",
              " 0.5474843978881836,\n",
              " 0.544434130191803,\n",
              " 0.5411956310272217,\n",
              " 0.5383793711662292,\n",
              " 0.536088764667511,\n",
              " 0.5337479710578918,\n",
              " 0.5313336849212646,\n",
              " 0.529327929019928,\n",
              " 0.5275447964668274,\n",
              " 0.5255805253982544,\n",
              " 0.5239339470863342,\n",
              " 0.5222292542457581,\n",
              " 0.5208341479301453,\n",
              " 0.5190392136573792,\n",
              " 0.5176166892051697,\n",
              " 0.5162274241447449,\n",
              " 0.5147665739059448,\n",
              " 0.5135622620582581,\n",
              " 0.5125440359115601,\n",
              " 0.5110586881637573,\n",
              " 0.5101397037506104,\n",
              " 0.5088183283805847,\n",
              " 0.5078573226928711,\n",
              " 0.506995677947998,\n",
              " 0.5061522722244263,\n",
              " 0.5053293704986572,\n",
              " 0.5043357610702515,\n",
              " 0.5035068988800049,\n",
              " 0.5027568936347961,\n",
              " 0.5018288493156433,\n",
              " 0.5012946724891663,\n",
              " 0.5000590682029724,\n",
              " 0.49944180250167847,\n",
              " 0.498470664024353,\n",
              " 0.497939795255661,\n",
              " 0.49687954783439636,\n",
              " 0.4960225820541382,\n",
              " 0.49539637565612793,\n",
              " 0.4945693910121918,\n",
              " 0.49389636516571045,\n",
              " 0.49299708008766174,\n",
              " 0.49275726079940796,\n",
              " 0.4916497468948364,\n",
              " 0.49120932817459106,\n",
              " 0.490497350692749,\n",
              " 0.48975780606269836,\n",
              " 0.48948660492897034,\n",
              " 0.4884834289550781,\n",
              " 0.48793184757232666,\n",
              " 0.4867873191833496,\n",
              " 0.4863969087600708,\n",
              " 0.48592567443847656,\n",
              " 0.4855392575263977,\n",
              " 0.48459580540657043,\n",
              " 0.484348863363266,\n",
              " 0.483437180519104,\n",
              " 0.48320281505584717,\n",
              " 0.4822218120098114,\n",
              " 0.48163551092147827,\n",
              " 0.48128262162208557,\n",
              " 0.48063164949417114,\n",
              " 0.4801991879940033,\n",
              " 0.4794289767742157,\n",
              " 0.47907140851020813,\n",
              " 0.4782479703426361,\n",
              " 0.4777919054031372,\n",
              " 0.47728604078292847,\n",
              " 0.4769536554813385,\n",
              " 0.47647252678871155,\n",
              " 0.47547170519828796,\n",
              " 0.4750114977359772,\n",
              " 0.4746778607368469,\n",
              " 0.4739859104156494,\n",
              " 0.4733990728855133,\n",
              " 0.47304239869117737,\n",
              " 0.4721175730228424,\n",
              " 0.47162318229675293,\n",
              " 0.4711759090423584,\n",
              " 0.4708016812801361,\n",
              " 0.47023719549179077,\n",
              " 0.470010906457901,\n",
              " 0.4693858325481415,\n",
              " 0.4688488245010376,\n",
              " 0.4683605134487152,\n",
              " 0.4681239724159241,\n",
              " 0.4672999382019043,\n",
              " 0.4675223231315613,\n",
              " 0.4669588506221771,\n",
              " 0.4663248062133789,\n",
              " 0.4659779369831085,\n",
              " 0.465648353099823,\n",
              " 0.4651552140712738,\n",
              " 0.46525442600250244,\n",
              " 0.4646512567996979,\n",
              " 0.4643787145614624,\n",
              " 0.4640003740787506,\n",
              " 0.46370887756347656,\n",
              " 0.4639565944671631,\n",
              " 0.46343985199928284,\n",
              " 0.46310073137283325,\n",
              " 0.46237319707870483,\n",
              " 0.46205833554267883,\n",
              " 0.46151360869407654,\n",
              " 0.4619593918323517,\n",
              " 0.4610437750816345,\n",
              " 0.4608032703399658,\n",
              " 0.46054866909980774,\n",
              " 0.46008533239364624,\n",
              " 0.4600065350532532,\n",
              " 0.45951539278030396,\n",
              " 0.4591439962387085,\n",
              " 0.4589855372905731,\n",
              " 0.45859652757644653,\n",
              " 0.45832163095474243,\n",
              " 0.4585840404033661,\n",
              " 0.45799142122268677,\n",
              " 0.45791012048721313,\n",
              " 0.45725566148757935,\n",
              " 0.45696836709976196,\n",
              " 0.4565679132938385,\n",
              " 0.4566955268383026,\n",
              " 0.4563652575016022,\n",
              " 0.4556969106197357,\n",
              " 0.45615848898887634,\n",
              " 0.4558062255382538,\n",
              " 0.4549333453178406,\n",
              " 0.45464426279067993,\n",
              " 0.4544439911842346,\n",
              " 0.4543848931789398,\n",
              " 0.4538995921611786,\n",
              " 0.45364508032798767,\n",
              " 0.4535835087299347,\n",
              " 0.4533142149448395,\n",
              " 0.45252886414527893,\n",
              " 0.45227667689323425,\n",
              " 0.4520159959793091,\n",
              " 0.45199182629585266,\n",
              " 0.4520232379436493,\n",
              " 0.45155009627342224,\n",
              " 0.45113933086395264,\n",
              " 0.4506930410861969,\n",
              " 0.4508056640625,\n",
              " 0.4502582252025604,\n",
              " 0.45031338930130005,\n",
              " 0.45011356472969055,\n",
              " 0.44951504468917847,\n",
              " 0.44939756393432617,\n",
              " 0.4493524730205536,\n",
              " 0.4486643075942993,\n",
              " 0.44878455996513367,\n",
              " 0.4479811191558838,\n",
              " 0.44820138812065125,\n",
              " 0.4477693438529968,\n",
              " 0.44742920994758606,\n",
              " 0.44773945212364197,\n",
              " 0.44827359914779663,\n",
              " 0.4465983510017395,\n",
              " 0.4463980495929718,\n",
              " 0.4461897015571594,\n",
              " 0.44568654894828796,\n",
              " 0.4460016191005707,\n",
              " 0.44518497586250305,\n",
              " 0.4451015591621399,\n",
              " 0.44465625286102295,\n",
              " 0.44453567266464233,\n",
              " 0.4443134367465973,\n",
              " 0.4444091320037842,\n",
              " 0.4445609152317047,\n",
              " 0.443732887506485,\n",
              " 0.4431173503398895,\n",
              " 0.4430962800979614,\n",
              " 0.44310206174850464,\n",
              " 0.4421573281288147,\n",
              " 0.4420115053653717,\n",
              " 0.4423314332962036,\n",
              " 0.4416150748729706,\n",
              " 0.44119200110435486,\n",
              " 0.44117310643196106,\n",
              " 0.44104471802711487,\n",
              " 0.4404837191104889,\n",
              " 0.4407845139503479,\n",
              " 0.44094815850257874,\n",
              " 0.43954187631607056,\n",
              " 0.44007399678230286,\n",
              " 0.4394683539867401,\n",
              " 0.4393109679222107,\n",
              " 0.43900391459465027,\n",
              " 0.43875592947006226,\n",
              " 0.43859583139419556,\n",
              " 0.4380028545856476,\n",
              " 0.4380364418029785,\n",
              " 0.4375505745410919,\n",
              " 0.43776148557662964,\n",
              " 0.4376327097415924,\n",
              " 0.4373258352279663,\n",
              " 0.43677255511283875,\n",
              " 0.43676143884658813,\n",
              " 0.4367053508758545,\n",
              " 0.43578773736953735,\n",
              " 0.4352913796901703,\n",
              " 0.43506401777267456,\n",
              " 0.43495261669158936,\n",
              " 0.43542054295539856,\n",
              " 0.4344042241573334,\n",
              " 0.43485596776008606,\n",
              " 0.43389639258384705,\n",
              " 0.4340646266937256,\n",
              " 0.43452179431915283,\n",
              " 0.4334232807159424,\n",
              " 0.43279892206192017,\n",
              " 0.43309956789016724,\n",
              " 0.4326447546482086,\n",
              " 0.43233296275138855,\n",
              " 0.4319153130054474,\n",
              " 0.43185150623321533,\n",
              " 0.4317963421344757,\n",
              " 0.43179288506507874,\n",
              " 0.43111345171928406,\n",
              " 0.4311716854572296,\n",
              " 0.4312618672847748,\n",
              " 0.43046653270721436,\n",
              " 0.4311738908290863,\n",
              " 0.4301743805408478,\n",
              " 0.4298856854438782,\n",
              " 0.42990976572036743,\n",
              " 0.4295251965522766,\n",
              " 0.42925384640693665,\n",
              " 0.4294549524784088,\n",
              " 0.4287147521972656,\n",
              " 0.42861151695251465,\n",
              " 0.428780198097229,\n",
              " 0.42812439799308777,\n",
              " 0.4282316565513611,\n",
              " 0.4275428354740143,\n",
              " 0.4281432628631592,\n",
              " 0.4272259771823883,\n",
              " 0.4271005392074585,\n",
              " 0.4266538918018341,\n",
              " 0.4264163672924042,\n",
              " 0.4273698329925537,\n",
              " 0.4260634481906891,\n",
              " 0.4263347089290619,\n",
              " 0.42585325241088867,\n",
              " 0.4260745346546173,\n",
              " 0.42530113458633423,\n",
              " 0.42518553137779236,\n",
              " 0.42557772994041443,\n",
              " 0.4251865744590759,\n",
              " 0.4247956871986389,\n",
              " 0.42415764927864075,\n",
              " 0.42437392473220825,\n",
              " 0.4241110682487488,\n",
              " 0.42411720752716064,\n",
              " 0.4238361418247223,\n",
              " 0.4242585003376007,\n",
              " 0.42330044507980347,\n",
              " 0.4236307442188263,\n",
              " 0.42370450496673584,\n",
              " 0.42259886860847473,\n",
              " 0.42303863167762756,\n",
              " 0.4225970506668091,\n",
              " 0.42236781120300293,\n",
              " 0.42253026366233826,\n",
              " 0.42236608266830444,\n",
              " 0.42216771841049194,\n",
              " 0.4220105707645416,\n",
              " 0.42135119438171387,\n",
              " 0.4214831590652466,\n",
              " 0.42146602272987366,\n",
              " 0.42140334844589233,\n",
              " 0.4210951030254364,\n",
              " 0.4218142330646515,\n",
              " 0.4214129149913788,\n",
              " 0.4204747974872589,\n",
              " 0.421394020318985,\n",
              " 0.4207165837287903,\n",
              " 0.41980788111686707,\n",
              " 0.42032501101493835,\n",
              " 0.41982534527778625,\n",
              " 0.420110285282135,\n",
              " 0.41924160718917847,\n",
              " 0.4194265604019165,\n",
              " 0.41966333985328674,\n",
              " 0.4194866418838501,\n",
              " 0.4187365770339966,\n",
              " 0.4191282391548157,\n",
              " 0.41883188486099243,\n",
              " 0.41813042759895325,\n",
              " 0.41895681619644165,\n",
              " 0.4178241491317749,\n",
              " 0.41860172152519226,\n",
              " 0.41867128014564514,\n",
              " 0.41828179359436035,\n",
              " 0.4177091717720032,\n",
              " 0.4182407855987549,\n",
              " 0.4176032245159149,\n",
              " 0.41780465841293335,\n",
              " 0.4173987805843353,\n",
              " 0.4169131815433502,\n",
              " 0.41691815853118896,\n",
              " 0.4166460931301117,\n",
              " 0.4169512093067169,\n",
              " 0.41654229164123535,\n",
              " 0.417243629693985,\n",
              " 0.41600432991981506,\n",
              " 0.4159507155418396,\n",
              " 0.4160735011100769,\n",
              " 0.4156327545642853,\n",
              " 0.4155571460723877,\n",
              " 0.4152962863445282,\n",
              " 0.4150272309780121,\n",
              " 0.4151577055454254,\n",
              " 0.41548779606819153,\n",
              " 0.415102481842041,\n",
              " 0.41484031081199646,\n",
              " 0.4147283732891083,\n",
              " 0.41466376185417175,\n",
              " 0.41468244791030884,\n",
              " 0.41437870264053345,\n",
              " 0.4137754440307617,\n",
              " 0.41384685039520264,\n",
              " 0.41387197375297546,\n",
              " 0.41383957862854004,\n",
              " 0.413770467042923,\n",
              " 0.4142157733440399,\n",
              " 0.4132556915283203,\n",
              " 0.41337138414382935,\n",
              " 0.4130595624446869,\n",
              " 0.4131779670715332,\n",
              " 0.4132051467895508,\n",
              " 0.41266536712646484,\n",
              " 0.4125700891017914,\n",
              " 0.41250985860824585,\n",
              " 0.4123423397541046,\n",
              " 0.4122065305709839,\n",
              " 0.4122883081436157,\n",
              " 0.41245517134666443,\n",
              " 0.4120471477508545,\n",
              " 0.4114251732826233,\n",
              " 0.4112800061702728,\n",
              " 0.41112905740737915,\n",
              " 0.4114295244216919,\n",
              " 0.4104754328727722,\n",
              " 0.41198739409446716,\n",
              " 0.4105193316936493,\n",
              " 0.41062116622924805,\n",
              " 0.4098690152168274,\n",
              " 0.41030147671699524,\n",
              " 0.4096106290817261,\n",
              " 0.40964359045028687,\n",
              " 0.4089928865432739,\n",
              " 0.40965503454208374,\n",
              " 0.40886467695236206,\n",
              " 0.408832311630249,\n",
              " 0.4085792899131775,\n",
              " 0.4087226092815399,\n",
              " 0.40840721130371094,\n",
              " 0.4083435535430908,\n",
              " 0.40785953402519226,\n",
              " 0.40882599353790283,\n",
              " 0.40753644704818726,\n",
              " 0.40770798921585083,\n",
              " 0.4072599411010742,\n",
              " 0.4078781306743622,\n",
              " 0.40703442692756653,\n",
              " 0.40700167417526245,\n",
              " 0.40646830201148987,\n",
              " 0.40653911232948303,\n",
              " 0.4062369167804718,\n",
              " 0.40612882375717163,\n",
              " 0.4060531556606293,\n",
              " 0.4065096974372864,\n",
              " 0.4063970744609833,\n",
              " 0.4064016044139862,\n",
              " 0.40634027123451233,\n",
              " 0.40623027086257935,\n",
              " 0.40559297800064087,\n",
              " 0.4053586721420288,\n",
              " 0.4045388996601105,\n",
              " 0.4047115743160248,\n",
              " 0.40471988916397095,\n",
              " 0.40438830852508545,\n",
              " 0.4045543670654297,\n",
              " 0.40389925241470337,\n",
              " 0.40480807423591614,\n",
              " 0.4040103554725647,\n",
              " 0.4038998782634735,\n",
              " 0.4039801359176636,\n",
              " 0.4029357433319092,\n",
              " 0.4035038352012634,\n",
              " 0.4028797149658203,\n",
              " 0.40287142992019653,\n",
              " 0.4022877514362335,\n",
              " 0.4028209149837494,\n",
              " 0.4024660587310791,\n",
              " 0.4027746915817261,\n",
              " 0.40225595235824585,\n",
              " 0.4019136130809784,\n",
              " 0.40167438983917236,\n",
              " 0.4017893970012665,\n",
              " 0.40129202604293823,\n",
              " 0.4017849862575531,\n",
              " 0.40152600407600403,\n",
              " 0.4015706479549408,\n",
              " 0.4017552435398102,\n",
              " 0.4005604684352875,\n",
              " 0.40113818645477295,\n",
              " 0.40099889039993286,\n",
              " 0.4012933075428009,\n",
              " 0.40010499954223633,\n",
              " 0.4010910093784332,\n",
              " 0.40062618255615234,\n",
              " 0.3998977243900299,\n",
              " 0.3999190628528595,\n",
              " 0.39998191595077515,\n",
              " 0.39991533756256104,\n",
              " 0.39913812279701233,\n",
              " 0.3984619975090027,\n",
              " 0.3991026282310486,\n",
              " 0.3992994427680969,\n",
              " 0.3980831801891327,\n",
              " 0.39889097213745117,\n",
              " 0.39860743284225464,\n",
              " 0.39809322357177734,\n",
              " 0.3980652987957001,\n",
              " 0.3976966142654419,\n",
              " 0.39788487553596497,\n",
              " 0.39789190888404846,\n",
              " 0.39793679118156433,\n",
              " 0.39760497212409973,\n",
              " 0.39743727445602417,\n",
              " 0.39730608463287354,\n",
              " 0.39727097749710083,\n",
              " 0.3968990743160248,\n",
              " 0.3980919122695923,\n",
              " 0.39664381742477417,\n",
              " 0.3964412212371826,\n",
              " 0.39675602316856384,\n",
              " 0.3960556089878082,\n",
              " 0.39650094509124756,\n",
              " 0.39618685841560364,\n",
              " 0.3955864906311035,\n",
              " 0.39591166377067566,\n",
              " 0.3954712748527527,\n",
              " 0.39611634612083435,\n",
              " 0.3949551284313202,\n",
              " 0.39519473910331726,\n",
              " 0.3956087827682495,\n",
              " 0.395709365606308,\n",
              " 0.3951893746852875,\n",
              " 0.39474359154701233,\n",
              " 0.39425814151763916,\n",
              " 0.3941309154033661,\n",
              " 0.3940383791923523,\n",
              " 0.394030898809433,\n",
              " 0.3937317132949829,\n",
              " 0.3935355246067047,\n",
              " 0.3935534954071045,\n",
              " 0.39343470335006714,\n",
              " 0.39325767755508423,\n",
              " 0.39440152049064636,\n",
              " 0.39277932047843933,\n",
              " 0.3929040729999542,\n",
              " 0.39311105012893677,\n",
              " 0.39338958263397217,\n",
              " 0.3928622901439667,\n",
              " 0.3923472464084625,\n",
              " 0.39239704608917236,\n",
              " 0.392939954996109,\n",
              " 0.39187270402908325,\n",
              " 0.3921932578086853,\n",
              " 0.39154720306396484,\n",
              " 0.39199432730674744,\n",
              " 0.39172908663749695,\n",
              " 0.39228150248527527,\n",
              " 0.3904457986354828,\n",
              " 0.391283243894577,\n",
              " 0.3904428482055664,\n",
              " 0.39056363701820374,\n",
              " 0.39084672927856445,\n",
              " 0.3904087543487549,\n",
              " 0.39035728573799133]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpCJ7NzwHhzF",
        "outputId": "06a22d90-070a-498a-990e-83a321aa6460",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model4 = Sequential([\n",
        "    Dense(8, input_shape=(10,), activation='relu'),\n",
        "    Dense(5, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model4.summary()\n",
        "model4.compile(optimizer='SGD',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "r4=model4.fit(X_train, y_train, epochs=500,validation_data=(X_test,y_test))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_23 (Dense)             (None, 8)                 88        \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 5)                 45        \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 1)                 6         \n",
            "=================================================================\n",
            "Total params: 139\n",
            "Trainable params: 139\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "13/13 [==============================] - 0s 13ms/step - loss: 0.9297 - accuracy: 0.3358 - val_loss: 0.9089 - val_accuracy: 0.3276\n",
            "Epoch 2/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.8147 - accuracy: 0.3802 - val_loss: 0.8171 - val_accuracy: 0.3736\n",
            "Epoch 3/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7418 - accuracy: 0.4568 - val_loss: 0.7558 - val_accuracy: 0.4425\n",
            "Epoch 4/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6933 - accuracy: 0.5259 - val_loss: 0.7128 - val_accuracy: 0.4943\n",
            "Epoch 5/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6601 - accuracy: 0.5728 - val_loss: 0.6815 - val_accuracy: 0.5977\n",
            "Epoch 6/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6363 - accuracy: 0.6370 - val_loss: 0.6581 - val_accuracy: 0.6207\n",
            "Epoch 7/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6187 - accuracy: 0.6469 - val_loss: 0.6405 - val_accuracy: 0.6264\n",
            "Epoch 8/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6054 - accuracy: 0.6543 - val_loss: 0.6266 - val_accuracy: 0.6264\n",
            "Epoch 9/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5954 - accuracy: 0.6642 - val_loss: 0.6159 - val_accuracy: 0.6379\n",
            "Epoch 10/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5877 - accuracy: 0.6790 - val_loss: 0.6068 - val_accuracy: 0.6609\n",
            "Epoch 11/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5812 - accuracy: 0.7012 - val_loss: 0.5992 - val_accuracy: 0.6552\n",
            "Epoch 12/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5758 - accuracy: 0.7012 - val_loss: 0.5929 - val_accuracy: 0.6552\n",
            "Epoch 13/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5714 - accuracy: 0.6963 - val_loss: 0.5876 - val_accuracy: 0.6609\n",
            "Epoch 14/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5679 - accuracy: 0.7037 - val_loss: 0.5834 - val_accuracy: 0.6667\n",
            "Epoch 15/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5649 - accuracy: 0.7062 - val_loss: 0.5796 - val_accuracy: 0.6782\n",
            "Epoch 16/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5623 - accuracy: 0.7136 - val_loss: 0.5766 - val_accuracy: 0.6839\n",
            "Epoch 17/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5603 - accuracy: 0.7086 - val_loss: 0.5739 - val_accuracy: 0.7011\n",
            "Epoch 18/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5585 - accuracy: 0.7086 - val_loss: 0.5715 - val_accuracy: 0.7011\n",
            "Epoch 19/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5570 - accuracy: 0.7111 - val_loss: 0.5698 - val_accuracy: 0.7011\n",
            "Epoch 20/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5557 - accuracy: 0.7111 - val_loss: 0.5681 - val_accuracy: 0.7011\n",
            "Epoch 21/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5545 - accuracy: 0.7136 - val_loss: 0.5665 - val_accuracy: 0.7011\n",
            "Epoch 22/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5535 - accuracy: 0.7185 - val_loss: 0.5652 - val_accuracy: 0.6954\n",
            "Epoch 23/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5523 - accuracy: 0.7160 - val_loss: 0.5640 - val_accuracy: 0.6954\n",
            "Epoch 24/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5516 - accuracy: 0.7185 - val_loss: 0.5627 - val_accuracy: 0.6954\n",
            "Epoch 25/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5506 - accuracy: 0.7185 - val_loss: 0.5618 - val_accuracy: 0.6954\n",
            "Epoch 26/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5498 - accuracy: 0.7136 - val_loss: 0.5607 - val_accuracy: 0.6954\n",
            "Epoch 27/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5490 - accuracy: 0.7136 - val_loss: 0.5596 - val_accuracy: 0.7011\n",
            "Epoch 28/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5483 - accuracy: 0.7185 - val_loss: 0.5589 - val_accuracy: 0.7069\n",
            "Epoch 29/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5477 - accuracy: 0.7185 - val_loss: 0.5581 - val_accuracy: 0.7069\n",
            "Epoch 30/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5470 - accuracy: 0.7210 - val_loss: 0.5574 - val_accuracy: 0.7011\n",
            "Epoch 31/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5464 - accuracy: 0.7185 - val_loss: 0.5568 - val_accuracy: 0.7011\n",
            "Epoch 32/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5458 - accuracy: 0.7185 - val_loss: 0.5561 - val_accuracy: 0.7011\n",
            "Epoch 33/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5452 - accuracy: 0.7210 - val_loss: 0.5556 - val_accuracy: 0.7011\n",
            "Epoch 34/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5445 - accuracy: 0.7185 - val_loss: 0.5550 - val_accuracy: 0.7011\n",
            "Epoch 35/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5440 - accuracy: 0.7185 - val_loss: 0.5544 - val_accuracy: 0.7011\n",
            "Epoch 36/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5434 - accuracy: 0.7185 - val_loss: 0.5538 - val_accuracy: 0.6954\n",
            "Epoch 37/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5429 - accuracy: 0.7185 - val_loss: 0.5532 - val_accuracy: 0.6954\n",
            "Epoch 38/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5423 - accuracy: 0.7185 - val_loss: 0.5526 - val_accuracy: 0.6954\n",
            "Epoch 39/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5417 - accuracy: 0.7185 - val_loss: 0.5521 - val_accuracy: 0.6954\n",
            "Epoch 40/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5413 - accuracy: 0.7185 - val_loss: 0.5516 - val_accuracy: 0.6954\n",
            "Epoch 41/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5407 - accuracy: 0.7185 - val_loss: 0.5510 - val_accuracy: 0.6954\n",
            "Epoch 42/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5402 - accuracy: 0.7185 - val_loss: 0.5504 - val_accuracy: 0.6954\n",
            "Epoch 43/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5398 - accuracy: 0.7185 - val_loss: 0.5501 - val_accuracy: 0.6954\n",
            "Epoch 44/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5393 - accuracy: 0.7185 - val_loss: 0.5497 - val_accuracy: 0.6954\n",
            "Epoch 45/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5388 - accuracy: 0.7185 - val_loss: 0.5493 - val_accuracy: 0.6954\n",
            "Epoch 46/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5383 - accuracy: 0.7185 - val_loss: 0.5489 - val_accuracy: 0.6954\n",
            "Epoch 47/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5378 - accuracy: 0.7185 - val_loss: 0.5485 - val_accuracy: 0.6954\n",
            "Epoch 48/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5373 - accuracy: 0.7185 - val_loss: 0.5483 - val_accuracy: 0.7011\n",
            "Epoch 49/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5369 - accuracy: 0.7185 - val_loss: 0.5480 - val_accuracy: 0.7011\n",
            "Epoch 50/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5364 - accuracy: 0.7210 - val_loss: 0.5476 - val_accuracy: 0.7011\n",
            "Epoch 51/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5359 - accuracy: 0.7210 - val_loss: 0.5473 - val_accuracy: 0.7011\n",
            "Epoch 52/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5355 - accuracy: 0.7210 - val_loss: 0.5470 - val_accuracy: 0.7011\n",
            "Epoch 53/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5350 - accuracy: 0.7210 - val_loss: 0.5467 - val_accuracy: 0.7011\n",
            "Epoch 54/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5347 - accuracy: 0.7160 - val_loss: 0.5463 - val_accuracy: 0.7011\n",
            "Epoch 55/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5342 - accuracy: 0.7185 - val_loss: 0.5461 - val_accuracy: 0.6954\n",
            "Epoch 56/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5340 - accuracy: 0.7160 - val_loss: 0.5456 - val_accuracy: 0.6954\n",
            "Epoch 57/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5334 - accuracy: 0.7136 - val_loss: 0.5453 - val_accuracy: 0.6954\n",
            "Epoch 58/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5331 - accuracy: 0.7136 - val_loss: 0.5450 - val_accuracy: 0.6954\n",
            "Epoch 59/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5327 - accuracy: 0.7136 - val_loss: 0.5447 - val_accuracy: 0.6954\n",
            "Epoch 60/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5323 - accuracy: 0.7136 - val_loss: 0.5444 - val_accuracy: 0.6954\n",
            "Epoch 61/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5318 - accuracy: 0.7136 - val_loss: 0.5442 - val_accuracy: 0.6954\n",
            "Epoch 62/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5314 - accuracy: 0.7136 - val_loss: 0.5438 - val_accuracy: 0.6954\n",
            "Epoch 63/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5311 - accuracy: 0.7136 - val_loss: 0.5435 - val_accuracy: 0.6954\n",
            "Epoch 64/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5308 - accuracy: 0.7136 - val_loss: 0.5433 - val_accuracy: 0.6954\n",
            "Epoch 65/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5303 - accuracy: 0.7111 - val_loss: 0.5431 - val_accuracy: 0.6954\n",
            "Epoch 66/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5301 - accuracy: 0.7111 - val_loss: 0.5429 - val_accuracy: 0.7011\n",
            "Epoch 67/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5297 - accuracy: 0.7111 - val_loss: 0.5427 - val_accuracy: 0.7011\n",
            "Epoch 68/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5293 - accuracy: 0.7111 - val_loss: 0.5424 - val_accuracy: 0.7011\n",
            "Epoch 69/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5289 - accuracy: 0.7111 - val_loss: 0.5423 - val_accuracy: 0.7011\n",
            "Epoch 70/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5284 - accuracy: 0.7160 - val_loss: 0.5420 - val_accuracy: 0.7069\n",
            "Epoch 71/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5283 - accuracy: 0.7160 - val_loss: 0.5417 - val_accuracy: 0.7011\n",
            "Epoch 72/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5279 - accuracy: 0.7136 - val_loss: 0.5415 - val_accuracy: 0.7011\n",
            "Epoch 73/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5275 - accuracy: 0.7160 - val_loss: 0.5412 - val_accuracy: 0.7011\n",
            "Epoch 74/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5272 - accuracy: 0.7160 - val_loss: 0.5411 - val_accuracy: 0.7011\n",
            "Epoch 75/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5268 - accuracy: 0.7185 - val_loss: 0.5408 - val_accuracy: 0.7011\n",
            "Epoch 76/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5264 - accuracy: 0.7185 - val_loss: 0.5405 - val_accuracy: 0.6954\n",
            "Epoch 77/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5260 - accuracy: 0.7185 - val_loss: 0.5401 - val_accuracy: 0.7011\n",
            "Epoch 78/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5257 - accuracy: 0.7185 - val_loss: 0.5399 - val_accuracy: 0.6954\n",
            "Epoch 79/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5255 - accuracy: 0.7185 - val_loss: 0.5395 - val_accuracy: 0.7011\n",
            "Epoch 80/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5252 - accuracy: 0.7185 - val_loss: 0.5394 - val_accuracy: 0.6954\n",
            "Epoch 81/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5247 - accuracy: 0.7210 - val_loss: 0.5391 - val_accuracy: 0.6954\n",
            "Epoch 82/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5244 - accuracy: 0.7185 - val_loss: 0.5388 - val_accuracy: 0.7011\n",
            "Epoch 83/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5241 - accuracy: 0.7210 - val_loss: 0.5387 - val_accuracy: 0.7011\n",
            "Epoch 84/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5238 - accuracy: 0.7210 - val_loss: 0.5385 - val_accuracy: 0.7011\n",
            "Epoch 85/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5235 - accuracy: 0.7210 - val_loss: 0.5384 - val_accuracy: 0.7011\n",
            "Epoch 86/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5231 - accuracy: 0.7185 - val_loss: 0.5381 - val_accuracy: 0.7011\n",
            "Epoch 87/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5229 - accuracy: 0.7210 - val_loss: 0.5380 - val_accuracy: 0.7011\n",
            "Epoch 88/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5225 - accuracy: 0.7235 - val_loss: 0.5380 - val_accuracy: 0.7011\n",
            "Epoch 89/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5222 - accuracy: 0.7185 - val_loss: 0.5379 - val_accuracy: 0.7011\n",
            "Epoch 90/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5219 - accuracy: 0.7235 - val_loss: 0.5376 - val_accuracy: 0.7011\n",
            "Epoch 91/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5215 - accuracy: 0.7210 - val_loss: 0.5374 - val_accuracy: 0.7011\n",
            "Epoch 92/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5213 - accuracy: 0.7235 - val_loss: 0.5372 - val_accuracy: 0.7011\n",
            "Epoch 93/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5211 - accuracy: 0.7235 - val_loss: 0.5368 - val_accuracy: 0.7011\n",
            "Epoch 94/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5208 - accuracy: 0.7235 - val_loss: 0.5367 - val_accuracy: 0.7011\n",
            "Epoch 95/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5205 - accuracy: 0.7259 - val_loss: 0.5364 - val_accuracy: 0.7011\n",
            "Epoch 96/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5201 - accuracy: 0.7284 - val_loss: 0.5363 - val_accuracy: 0.7011\n",
            "Epoch 97/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5199 - accuracy: 0.7259 - val_loss: 0.5360 - val_accuracy: 0.7011\n",
            "Epoch 98/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5194 - accuracy: 0.7284 - val_loss: 0.5358 - val_accuracy: 0.7069\n",
            "Epoch 99/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5191 - accuracy: 0.7284 - val_loss: 0.5354 - val_accuracy: 0.7069\n",
            "Epoch 100/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5188 - accuracy: 0.7309 - val_loss: 0.5352 - val_accuracy: 0.7069\n",
            "Epoch 101/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5185 - accuracy: 0.7309 - val_loss: 0.5350 - val_accuracy: 0.7069\n",
            "Epoch 102/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5182 - accuracy: 0.7284 - val_loss: 0.5347 - val_accuracy: 0.7069\n",
            "Epoch 103/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5180 - accuracy: 0.7259 - val_loss: 0.5344 - val_accuracy: 0.7069\n",
            "Epoch 104/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5176 - accuracy: 0.7333 - val_loss: 0.5343 - val_accuracy: 0.7126\n",
            "Epoch 105/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5174 - accuracy: 0.7259 - val_loss: 0.5340 - val_accuracy: 0.7126\n",
            "Epoch 106/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5172 - accuracy: 0.7309 - val_loss: 0.5338 - val_accuracy: 0.7126\n",
            "Epoch 107/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5169 - accuracy: 0.7284 - val_loss: 0.5335 - val_accuracy: 0.7126\n",
            "Epoch 108/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5167 - accuracy: 0.7284 - val_loss: 0.5333 - val_accuracy: 0.7126\n",
            "Epoch 109/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5163 - accuracy: 0.7259 - val_loss: 0.5330 - val_accuracy: 0.7126\n",
            "Epoch 110/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5160 - accuracy: 0.7259 - val_loss: 0.5328 - val_accuracy: 0.7126\n",
            "Epoch 111/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5159 - accuracy: 0.7309 - val_loss: 0.5325 - val_accuracy: 0.7069\n",
            "Epoch 112/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7259 - val_loss: 0.5322 - val_accuracy: 0.7126\n",
            "Epoch 113/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5151 - accuracy: 0.7259 - val_loss: 0.5321 - val_accuracy: 0.7126\n",
            "Epoch 114/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5150 - accuracy: 0.7259 - val_loss: 0.5319 - val_accuracy: 0.7126\n",
            "Epoch 115/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5147 - accuracy: 0.7284 - val_loss: 0.5318 - val_accuracy: 0.7126\n",
            "Epoch 116/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5144 - accuracy: 0.7259 - val_loss: 0.5316 - val_accuracy: 0.7126\n",
            "Epoch 117/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5142 - accuracy: 0.7284 - val_loss: 0.5316 - val_accuracy: 0.7126\n",
            "Epoch 118/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5138 - accuracy: 0.7333 - val_loss: 0.5313 - val_accuracy: 0.7126\n",
            "Epoch 119/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5138 - accuracy: 0.7309 - val_loss: 0.5311 - val_accuracy: 0.7126\n",
            "Epoch 120/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5133 - accuracy: 0.7333 - val_loss: 0.5309 - val_accuracy: 0.7126\n",
            "Epoch 121/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5132 - accuracy: 0.7358 - val_loss: 0.5308 - val_accuracy: 0.7126\n",
            "Epoch 122/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5128 - accuracy: 0.7358 - val_loss: 0.5305 - val_accuracy: 0.7184\n",
            "Epoch 123/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5127 - accuracy: 0.7333 - val_loss: 0.5304 - val_accuracy: 0.7126\n",
            "Epoch 124/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5125 - accuracy: 0.7309 - val_loss: 0.5304 - val_accuracy: 0.7126\n",
            "Epoch 125/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5121 - accuracy: 0.7333 - val_loss: 0.5302 - val_accuracy: 0.7126\n",
            "Epoch 126/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5119 - accuracy: 0.7333 - val_loss: 0.5299 - val_accuracy: 0.7126\n",
            "Epoch 127/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5118 - accuracy: 0.7333 - val_loss: 0.5298 - val_accuracy: 0.7126\n",
            "Epoch 128/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5114 - accuracy: 0.7309 - val_loss: 0.5295 - val_accuracy: 0.7126\n",
            "Epoch 129/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5112 - accuracy: 0.7333 - val_loss: 0.5293 - val_accuracy: 0.7126\n",
            "Epoch 130/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5108 - accuracy: 0.7309 - val_loss: 0.5291 - val_accuracy: 0.7126\n",
            "Epoch 131/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5107 - accuracy: 0.7333 - val_loss: 0.5289 - val_accuracy: 0.7126\n",
            "Epoch 132/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5103 - accuracy: 0.7358 - val_loss: 0.5289 - val_accuracy: 0.7126\n",
            "Epoch 133/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5101 - accuracy: 0.7284 - val_loss: 0.5287 - val_accuracy: 0.7126\n",
            "Epoch 134/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5098 - accuracy: 0.7309 - val_loss: 0.5285 - val_accuracy: 0.7126\n",
            "Epoch 135/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5098 - accuracy: 0.7259 - val_loss: 0.5286 - val_accuracy: 0.7126\n",
            "Epoch 136/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5093 - accuracy: 0.7284 - val_loss: 0.5283 - val_accuracy: 0.7126\n",
            "Epoch 137/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5091 - accuracy: 0.7309 - val_loss: 0.5283 - val_accuracy: 0.7126\n",
            "Epoch 138/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5089 - accuracy: 0.7309 - val_loss: 0.5281 - val_accuracy: 0.7184\n",
            "Epoch 139/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5085 - accuracy: 0.7259 - val_loss: 0.5280 - val_accuracy: 0.7184\n",
            "Epoch 140/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5083 - accuracy: 0.7259 - val_loss: 0.5278 - val_accuracy: 0.7184\n",
            "Epoch 141/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5080 - accuracy: 0.7259 - val_loss: 0.5277 - val_accuracy: 0.7184\n",
            "Epoch 142/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5079 - accuracy: 0.7259 - val_loss: 0.5274 - val_accuracy: 0.7184\n",
            "Epoch 143/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5076 - accuracy: 0.7235 - val_loss: 0.5272 - val_accuracy: 0.7184\n",
            "Epoch 144/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5073 - accuracy: 0.7259 - val_loss: 0.5272 - val_accuracy: 0.7184\n",
            "Epoch 145/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5072 - accuracy: 0.7235 - val_loss: 0.5272 - val_accuracy: 0.7184\n",
            "Epoch 146/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5069 - accuracy: 0.7235 - val_loss: 0.5269 - val_accuracy: 0.7184\n",
            "Epoch 147/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5067 - accuracy: 0.7235 - val_loss: 0.5267 - val_accuracy: 0.7184\n",
            "Epoch 148/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5064 - accuracy: 0.7235 - val_loss: 0.5265 - val_accuracy: 0.7184\n",
            "Epoch 149/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5063 - accuracy: 0.7259 - val_loss: 0.5263 - val_accuracy: 0.7184\n",
            "Epoch 150/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5060 - accuracy: 0.7235 - val_loss: 0.5261 - val_accuracy: 0.7184\n",
            "Epoch 151/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5058 - accuracy: 0.7259 - val_loss: 0.5259 - val_accuracy: 0.7184\n",
            "Epoch 152/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.7259 - val_loss: 0.5257 - val_accuracy: 0.7184\n",
            "Epoch 153/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.7235 - val_loss: 0.5257 - val_accuracy: 0.7184\n",
            "Epoch 154/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7259 - val_loss: 0.5255 - val_accuracy: 0.7184\n",
            "Epoch 155/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5049 - accuracy: 0.7259 - val_loss: 0.5254 - val_accuracy: 0.7184\n",
            "Epoch 156/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5047 - accuracy: 0.7309 - val_loss: 0.5252 - val_accuracy: 0.7184\n",
            "Epoch 157/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5044 - accuracy: 0.7259 - val_loss: 0.5250 - val_accuracy: 0.7184\n",
            "Epoch 158/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5043 - accuracy: 0.7235 - val_loss: 0.5249 - val_accuracy: 0.7184\n",
            "Epoch 159/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5040 - accuracy: 0.7235 - val_loss: 0.5249 - val_accuracy: 0.7241\n",
            "Epoch 160/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5039 - accuracy: 0.7284 - val_loss: 0.5247 - val_accuracy: 0.7184\n",
            "Epoch 161/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5037 - accuracy: 0.7259 - val_loss: 0.5246 - val_accuracy: 0.7241\n",
            "Epoch 162/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5033 - accuracy: 0.7259 - val_loss: 0.5244 - val_accuracy: 0.7241\n",
            "Epoch 163/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5032 - accuracy: 0.7284 - val_loss: 0.5243 - val_accuracy: 0.7241\n",
            "Epoch 164/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5030 - accuracy: 0.7259 - val_loss: 0.5243 - val_accuracy: 0.7184\n",
            "Epoch 165/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5028 - accuracy: 0.7309 - val_loss: 0.5242 - val_accuracy: 0.7184\n",
            "Epoch 166/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5026 - accuracy: 0.7259 - val_loss: 0.5240 - val_accuracy: 0.7184\n",
            "Epoch 167/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5025 - accuracy: 0.7457 - val_loss: 0.5239 - val_accuracy: 0.7184\n",
            "Epoch 168/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5022 - accuracy: 0.7333 - val_loss: 0.5238 - val_accuracy: 0.7184\n",
            "Epoch 169/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5020 - accuracy: 0.7358 - val_loss: 0.5236 - val_accuracy: 0.7184\n",
            "Epoch 170/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5019 - accuracy: 0.7284 - val_loss: 0.5237 - val_accuracy: 0.7184\n",
            "Epoch 171/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5015 - accuracy: 0.7309 - val_loss: 0.5236 - val_accuracy: 0.7184\n",
            "Epoch 172/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5014 - accuracy: 0.7407 - val_loss: 0.5236 - val_accuracy: 0.7126\n",
            "Epoch 173/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5011 - accuracy: 0.7383 - val_loss: 0.5235 - val_accuracy: 0.7126\n",
            "Epoch 174/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5010 - accuracy: 0.7407 - val_loss: 0.5234 - val_accuracy: 0.7126\n",
            "Epoch 175/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5007 - accuracy: 0.7407 - val_loss: 0.5232 - val_accuracy: 0.7126\n",
            "Epoch 176/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5005 - accuracy: 0.7407 - val_loss: 0.5232 - val_accuracy: 0.7126\n",
            "Epoch 177/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5002 - accuracy: 0.7407 - val_loss: 0.5230 - val_accuracy: 0.7126\n",
            "Epoch 178/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4999 - accuracy: 0.7432 - val_loss: 0.5229 - val_accuracy: 0.7126\n",
            "Epoch 179/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5000 - accuracy: 0.7407 - val_loss: 0.5228 - val_accuracy: 0.7126\n",
            "Epoch 180/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4996 - accuracy: 0.7432 - val_loss: 0.5227 - val_accuracy: 0.7126\n",
            "Epoch 181/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4993 - accuracy: 0.7407 - val_loss: 0.5227 - val_accuracy: 0.7126\n",
            "Epoch 182/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4990 - accuracy: 0.7432 - val_loss: 0.5225 - val_accuracy: 0.7126\n",
            "Epoch 183/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4988 - accuracy: 0.7407 - val_loss: 0.5225 - val_accuracy: 0.7011\n",
            "Epoch 184/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4988 - accuracy: 0.7432 - val_loss: 0.5222 - val_accuracy: 0.7011\n",
            "Epoch 185/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4985 - accuracy: 0.7432 - val_loss: 0.5223 - val_accuracy: 0.7011\n",
            "Epoch 186/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4981 - accuracy: 0.7432 - val_loss: 0.5220 - val_accuracy: 0.7011\n",
            "Epoch 187/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4981 - accuracy: 0.7432 - val_loss: 0.5219 - val_accuracy: 0.7011\n",
            "Epoch 188/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4978 - accuracy: 0.7407 - val_loss: 0.5217 - val_accuracy: 0.7011\n",
            "Epoch 189/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4976 - accuracy: 0.7383 - val_loss: 0.5215 - val_accuracy: 0.7011\n",
            "Epoch 190/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4975 - accuracy: 0.7407 - val_loss: 0.5216 - val_accuracy: 0.6897\n",
            "Epoch 191/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4971 - accuracy: 0.7432 - val_loss: 0.5212 - val_accuracy: 0.7011\n",
            "Epoch 192/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4969 - accuracy: 0.7407 - val_loss: 0.5209 - val_accuracy: 0.7069\n",
            "Epoch 193/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4969 - accuracy: 0.7383 - val_loss: 0.5208 - val_accuracy: 0.7011\n",
            "Epoch 194/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4966 - accuracy: 0.7383 - val_loss: 0.5206 - val_accuracy: 0.7011\n",
            "Epoch 195/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4964 - accuracy: 0.7358 - val_loss: 0.5207 - val_accuracy: 0.6897\n",
            "Epoch 196/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4961 - accuracy: 0.7407 - val_loss: 0.5206 - val_accuracy: 0.6897\n",
            "Epoch 197/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4959 - accuracy: 0.7457 - val_loss: 0.5204 - val_accuracy: 0.6897\n",
            "Epoch 198/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4959 - accuracy: 0.7407 - val_loss: 0.5203 - val_accuracy: 0.6897\n",
            "Epoch 199/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4955 - accuracy: 0.7432 - val_loss: 0.5202 - val_accuracy: 0.6897\n",
            "Epoch 200/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4953 - accuracy: 0.7383 - val_loss: 0.5201 - val_accuracy: 0.6897\n",
            "Epoch 201/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4951 - accuracy: 0.7383 - val_loss: 0.5199 - val_accuracy: 0.6897\n",
            "Epoch 202/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4950 - accuracy: 0.7383 - val_loss: 0.5200 - val_accuracy: 0.6897\n",
            "Epoch 203/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4948 - accuracy: 0.7407 - val_loss: 0.5199 - val_accuracy: 0.6897\n",
            "Epoch 204/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4947 - accuracy: 0.7383 - val_loss: 0.5198 - val_accuracy: 0.6897\n",
            "Epoch 205/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4943 - accuracy: 0.7358 - val_loss: 0.5196 - val_accuracy: 0.6897\n",
            "Epoch 206/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4942 - accuracy: 0.7383 - val_loss: 0.5195 - val_accuracy: 0.6897\n",
            "Epoch 207/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4942 - accuracy: 0.7383 - val_loss: 0.5190 - val_accuracy: 0.6897\n",
            "Epoch 208/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4937 - accuracy: 0.7407 - val_loss: 0.5189 - val_accuracy: 0.6897\n",
            "Epoch 209/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4936 - accuracy: 0.7432 - val_loss: 0.5188 - val_accuracy: 0.6897\n",
            "Epoch 210/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4934 - accuracy: 0.7432 - val_loss: 0.5189 - val_accuracy: 0.6897\n",
            "Epoch 211/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4932 - accuracy: 0.7432 - val_loss: 0.5185 - val_accuracy: 0.6897\n",
            "Epoch 212/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4929 - accuracy: 0.7383 - val_loss: 0.5183 - val_accuracy: 0.6897\n",
            "Epoch 213/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4929 - accuracy: 0.7383 - val_loss: 0.5183 - val_accuracy: 0.6897\n",
            "Epoch 214/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4926 - accuracy: 0.7432 - val_loss: 0.5180 - val_accuracy: 0.6897\n",
            "Epoch 215/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4925 - accuracy: 0.7407 - val_loss: 0.5179 - val_accuracy: 0.6897\n",
            "Epoch 216/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4922 - accuracy: 0.7407 - val_loss: 0.5179 - val_accuracy: 0.6897\n",
            "Epoch 217/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4919 - accuracy: 0.7407 - val_loss: 0.5178 - val_accuracy: 0.6897\n",
            "Epoch 218/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4918 - accuracy: 0.7432 - val_loss: 0.5178 - val_accuracy: 0.6897\n",
            "Epoch 219/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4917 - accuracy: 0.7383 - val_loss: 0.5179 - val_accuracy: 0.6897\n",
            "Epoch 220/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4915 - accuracy: 0.7432 - val_loss: 0.5176 - val_accuracy: 0.6897\n",
            "Epoch 221/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4913 - accuracy: 0.7407 - val_loss: 0.5175 - val_accuracy: 0.6897\n",
            "Epoch 222/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4911 - accuracy: 0.7457 - val_loss: 0.5174 - val_accuracy: 0.6897\n",
            "Epoch 223/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4910 - accuracy: 0.7383 - val_loss: 0.5174 - val_accuracy: 0.6897\n",
            "Epoch 224/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4908 - accuracy: 0.7457 - val_loss: 0.5172 - val_accuracy: 0.6897\n",
            "Epoch 225/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4906 - accuracy: 0.7432 - val_loss: 0.5171 - val_accuracy: 0.6897\n",
            "Epoch 226/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4905 - accuracy: 0.7432 - val_loss: 0.5169 - val_accuracy: 0.6897\n",
            "Epoch 227/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4903 - accuracy: 0.7407 - val_loss: 0.5168 - val_accuracy: 0.6897\n",
            "Epoch 228/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4901 - accuracy: 0.7481 - val_loss: 0.5168 - val_accuracy: 0.6897\n",
            "Epoch 229/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4900 - accuracy: 0.7481 - val_loss: 0.5164 - val_accuracy: 0.6897\n",
            "Epoch 230/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4898 - accuracy: 0.7407 - val_loss: 0.5163 - val_accuracy: 0.6897\n",
            "Epoch 231/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4895 - accuracy: 0.7383 - val_loss: 0.5162 - val_accuracy: 0.6897\n",
            "Epoch 232/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4894 - accuracy: 0.7432 - val_loss: 0.5164 - val_accuracy: 0.6954\n",
            "Epoch 233/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4894 - accuracy: 0.7407 - val_loss: 0.5164 - val_accuracy: 0.6954\n",
            "Epoch 234/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4891 - accuracy: 0.7481 - val_loss: 0.5162 - val_accuracy: 0.6954\n",
            "Epoch 235/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4889 - accuracy: 0.7383 - val_loss: 0.5163 - val_accuracy: 0.6954\n",
            "Epoch 236/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4887 - accuracy: 0.7457 - val_loss: 0.5162 - val_accuracy: 0.6954\n",
            "Epoch 237/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4887 - accuracy: 0.7432 - val_loss: 0.5160 - val_accuracy: 0.6954\n",
            "Epoch 238/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4885 - accuracy: 0.7457 - val_loss: 0.5162 - val_accuracy: 0.6954\n",
            "Epoch 239/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4886 - accuracy: 0.7383 - val_loss: 0.5163 - val_accuracy: 0.6954\n",
            "Epoch 240/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4882 - accuracy: 0.7481 - val_loss: 0.5160 - val_accuracy: 0.6954\n",
            "Epoch 241/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4880 - accuracy: 0.7506 - val_loss: 0.5155 - val_accuracy: 0.6954\n",
            "Epoch 242/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4878 - accuracy: 0.7432 - val_loss: 0.5155 - val_accuracy: 0.7011\n",
            "Epoch 243/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4876 - accuracy: 0.7407 - val_loss: 0.5155 - val_accuracy: 0.7011\n",
            "Epoch 244/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4876 - accuracy: 0.7457 - val_loss: 0.5151 - val_accuracy: 0.6954\n",
            "Epoch 245/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4874 - accuracy: 0.7432 - val_loss: 0.5150 - val_accuracy: 0.6954\n",
            "Epoch 246/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4871 - accuracy: 0.7407 - val_loss: 0.5148 - val_accuracy: 0.7011\n",
            "Epoch 247/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4873 - accuracy: 0.7407 - val_loss: 0.5147 - val_accuracy: 0.7126\n",
            "Epoch 248/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4870 - accuracy: 0.7432 - val_loss: 0.5146 - val_accuracy: 0.7126\n",
            "Epoch 249/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4869 - accuracy: 0.7407 - val_loss: 0.5147 - val_accuracy: 0.6954\n",
            "Epoch 250/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4868 - accuracy: 0.7481 - val_loss: 0.5147 - val_accuracy: 0.6839\n",
            "Epoch 251/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4864 - accuracy: 0.7457 - val_loss: 0.5145 - val_accuracy: 0.7011\n",
            "Epoch 252/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4863 - accuracy: 0.7407 - val_loss: 0.5145 - val_accuracy: 0.6839\n",
            "Epoch 253/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4862 - accuracy: 0.7407 - val_loss: 0.5145 - val_accuracy: 0.6839\n",
            "Epoch 254/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4862 - accuracy: 0.7432 - val_loss: 0.5143 - val_accuracy: 0.6897\n",
            "Epoch 255/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4858 - accuracy: 0.7432 - val_loss: 0.5143 - val_accuracy: 0.6897\n",
            "Epoch 256/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4859 - accuracy: 0.7432 - val_loss: 0.5143 - val_accuracy: 0.6897\n",
            "Epoch 257/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4857 - accuracy: 0.7432 - val_loss: 0.5144 - val_accuracy: 0.6897\n",
            "Epoch 258/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4856 - accuracy: 0.7432 - val_loss: 0.5141 - val_accuracy: 0.6839\n",
            "Epoch 259/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4855 - accuracy: 0.7457 - val_loss: 0.5140 - val_accuracy: 0.6897\n",
            "Epoch 260/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4853 - accuracy: 0.7432 - val_loss: 0.5138 - val_accuracy: 0.6954\n",
            "Epoch 261/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4853 - accuracy: 0.7432 - val_loss: 0.5138 - val_accuracy: 0.6954\n",
            "Epoch 262/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4851 - accuracy: 0.7457 - val_loss: 0.5136 - val_accuracy: 0.7011\n",
            "Epoch 263/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4850 - accuracy: 0.7457 - val_loss: 0.5134 - val_accuracy: 0.7126\n",
            "Epoch 264/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4850 - accuracy: 0.7432 - val_loss: 0.5135 - val_accuracy: 0.7011\n",
            "Epoch 265/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4848 - accuracy: 0.7432 - val_loss: 0.5134 - val_accuracy: 0.7011\n",
            "Epoch 266/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4846 - accuracy: 0.7432 - val_loss: 0.5134 - val_accuracy: 0.6954\n",
            "Epoch 267/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4844 - accuracy: 0.7383 - val_loss: 0.5134 - val_accuracy: 0.6954\n",
            "Epoch 268/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4844 - accuracy: 0.7457 - val_loss: 0.5134 - val_accuracy: 0.6954\n",
            "Epoch 269/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7457 - val_loss: 0.5131 - val_accuracy: 0.7011\n",
            "Epoch 270/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7481 - val_loss: 0.5130 - val_accuracy: 0.7011\n",
            "Epoch 271/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4838 - accuracy: 0.7457 - val_loss: 0.5129 - val_accuracy: 0.7126\n",
            "Epoch 272/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4839 - accuracy: 0.7457 - val_loss: 0.5128 - val_accuracy: 0.7126\n",
            "Epoch 273/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4839 - accuracy: 0.7457 - val_loss: 0.5129 - val_accuracy: 0.7011\n",
            "Epoch 274/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4836 - accuracy: 0.7432 - val_loss: 0.5127 - val_accuracy: 0.7011\n",
            "Epoch 275/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4834 - accuracy: 0.7457 - val_loss: 0.5127 - val_accuracy: 0.7011\n",
            "Epoch 276/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4834 - accuracy: 0.7432 - val_loss: 0.5127 - val_accuracy: 0.6954\n",
            "Epoch 277/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4833 - accuracy: 0.7432 - val_loss: 0.5128 - val_accuracy: 0.6897\n",
            "Epoch 278/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4830 - accuracy: 0.7506 - val_loss: 0.5126 - val_accuracy: 0.7011\n",
            "Epoch 279/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4830 - accuracy: 0.7506 - val_loss: 0.5123 - val_accuracy: 0.7126\n",
            "Epoch 280/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4827 - accuracy: 0.7481 - val_loss: 0.5121 - val_accuracy: 0.7126\n",
            "Epoch 281/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4828 - accuracy: 0.7432 - val_loss: 0.5117 - val_accuracy: 0.7126\n",
            "Epoch 282/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4828 - accuracy: 0.7358 - val_loss: 0.5121 - val_accuracy: 0.7126\n",
            "Epoch 283/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4826 - accuracy: 0.7506 - val_loss: 0.5121 - val_accuracy: 0.7069\n",
            "Epoch 284/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4826 - accuracy: 0.7457 - val_loss: 0.5122 - val_accuracy: 0.7011\n",
            "Epoch 285/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4822 - accuracy: 0.7481 - val_loss: 0.5120 - val_accuracy: 0.7011\n",
            "Epoch 286/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.4820 - accuracy: 0.7481 - val_loss: 0.5119 - val_accuracy: 0.7011\n",
            "Epoch 287/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4823 - accuracy: 0.7506 - val_loss: 0.5119 - val_accuracy: 0.7069\n",
            "Epoch 288/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4818 - accuracy: 0.7432 - val_loss: 0.5120 - val_accuracy: 0.7069\n",
            "Epoch 289/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4816 - accuracy: 0.7481 - val_loss: 0.5120 - val_accuracy: 0.7069\n",
            "Epoch 290/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4817 - accuracy: 0.7457 - val_loss: 0.5121 - val_accuracy: 0.6954\n",
            "Epoch 291/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4816 - accuracy: 0.7506 - val_loss: 0.5120 - val_accuracy: 0.7069\n",
            "Epoch 292/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4814 - accuracy: 0.7481 - val_loss: 0.5120 - val_accuracy: 0.7069\n",
            "Epoch 293/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4814 - accuracy: 0.7457 - val_loss: 0.5123 - val_accuracy: 0.6954\n",
            "Epoch 294/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4811 - accuracy: 0.7506 - val_loss: 0.5119 - val_accuracy: 0.7069\n",
            "Epoch 295/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4809 - accuracy: 0.7457 - val_loss: 0.5116 - val_accuracy: 0.7069\n",
            "Epoch 296/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4810 - accuracy: 0.7457 - val_loss: 0.5118 - val_accuracy: 0.7011\n",
            "Epoch 297/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4809 - accuracy: 0.7506 - val_loss: 0.5116 - val_accuracy: 0.7011\n",
            "Epoch 298/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4806 - accuracy: 0.7506 - val_loss: 0.5115 - val_accuracy: 0.7069\n",
            "Epoch 299/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4806 - accuracy: 0.7481 - val_loss: 0.5115 - val_accuracy: 0.7069\n",
            "Epoch 300/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4804 - accuracy: 0.7506 - val_loss: 0.5114 - val_accuracy: 0.7069\n",
            "Epoch 301/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4803 - accuracy: 0.7481 - val_loss: 0.5114 - val_accuracy: 0.7069\n",
            "Epoch 302/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4802 - accuracy: 0.7506 - val_loss: 0.5116 - val_accuracy: 0.7069\n",
            "Epoch 303/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4802 - accuracy: 0.7457 - val_loss: 0.5116 - val_accuracy: 0.7069\n",
            "Epoch 304/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4798 - accuracy: 0.7506 - val_loss: 0.5114 - val_accuracy: 0.7011\n",
            "Epoch 305/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4798 - accuracy: 0.7481 - val_loss: 0.5114 - val_accuracy: 0.7011\n",
            "Epoch 306/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4796 - accuracy: 0.7506 - val_loss: 0.5111 - val_accuracy: 0.7069\n",
            "Epoch 307/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4796 - accuracy: 0.7481 - val_loss: 0.5112 - val_accuracy: 0.7069\n",
            "Epoch 308/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4798 - accuracy: 0.7457 - val_loss: 0.5112 - val_accuracy: 0.7069\n",
            "Epoch 309/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4795 - accuracy: 0.7506 - val_loss: 0.5109 - val_accuracy: 0.7069\n",
            "Epoch 310/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4792 - accuracy: 0.7531 - val_loss: 0.5108 - val_accuracy: 0.7069\n",
            "Epoch 311/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4792 - accuracy: 0.7531 - val_loss: 0.5106 - val_accuracy: 0.7069\n",
            "Epoch 312/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4791 - accuracy: 0.7531 - val_loss: 0.5103 - val_accuracy: 0.7126\n",
            "Epoch 313/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4788 - accuracy: 0.7481 - val_loss: 0.5103 - val_accuracy: 0.7126\n",
            "Epoch 314/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4790 - accuracy: 0.7506 - val_loss: 0.5103 - val_accuracy: 0.7126\n",
            "Epoch 315/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4787 - accuracy: 0.7481 - val_loss: 0.5102 - val_accuracy: 0.7126\n",
            "Epoch 316/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4786 - accuracy: 0.7407 - val_loss: 0.5105 - val_accuracy: 0.7126\n",
            "Epoch 317/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4784 - accuracy: 0.7506 - val_loss: 0.5102 - val_accuracy: 0.7126\n",
            "Epoch 318/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4784 - accuracy: 0.7481 - val_loss: 0.5104 - val_accuracy: 0.7126\n",
            "Epoch 319/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4781 - accuracy: 0.7531 - val_loss: 0.5103 - val_accuracy: 0.7184\n",
            "Epoch 320/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4782 - accuracy: 0.7506 - val_loss: 0.5104 - val_accuracy: 0.7126\n",
            "Epoch 321/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4781 - accuracy: 0.7481 - val_loss: 0.5102 - val_accuracy: 0.7126\n",
            "Epoch 322/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4779 - accuracy: 0.7506 - val_loss: 0.5100 - val_accuracy: 0.7184\n",
            "Epoch 323/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4779 - accuracy: 0.7481 - val_loss: 0.5100 - val_accuracy: 0.7184\n",
            "Epoch 324/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4778 - accuracy: 0.7580 - val_loss: 0.5097 - val_accuracy: 0.7184\n",
            "Epoch 325/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4779 - accuracy: 0.7457 - val_loss: 0.5097 - val_accuracy: 0.7184\n",
            "Epoch 326/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4775 - accuracy: 0.7506 - val_loss: 0.5096 - val_accuracy: 0.7184\n",
            "Epoch 327/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4776 - accuracy: 0.7506 - val_loss: 0.5096 - val_accuracy: 0.7184\n",
            "Epoch 328/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4775 - accuracy: 0.7506 - val_loss: 0.5096 - val_accuracy: 0.7184\n",
            "Epoch 329/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4775 - accuracy: 0.7481 - val_loss: 0.5094 - val_accuracy: 0.7184\n",
            "Epoch 330/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4772 - accuracy: 0.7531 - val_loss: 0.5094 - val_accuracy: 0.7184\n",
            "Epoch 331/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4771 - accuracy: 0.7506 - val_loss: 0.5093 - val_accuracy: 0.7184\n",
            "Epoch 332/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4770 - accuracy: 0.7481 - val_loss: 0.5093 - val_accuracy: 0.7184\n",
            "Epoch 333/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4771 - accuracy: 0.7506 - val_loss: 0.5093 - val_accuracy: 0.7184\n",
            "Epoch 334/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4766 - accuracy: 0.7531 - val_loss: 0.5093 - val_accuracy: 0.7184\n",
            "Epoch 335/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4767 - accuracy: 0.7506 - val_loss: 0.5093 - val_accuracy: 0.7184\n",
            "Epoch 336/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4767 - accuracy: 0.7556 - val_loss: 0.5092 - val_accuracy: 0.7184\n",
            "Epoch 337/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4766 - accuracy: 0.7506 - val_loss: 0.5090 - val_accuracy: 0.7184\n",
            "Epoch 338/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4764 - accuracy: 0.7506 - val_loss: 0.5090 - val_accuracy: 0.7184\n",
            "Epoch 339/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4765 - accuracy: 0.7506 - val_loss: 0.5092 - val_accuracy: 0.7184\n",
            "Epoch 340/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4764 - accuracy: 0.7556 - val_loss: 0.5089 - val_accuracy: 0.7184\n",
            "Epoch 341/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4762 - accuracy: 0.7481 - val_loss: 0.5093 - val_accuracy: 0.7184\n",
            "Epoch 342/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4759 - accuracy: 0.7556 - val_loss: 0.5094 - val_accuracy: 0.7184\n",
            "Epoch 343/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4758 - accuracy: 0.7506 - val_loss: 0.5092 - val_accuracy: 0.7184\n",
            "Epoch 344/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4758 - accuracy: 0.7556 - val_loss: 0.5093 - val_accuracy: 0.7184\n",
            "Epoch 345/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4757 - accuracy: 0.7580 - val_loss: 0.5092 - val_accuracy: 0.7184\n",
            "Epoch 346/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4755 - accuracy: 0.7580 - val_loss: 0.5091 - val_accuracy: 0.7184\n",
            "Epoch 347/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4756 - accuracy: 0.7605 - val_loss: 0.5091 - val_accuracy: 0.7241\n",
            "Epoch 348/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4754 - accuracy: 0.7556 - val_loss: 0.5089 - val_accuracy: 0.7184\n",
            "Epoch 349/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4753 - accuracy: 0.7531 - val_loss: 0.5089 - val_accuracy: 0.7241\n",
            "Epoch 350/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4750 - accuracy: 0.7580 - val_loss: 0.5089 - val_accuracy: 0.7241\n",
            "Epoch 351/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4751 - accuracy: 0.7580 - val_loss: 0.5088 - val_accuracy: 0.7241\n",
            "Epoch 352/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4748 - accuracy: 0.7556 - val_loss: 0.5086 - val_accuracy: 0.7241\n",
            "Epoch 353/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4752 - accuracy: 0.7556 - val_loss: 0.5088 - val_accuracy: 0.7241\n",
            "Epoch 354/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4746 - accuracy: 0.7605 - val_loss: 0.5088 - val_accuracy: 0.7241\n",
            "Epoch 355/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4746 - accuracy: 0.7556 - val_loss: 0.5086 - val_accuracy: 0.7241\n",
            "Epoch 356/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4748 - accuracy: 0.7556 - val_loss: 0.5087 - val_accuracy: 0.7241\n",
            "Epoch 357/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4746 - accuracy: 0.7556 - val_loss: 0.5088 - val_accuracy: 0.7241\n",
            "Epoch 358/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4744 - accuracy: 0.7580 - val_loss: 0.5086 - val_accuracy: 0.7241\n",
            "Epoch 359/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4742 - accuracy: 0.7556 - val_loss: 0.5083 - val_accuracy: 0.7241\n",
            "Epoch 360/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4743 - accuracy: 0.7531 - val_loss: 0.5085 - val_accuracy: 0.7241\n",
            "Epoch 361/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4741 - accuracy: 0.7605 - val_loss: 0.5085 - val_accuracy: 0.7241\n",
            "Epoch 362/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4744 - accuracy: 0.7580 - val_loss: 0.5086 - val_accuracy: 0.7241\n",
            "Epoch 363/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4740 - accuracy: 0.7580 - val_loss: 0.5086 - val_accuracy: 0.7241\n",
            "Epoch 364/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4739 - accuracy: 0.7630 - val_loss: 0.5085 - val_accuracy: 0.7241\n",
            "Epoch 365/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4740 - accuracy: 0.7580 - val_loss: 0.5085 - val_accuracy: 0.7241\n",
            "Epoch 366/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4738 - accuracy: 0.7580 - val_loss: 0.5082 - val_accuracy: 0.7241\n",
            "Epoch 367/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4736 - accuracy: 0.7556 - val_loss: 0.5083 - val_accuracy: 0.7241\n",
            "Epoch 368/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4736 - accuracy: 0.7556 - val_loss: 0.5084 - val_accuracy: 0.7241\n",
            "Epoch 369/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4733 - accuracy: 0.7531 - val_loss: 0.5084 - val_accuracy: 0.7241\n",
            "Epoch 370/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4732 - accuracy: 0.7605 - val_loss: 0.5082 - val_accuracy: 0.7241\n",
            "Epoch 371/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4730 - accuracy: 0.7580 - val_loss: 0.5081 - val_accuracy: 0.7299\n",
            "Epoch 372/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4732 - accuracy: 0.7531 - val_loss: 0.5081 - val_accuracy: 0.7299\n",
            "Epoch 373/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4730 - accuracy: 0.7531 - val_loss: 0.5080 - val_accuracy: 0.7299\n",
            "Epoch 374/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4729 - accuracy: 0.7580 - val_loss: 0.5077 - val_accuracy: 0.7299\n",
            "Epoch 375/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4731 - accuracy: 0.7580 - val_loss: 0.5078 - val_accuracy: 0.7299\n",
            "Epoch 376/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4729 - accuracy: 0.7481 - val_loss: 0.5080 - val_accuracy: 0.7241\n",
            "Epoch 377/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4727 - accuracy: 0.7654 - val_loss: 0.5078 - val_accuracy: 0.7299\n",
            "Epoch 378/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4726 - accuracy: 0.7580 - val_loss: 0.5080 - val_accuracy: 0.7299\n",
            "Epoch 379/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4725 - accuracy: 0.7556 - val_loss: 0.5080 - val_accuracy: 0.7299\n",
            "Epoch 380/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4724 - accuracy: 0.7580 - val_loss: 0.5082 - val_accuracy: 0.7241\n",
            "Epoch 381/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4724 - accuracy: 0.7556 - val_loss: 0.5086 - val_accuracy: 0.7241\n",
            "Epoch 382/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4726 - accuracy: 0.7580 - val_loss: 0.5084 - val_accuracy: 0.7241\n",
            "Epoch 383/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4724 - accuracy: 0.7654 - val_loss: 0.5087 - val_accuracy: 0.7241\n",
            "Epoch 384/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4724 - accuracy: 0.7580 - val_loss: 0.5085 - val_accuracy: 0.7241\n",
            "Epoch 385/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4719 - accuracy: 0.7654 - val_loss: 0.5085 - val_accuracy: 0.7241\n",
            "Epoch 386/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4722 - accuracy: 0.7531 - val_loss: 0.5085 - val_accuracy: 0.7241\n",
            "Epoch 387/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4717 - accuracy: 0.7556 - val_loss: 0.5086 - val_accuracy: 0.7241\n",
            "Epoch 388/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4719 - accuracy: 0.7580 - val_loss: 0.5085 - val_accuracy: 0.7241\n",
            "Epoch 389/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4716 - accuracy: 0.7580 - val_loss: 0.5084 - val_accuracy: 0.7241\n",
            "Epoch 390/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4716 - accuracy: 0.7605 - val_loss: 0.5081 - val_accuracy: 0.7241\n",
            "Epoch 391/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4717 - accuracy: 0.7580 - val_loss: 0.5079 - val_accuracy: 0.7299\n",
            "Epoch 392/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4715 - accuracy: 0.7531 - val_loss: 0.5080 - val_accuracy: 0.7299\n",
            "Epoch 393/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4712 - accuracy: 0.7605 - val_loss: 0.5082 - val_accuracy: 0.7241\n",
            "Epoch 394/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.4713 - accuracy: 0.7556 - val_loss: 0.5083 - val_accuracy: 0.7241\n",
            "Epoch 395/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4712 - accuracy: 0.7630 - val_loss: 0.5081 - val_accuracy: 0.7299\n",
            "Epoch 396/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4709 - accuracy: 0.7556 - val_loss: 0.5082 - val_accuracy: 0.7241\n",
            "Epoch 397/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4711 - accuracy: 0.7630 - val_loss: 0.5080 - val_accuracy: 0.7299\n",
            "Epoch 398/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4711 - accuracy: 0.7580 - val_loss: 0.5081 - val_accuracy: 0.7299\n",
            "Epoch 399/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4709 - accuracy: 0.7556 - val_loss: 0.5081 - val_accuracy: 0.7241\n",
            "Epoch 400/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4711 - accuracy: 0.7580 - val_loss: 0.5084 - val_accuracy: 0.7241\n",
            "Epoch 401/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.4707 - accuracy: 0.7580 - val_loss: 0.5086 - val_accuracy: 0.7241\n",
            "Epoch 402/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4711 - accuracy: 0.7556 - val_loss: 0.5088 - val_accuracy: 0.7241\n",
            "Epoch 403/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4707 - accuracy: 0.7630 - val_loss: 0.5085 - val_accuracy: 0.7241\n",
            "Epoch 404/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4705 - accuracy: 0.7580 - val_loss: 0.5082 - val_accuracy: 0.7241\n",
            "Epoch 405/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.4704 - accuracy: 0.7605 - val_loss: 0.5082 - val_accuracy: 0.7241\n",
            "Epoch 406/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4707 - accuracy: 0.7556 - val_loss: 0.5086 - val_accuracy: 0.7241\n",
            "Epoch 407/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4703 - accuracy: 0.7605 - val_loss: 0.5085 - val_accuracy: 0.7241\n",
            "Epoch 408/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4703 - accuracy: 0.7580 - val_loss: 0.5084 - val_accuracy: 0.7241\n",
            "Epoch 409/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4701 - accuracy: 0.7556 - val_loss: 0.5085 - val_accuracy: 0.7241\n",
            "Epoch 410/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4703 - accuracy: 0.7580 - val_loss: 0.5084 - val_accuracy: 0.7241\n",
            "Epoch 411/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4701 - accuracy: 0.7580 - val_loss: 0.5081 - val_accuracy: 0.7241\n",
            "Epoch 412/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4700 - accuracy: 0.7556 - val_loss: 0.5079 - val_accuracy: 0.7299\n",
            "Epoch 413/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4698 - accuracy: 0.7556 - val_loss: 0.5083 - val_accuracy: 0.7241\n",
            "Epoch 414/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4698 - accuracy: 0.7605 - val_loss: 0.5082 - val_accuracy: 0.7299\n",
            "Epoch 415/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4701 - accuracy: 0.7556 - val_loss: 0.5083 - val_accuracy: 0.7241\n",
            "Epoch 416/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4696 - accuracy: 0.7580 - val_loss: 0.5085 - val_accuracy: 0.7241\n",
            "Epoch 417/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4698 - accuracy: 0.7630 - val_loss: 0.5089 - val_accuracy: 0.7241\n",
            "Epoch 418/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4697 - accuracy: 0.7704 - val_loss: 0.5086 - val_accuracy: 0.7241\n",
            "Epoch 419/500\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.4696 - accuracy: 0.7580 - val_loss: 0.5084 - val_accuracy: 0.7241\n",
            "Epoch 420/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4695 - accuracy: 0.7605 - val_loss: 0.5085 - val_accuracy: 0.7241\n",
            "Epoch 421/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4695 - accuracy: 0.7630 - val_loss: 0.5084 - val_accuracy: 0.7241\n",
            "Epoch 422/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4696 - accuracy: 0.7531 - val_loss: 0.5086 - val_accuracy: 0.7241\n",
            "Epoch 423/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4694 - accuracy: 0.7531 - val_loss: 0.5089 - val_accuracy: 0.7241\n",
            "Epoch 424/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4692 - accuracy: 0.7531 - val_loss: 0.5089 - val_accuracy: 0.7241\n",
            "Epoch 425/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4695 - accuracy: 0.7630 - val_loss: 0.5090 - val_accuracy: 0.7241\n",
            "Epoch 426/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4694 - accuracy: 0.7506 - val_loss: 0.5090 - val_accuracy: 0.7241\n",
            "Epoch 427/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4690 - accuracy: 0.7605 - val_loss: 0.5086 - val_accuracy: 0.7241\n",
            "Epoch 428/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4690 - accuracy: 0.7605 - val_loss: 0.5083 - val_accuracy: 0.7241\n",
            "Epoch 429/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4691 - accuracy: 0.7630 - val_loss: 0.5080 - val_accuracy: 0.7299\n",
            "Epoch 430/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4688 - accuracy: 0.7506 - val_loss: 0.5087 - val_accuracy: 0.7241\n",
            "Epoch 431/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4692 - accuracy: 0.7605 - val_loss: 0.5083 - val_accuracy: 0.7241\n",
            "Epoch 432/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4689 - accuracy: 0.7630 - val_loss: 0.5084 - val_accuracy: 0.7241\n",
            "Epoch 433/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.4690 - accuracy: 0.7556 - val_loss: 0.5086 - val_accuracy: 0.7241\n",
            "Epoch 434/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4688 - accuracy: 0.7654 - val_loss: 0.5084 - val_accuracy: 0.7241\n",
            "Epoch 435/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4685 - accuracy: 0.7605 - val_loss: 0.5083 - val_accuracy: 0.7241\n",
            "Epoch 436/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.4685 - accuracy: 0.7506 - val_loss: 0.5084 - val_accuracy: 0.7241\n",
            "Epoch 437/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4684 - accuracy: 0.7556 - val_loss: 0.5081 - val_accuracy: 0.7299\n",
            "Epoch 438/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4685 - accuracy: 0.7630 - val_loss: 0.5082 - val_accuracy: 0.7299\n",
            "Epoch 439/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4685 - accuracy: 0.7556 - val_loss: 0.5083 - val_accuracy: 0.7299\n",
            "Epoch 440/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4681 - accuracy: 0.7580 - val_loss: 0.5086 - val_accuracy: 0.7241\n",
            "Epoch 441/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4682 - accuracy: 0.7556 - val_loss: 0.5088 - val_accuracy: 0.7241\n",
            "Epoch 442/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4681 - accuracy: 0.7580 - val_loss: 0.5087 - val_accuracy: 0.7241\n",
            "Epoch 443/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4678 - accuracy: 0.7605 - val_loss: 0.5085 - val_accuracy: 0.7241\n",
            "Epoch 444/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4679 - accuracy: 0.7630 - val_loss: 0.5087 - val_accuracy: 0.7241\n",
            "Epoch 445/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4680 - accuracy: 0.7630 - val_loss: 0.5085 - val_accuracy: 0.7241\n",
            "Epoch 446/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4681 - accuracy: 0.7630 - val_loss: 0.5082 - val_accuracy: 0.7299\n",
            "Epoch 447/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.4679 - accuracy: 0.7630 - val_loss: 0.5080 - val_accuracy: 0.7299\n",
            "Epoch 448/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4676 - accuracy: 0.7580 - val_loss: 0.5081 - val_accuracy: 0.7299\n",
            "Epoch 449/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4675 - accuracy: 0.7580 - val_loss: 0.5081 - val_accuracy: 0.7356\n",
            "Epoch 450/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.4676 - accuracy: 0.7556 - val_loss: 0.5083 - val_accuracy: 0.7299\n",
            "Epoch 451/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4676 - accuracy: 0.7654 - val_loss: 0.5082 - val_accuracy: 0.7356\n",
            "Epoch 452/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4674 - accuracy: 0.7580 - val_loss: 0.5084 - val_accuracy: 0.7299\n",
            "Epoch 453/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4675 - accuracy: 0.7630 - val_loss: 0.5086 - val_accuracy: 0.7299\n",
            "Epoch 454/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.7580 - val_loss: 0.5085 - val_accuracy: 0.7241\n",
            "Epoch 455/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7630 - val_loss: 0.5081 - val_accuracy: 0.7356\n",
            "Epoch 456/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7630 - val_loss: 0.5080 - val_accuracy: 0.7356\n",
            "Epoch 457/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7556 - val_loss: 0.5078 - val_accuracy: 0.7356\n",
            "Epoch 458/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7605 - val_loss: 0.5077 - val_accuracy: 0.7356\n",
            "Epoch 459/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4674 - accuracy: 0.7531 - val_loss: 0.5080 - val_accuracy: 0.7356\n",
            "Epoch 460/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.7580 - val_loss: 0.5080 - val_accuracy: 0.7356\n",
            "Epoch 461/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.7654 - val_loss: 0.5078 - val_accuracy: 0.7356\n",
            "Epoch 462/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.7580 - val_loss: 0.5077 - val_accuracy: 0.7356\n",
            "Epoch 463/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4669 - accuracy: 0.7654 - val_loss: 0.5074 - val_accuracy: 0.7356\n",
            "Epoch 464/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4669 - accuracy: 0.7531 - val_loss: 0.5075 - val_accuracy: 0.7356\n",
            "Epoch 465/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4667 - accuracy: 0.7630 - val_loss: 0.5076 - val_accuracy: 0.7356\n",
            "Epoch 466/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4666 - accuracy: 0.7556 - val_loss: 0.5078 - val_accuracy: 0.7356\n",
            "Epoch 467/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4667 - accuracy: 0.7556 - val_loss: 0.5081 - val_accuracy: 0.7356\n",
            "Epoch 468/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4664 - accuracy: 0.7605 - val_loss: 0.5081 - val_accuracy: 0.7356\n",
            "Epoch 469/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4664 - accuracy: 0.7704 - val_loss: 0.5082 - val_accuracy: 0.7356\n",
            "Epoch 470/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4666 - accuracy: 0.7605 - val_loss: 0.5082 - val_accuracy: 0.7299\n",
            "Epoch 471/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4663 - accuracy: 0.7630 - val_loss: 0.5083 - val_accuracy: 0.7299\n",
            "Epoch 472/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4663 - accuracy: 0.7630 - val_loss: 0.5083 - val_accuracy: 0.7299\n",
            "Epoch 473/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4664 - accuracy: 0.7630 - val_loss: 0.5084 - val_accuracy: 0.7299\n",
            "Epoch 474/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4663 - accuracy: 0.7556 - val_loss: 0.5083 - val_accuracy: 0.7299\n",
            "Epoch 475/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4662 - accuracy: 0.7654 - val_loss: 0.5080 - val_accuracy: 0.7356\n",
            "Epoch 476/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4660 - accuracy: 0.7605 - val_loss: 0.5081 - val_accuracy: 0.7299\n",
            "Epoch 477/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4661 - accuracy: 0.7630 - val_loss: 0.5082 - val_accuracy: 0.7299\n",
            "Epoch 478/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4661 - accuracy: 0.7679 - val_loss: 0.5080 - val_accuracy: 0.7356\n",
            "Epoch 479/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4659 - accuracy: 0.7630 - val_loss: 0.5082 - val_accuracy: 0.7299\n",
            "Epoch 480/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4661 - accuracy: 0.7654 - val_loss: 0.5079 - val_accuracy: 0.7356\n",
            "Epoch 481/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4657 - accuracy: 0.7580 - val_loss: 0.5079 - val_accuracy: 0.7356\n",
            "Epoch 482/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4657 - accuracy: 0.7630 - val_loss: 0.5082 - val_accuracy: 0.7299\n",
            "Epoch 483/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4654 - accuracy: 0.7654 - val_loss: 0.5081 - val_accuracy: 0.7356\n",
            "Epoch 484/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4657 - accuracy: 0.7654 - val_loss: 0.5079 - val_accuracy: 0.7356\n",
            "Epoch 485/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4655 - accuracy: 0.7679 - val_loss: 0.5078 - val_accuracy: 0.7356\n",
            "Epoch 486/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7580 - val_loss: 0.5077 - val_accuracy: 0.7356\n",
            "Epoch 487/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4655 - accuracy: 0.7630 - val_loss: 0.5075 - val_accuracy: 0.7356\n",
            "Epoch 488/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4655 - accuracy: 0.7556 - val_loss: 0.5074 - val_accuracy: 0.7356\n",
            "Epoch 489/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4654 - accuracy: 0.7531 - val_loss: 0.5077 - val_accuracy: 0.7356\n",
            "Epoch 490/500\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4653 - accuracy: 0.7605 - val_loss: 0.5078 - val_accuracy: 0.7356\n",
            "Epoch 491/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4651 - accuracy: 0.7605 - val_loss: 0.5079 - val_accuracy: 0.7356\n",
            "Epoch 492/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4653 - accuracy: 0.7556 - val_loss: 0.5081 - val_accuracy: 0.7356\n",
            "Epoch 493/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4649 - accuracy: 0.7630 - val_loss: 0.5081 - val_accuracy: 0.7356\n",
            "Epoch 494/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4653 - accuracy: 0.7556 - val_loss: 0.5083 - val_accuracy: 0.7299\n",
            "Epoch 495/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4649 - accuracy: 0.7654 - val_loss: 0.5083 - val_accuracy: 0.7356\n",
            "Epoch 496/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4650 - accuracy: 0.7630 - val_loss: 0.5085 - val_accuracy: 0.7299\n",
            "Epoch 497/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4649 - accuracy: 0.7654 - val_loss: 0.5083 - val_accuracy: 0.7356\n",
            "Epoch 498/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4649 - accuracy: 0.7580 - val_loss: 0.5084 - val_accuracy: 0.7299\n",
            "Epoch 499/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4649 - accuracy: 0.7605 - val_loss: 0.5088 - val_accuracy: 0.7299\n",
            "Epoch 500/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4647 - accuracy: 0.7630 - val_loss: 0.5089 - val_accuracy: 0.7299\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CL9g7kpnHuWM",
        "outputId": "c09b8cc7-7675-44c0-f83c-ba316bc53203",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "r4.history['loss']"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9296666383743286,\n",
              " 0.8147178888320923,\n",
              " 0.7418076992034912,\n",
              " 0.6933284997940063,\n",
              " 0.6601186990737915,\n",
              " 0.6362630724906921,\n",
              " 0.6186575889587402,\n",
              " 0.6053895950317383,\n",
              " 0.595370352268219,\n",
              " 0.587706983089447,\n",
              " 0.581221878528595,\n",
              " 0.5757888555526733,\n",
              " 0.5713804364204407,\n",
              " 0.5678577423095703,\n",
              " 0.5649436116218567,\n",
              " 0.5622843503952026,\n",
              " 0.5603090524673462,\n",
              " 0.5585131049156189,\n",
              " 0.557013750076294,\n",
              " 0.5556607246398926,\n",
              " 0.5544983148574829,\n",
              " 0.5534711480140686,\n",
              " 0.5523397326469421,\n",
              " 0.551551103591919,\n",
              " 0.55058753490448,\n",
              " 0.5498431921005249,\n",
              " 0.5489808917045593,\n",
              " 0.5483192801475525,\n",
              " 0.5477028489112854,\n",
              " 0.5469892621040344,\n",
              " 0.5464160442352295,\n",
              " 0.5458080768585205,\n",
              " 0.5452483892440796,\n",
              " 0.5445365309715271,\n",
              " 0.5439522862434387,\n",
              " 0.5434050559997559,\n",
              " 0.5428576469421387,\n",
              " 0.5422585010528564,\n",
              " 0.5417096018791199,\n",
              " 0.5412766337394714,\n",
              " 0.5407065153121948,\n",
              " 0.5402344465255737,\n",
              " 0.5398337244987488,\n",
              " 0.5392670035362244,\n",
              " 0.5388115644454956,\n",
              " 0.5382701754570007,\n",
              " 0.5377756357192993,\n",
              " 0.5373165607452393,\n",
              " 0.5369163155555725,\n",
              " 0.5363580584526062,\n",
              " 0.5359329581260681,\n",
              " 0.5355201959609985,\n",
              " 0.535045862197876,\n",
              " 0.5346657633781433,\n",
              " 0.5342475771903992,\n",
              " 0.5339605808258057,\n",
              " 0.5334413647651672,\n",
              " 0.5330823063850403,\n",
              " 0.5326896905899048,\n",
              " 0.5322718024253845,\n",
              " 0.5318403840065002,\n",
              " 0.5314493775367737,\n",
              " 0.5310949087142944,\n",
              " 0.5307743549346924,\n",
              " 0.5302700996398926,\n",
              " 0.5300682187080383,\n",
              " 0.5296550393104553,\n",
              " 0.529289186000824,\n",
              " 0.5289081931114197,\n",
              " 0.528436005115509,\n",
              " 0.5283483266830444,\n",
              " 0.5278800129890442,\n",
              " 0.5275020599365234,\n",
              " 0.5272155404090881,\n",
              " 0.5267939567565918,\n",
              " 0.5263959169387817,\n",
              " 0.5259904861450195,\n",
              " 0.5257192850112915,\n",
              " 0.5254825353622437,\n",
              " 0.5251586437225342,\n",
              " 0.5247341990470886,\n",
              " 0.5244213938713074,\n",
              " 0.5241059064865112,\n",
              " 0.5238205194473267,\n",
              " 0.5235059857368469,\n",
              " 0.5231311321258545,\n",
              " 0.5228688716888428,\n",
              " 0.5225383043289185,\n",
              " 0.5221955180168152,\n",
              " 0.5218885540962219,\n",
              " 0.5215216279029846,\n",
              " 0.5212765336036682,\n",
              " 0.5210679769515991,\n",
              " 0.5207739472389221,\n",
              " 0.5205245614051819,\n",
              " 0.5201177000999451,\n",
              " 0.5198520421981812,\n",
              " 0.5193885564804077,\n",
              " 0.5191065073013306,\n",
              " 0.5187612175941467,\n",
              " 0.5184961557388306,\n",
              " 0.5181856155395508,\n",
              " 0.5179591774940491,\n",
              " 0.5176002979278564,\n",
              " 0.5174304842948914,\n",
              " 0.5171511173248291,\n",
              " 0.5168575644493103,\n",
              " 0.5166542530059814,\n",
              " 0.5163347125053406,\n",
              " 0.51597660779953,\n",
              " 0.5158703923225403,\n",
              " 0.5156163573265076,\n",
              " 0.5151102542877197,\n",
              " 0.5149933099746704,\n",
              " 0.5146846175193787,\n",
              " 0.5144035220146179,\n",
              " 0.5141704678535461,\n",
              " 0.5138387084007263,\n",
              " 0.5137766003608704,\n",
              " 0.5132864713668823,\n",
              " 0.5132116079330444,\n",
              " 0.512831449508667,\n",
              " 0.5126509070396423,\n",
              " 0.5125335454940796,\n",
              " 0.5121338367462158,\n",
              " 0.5119360089302063,\n",
              " 0.5117606520652771,\n",
              " 0.5114232301712036,\n",
              " 0.5111984014511108,\n",
              " 0.5108461976051331,\n",
              " 0.5106602907180786,\n",
              " 0.5103346705436707,\n",
              " 0.5100675821304321,\n",
              " 0.5098430514335632,\n",
              " 0.5097505450248718,\n",
              " 0.5092704892158508,\n",
              " 0.5091228485107422,\n",
              " 0.5089011192321777,\n",
              " 0.5085365772247314,\n",
              " 0.5082959532737732,\n",
              " 0.5079920887947083,\n",
              " 0.5079343914985657,\n",
              " 0.5075993537902832,\n",
              " 0.5073258876800537,\n",
              " 0.5071825385093689,\n",
              " 0.5069006681442261,\n",
              " 0.5067183971405029,\n",
              " 0.5063574910163879,\n",
              " 0.5062675476074219,\n",
              " 0.5059567093849182,\n",
              " 0.5057882070541382,\n",
              " 0.5054616928100586,\n",
              " 0.5052924752235413,\n",
              " 0.5051463842391968,\n",
              " 0.5049422383308411,\n",
              " 0.5046536326408386,\n",
              " 0.5044307112693787,\n",
              " 0.5042964816093445,\n",
              " 0.5040006041526794,\n",
              " 0.5038933753967285,\n",
              " 0.5037222504615784,\n",
              " 0.5033480525016785,\n",
              " 0.503235936164856,\n",
              " 0.5029775500297546,\n",
              " 0.502802312374115,\n",
              " 0.502562403678894,\n",
              " 0.5024861097335815,\n",
              " 0.5021640062332153,\n",
              " 0.5020073652267456,\n",
              " 0.501896321773529,\n",
              " 0.5015402436256409,\n",
              " 0.5013734698295593,\n",
              " 0.5010758638381958,\n",
              " 0.5010214447975159,\n",
              " 0.5007343292236328,\n",
              " 0.5005468726158142,\n",
              " 0.5001891255378723,\n",
              " 0.4999232888221741,\n",
              " 0.4999692142009735,\n",
              " 0.49962061643600464,\n",
              " 0.49929729104042053,\n",
              " 0.4990387260913849,\n",
              " 0.4988313317298889,\n",
              " 0.4987523555755615,\n",
              " 0.4984770715236664,\n",
              " 0.4980928897857666,\n",
              " 0.4981358051300049,\n",
              " 0.4977819621562958,\n",
              " 0.4975755512714386,\n",
              " 0.49745121598243713,\n",
              " 0.4971276819705963,\n",
              " 0.4968521296977997,\n",
              " 0.4968782663345337,\n",
              " 0.4965950548648834,\n",
              " 0.496359258890152,\n",
              " 0.49613192677497864,\n",
              " 0.4958980679512024,\n",
              " 0.49586424231529236,\n",
              " 0.49554744362831116,\n",
              " 0.4953155219554901,\n",
              " 0.4950621426105499,\n",
              " 0.4950094223022461,\n",
              " 0.49475157260894775,\n",
              " 0.49465280771255493,\n",
              " 0.4943021833896637,\n",
              " 0.49418750405311584,\n",
              " 0.4941923916339874,\n",
              " 0.49372583627700806,\n",
              " 0.49355047941207886,\n",
              " 0.49342185258865356,\n",
              " 0.4932287037372589,\n",
              " 0.49292704463005066,\n",
              " 0.4928872883319855,\n",
              " 0.4925568103790283,\n",
              " 0.4924764037132263,\n",
              " 0.4921760559082031,\n",
              " 0.49192649126052856,\n",
              " 0.4917644262313843,\n",
              " 0.4916665256023407,\n",
              " 0.49150124192237854,\n",
              " 0.49127569794654846,\n",
              " 0.49105119705200195,\n",
              " 0.4909796714782715,\n",
              " 0.4908106029033661,\n",
              " 0.49055027961730957,\n",
              " 0.4904884994029999,\n",
              " 0.4903160333633423,\n",
              " 0.4901025593280792,\n",
              " 0.4899705648422241,\n",
              " 0.48983994126319885,\n",
              " 0.48950648307800293,\n",
              " 0.48938456177711487,\n",
              " 0.489385187625885,\n",
              " 0.4891015589237213,\n",
              " 0.4889146685600281,\n",
              " 0.4887371063232422,\n",
              " 0.48865413665771484,\n",
              " 0.48846203088760376,\n",
              " 0.48861557245254517,\n",
              " 0.48819345235824585,\n",
              " 0.4879891872406006,\n",
              " 0.487804651260376,\n",
              " 0.487571656703949,\n",
              " 0.4875542223453522,\n",
              " 0.4873698055744171,\n",
              " 0.48713597655296326,\n",
              " 0.48727986216545105,\n",
              " 0.4870411157608032,\n",
              " 0.48687440156936646,\n",
              " 0.4868392050266266,\n",
              " 0.48642832040786743,\n",
              " 0.48630428314208984,\n",
              " 0.48616746068000793,\n",
              " 0.48616641759872437,\n",
              " 0.4858209788799286,\n",
              " 0.485911101102829,\n",
              " 0.48570704460144043,\n",
              " 0.48555558919906616,\n",
              " 0.4854687750339508,\n",
              " 0.485291063785553,\n",
              " 0.4852791726589203,\n",
              " 0.48505792021751404,\n",
              " 0.4849565327167511,\n",
              " 0.48495638370513916,\n",
              " 0.4847758710384369,\n",
              " 0.484575480222702,\n",
              " 0.48439082503318787,\n",
              " 0.4844154715538025,\n",
              " 0.4842503070831299,\n",
              " 0.48413094878196716,\n",
              " 0.48384732007980347,\n",
              " 0.48385101556777954,\n",
              " 0.4838501214981079,\n",
              " 0.483609676361084,\n",
              " 0.48339715600013733,\n",
              " 0.48337486386299133,\n",
              " 0.4832572042942047,\n",
              " 0.4830065667629242,\n",
              " 0.48296451568603516,\n",
              " 0.4827367067337036,\n",
              " 0.4827708601951599,\n",
              " 0.48278436064720154,\n",
              " 0.4825572371482849,\n",
              " 0.48257744312286377,\n",
              " 0.48223134875297546,\n",
              " 0.4819597005844116,\n",
              " 0.4822691082954407,\n",
              " 0.4817976951599121,\n",
              " 0.48163342475891113,\n",
              " 0.4816921353340149,\n",
              " 0.48156169056892395,\n",
              " 0.48137614130973816,\n",
              " 0.4814324378967285,\n",
              " 0.48107683658599854,\n",
              " 0.4809078276157379,\n",
              " 0.4809958338737488,\n",
              " 0.48088476061820984,\n",
              " 0.48057636618614197,\n",
              " 0.4806287884712219,\n",
              " 0.4803663492202759,\n",
              " 0.4803137481212616,\n",
              " 0.4802153408527374,\n",
              " 0.4801889955997467,\n",
              " 0.47984856367111206,\n",
              " 0.47983986139297485,\n",
              " 0.4795997440814972,\n",
              " 0.4795807898044586,\n",
              " 0.47980406880378723,\n",
              " 0.479476660490036,\n",
              " 0.4791957139968872,\n",
              " 0.4792068302631378,\n",
              " 0.4790785312652588,\n",
              " 0.47879138588905334,\n",
              " 0.4789525270462036,\n",
              " 0.47865456342697144,\n",
              " 0.4785735309123993,\n",
              " 0.4784456193447113,\n",
              " 0.47842374444007874,\n",
              " 0.47812336683273315,\n",
              " 0.478183776140213,\n",
              " 0.4781077206134796,\n",
              " 0.47788602113723755,\n",
              " 0.4778997004032135,\n",
              " 0.4777653217315674,\n",
              " 0.47789260745048523,\n",
              " 0.477524995803833,\n",
              " 0.4775979816913605,\n",
              " 0.4775274693965912,\n",
              " 0.47751495242118835,\n",
              " 0.47720304131507874,\n",
              " 0.47708576917648315,\n",
              " 0.47698312997817993,\n",
              " 0.47708454728126526,\n",
              " 0.47663888335227966,\n",
              " 0.47672709822654724,\n",
              " 0.47671234607696533,\n",
              " 0.47662320733070374,\n",
              " 0.47644487023353577,\n",
              " 0.47653424739837646,\n",
              " 0.47639575600624084,\n",
              " 0.47624093294143677,\n",
              " 0.47585803270339966,\n",
              " 0.47578558325767517,\n",
              " 0.4757591784000397,\n",
              " 0.4756835997104645,\n",
              " 0.47546127438545227,\n",
              " 0.475555419921875,\n",
              " 0.4753583073616028,\n",
              " 0.4753473699092865,\n",
              " 0.47500601410865784,\n",
              " 0.4750939607620239,\n",
              " 0.47483351826667786,\n",
              " 0.47521206736564636,\n",
              " 0.4746311902999878,\n",
              " 0.4746086597442627,\n",
              " 0.4747811257839203,\n",
              " 0.47462281584739685,\n",
              " 0.474387526512146,\n",
              " 0.4742307960987091,\n",
              " 0.4742538630962372,\n",
              " 0.47408121824264526,\n",
              " 0.47438424825668335,\n",
              " 0.473989337682724,\n",
              " 0.4739416539669037,\n",
              " 0.4740326404571533,\n",
              " 0.4737823009490967,\n",
              " 0.47358816862106323,\n",
              " 0.473632276058197,\n",
              " 0.4733133912086487,\n",
              " 0.47322335839271545,\n",
              " 0.4729732275009155,\n",
              " 0.4731619656085968,\n",
              " 0.4729556143283844,\n",
              " 0.4728732407093048,\n",
              " 0.4730755388736725,\n",
              " 0.4728580117225647,\n",
              " 0.4727002680301666,\n",
              " 0.47264546155929565,\n",
              " 0.4725019633769989,\n",
              " 0.47244730591773987,\n",
              " 0.4723639488220215,\n",
              " 0.4725819230079651,\n",
              " 0.47238844633102417,\n",
              " 0.47235164046287537,\n",
              " 0.4718717634677887,\n",
              " 0.472215861082077,\n",
              " 0.47171518206596375,\n",
              " 0.47187551856040955,\n",
              " 0.47156041860580444,\n",
              " 0.47163575887680054,\n",
              " 0.4717194437980652,\n",
              " 0.47154560685157776,\n",
              " 0.47123223543167114,\n",
              " 0.4713265597820282,\n",
              " 0.47120776772499084,\n",
              " 0.4709385633468628,\n",
              " 0.47110432386398315,\n",
              " 0.4710848331451416,\n",
              " 0.4709182679653168,\n",
              " 0.4710662066936493,\n",
              " 0.4707282781600952,\n",
              " 0.4710790812969208,\n",
              " 0.4706500470638275,\n",
              " 0.4704534709453583,\n",
              " 0.4703576862812042,\n",
              " 0.4706598222255707,\n",
              " 0.4703105092048645,\n",
              " 0.47034600377082825,\n",
              " 0.4700503647327423,\n",
              " 0.4702553451061249,\n",
              " 0.47009164094924927,\n",
              " 0.4700027406215668,\n",
              " 0.4698351323604584,\n",
              " 0.46982935070991516,\n",
              " 0.4700719118118286,\n",
              " 0.4696066081523895,\n",
              " 0.4698372781276703,\n",
              " 0.46967196464538574,\n",
              " 0.4696180522441864,\n",
              " 0.4694947898387909,\n",
              " 0.46947014331817627,\n",
              " 0.4696425199508667,\n",
              " 0.4694034457206726,\n",
              " 0.46918508410453796,\n",
              " 0.46948105096817017,\n",
              " 0.469388484954834,\n",
              " 0.46903151273727417,\n",
              " 0.46897345781326294,\n",
              " 0.4690653085708618,\n",
              " 0.4688206911087036,\n",
              " 0.4692031741142273,\n",
              " 0.4689052700996399,\n",
              " 0.4689963161945343,\n",
              " 0.4688454270362854,\n",
              " 0.4684896171092987,\n",
              " 0.46852025389671326,\n",
              " 0.4684310853481293,\n",
              " 0.46847331523895264,\n",
              " 0.46850454807281494,\n",
              " 0.4681021273136139,\n",
              " 0.4682089388370514,\n",
              " 0.4680507779121399,\n",
              " 0.4678393304347992,\n",
              " 0.46794089674949646,\n",
              " 0.46804484724998474,\n",
              " 0.46813255548477173,\n",
              " 0.4679224193096161,\n",
              " 0.46762537956237793,\n",
              " 0.4675113260746002,\n",
              " 0.46763524413108826,\n",
              " 0.4675982892513275,\n",
              " 0.467433363199234,\n",
              " 0.46751418709754944,\n",
              " 0.4673457443714142,\n",
              " 0.4673186242580414,\n",
              " 0.46721580624580383,\n",
              " 0.46725964546203613,\n",
              " 0.46734628081321716,\n",
              " 0.4673532247543335,\n",
              " 0.46716517210006714,\n",
              " 0.46718502044677734,\n",
              " 0.4672718942165375,\n",
              " 0.4669477939605713,\n",
              " 0.46690288186073303,\n",
              " 0.46670806407928467,\n",
              " 0.4666254222393036,\n",
              " 0.46666112542152405,\n",
              " 0.46635517477989197,\n",
              " 0.4663989543914795,\n",
              " 0.46655282378196716,\n",
              " 0.4662860333919525,\n",
              " 0.4662548303604126,\n",
              " 0.4663589298725128,\n",
              " 0.4663069248199463,\n",
              " 0.46624916791915894,\n",
              " 0.46602582931518555,\n",
              " 0.46605321764945984,\n",
              " 0.46607470512390137,\n",
              " 0.46585410833358765,\n",
              " 0.4660615026950836,\n",
              " 0.465679794549942,\n",
              " 0.465683251619339,\n",
              " 0.4654472768306732,\n",
              " 0.465710312128067,\n",
              " 0.46552345156669617,\n",
              " 0.4656362235546112,\n",
              " 0.46552544832229614,\n",
              " 0.4655381143093109,\n",
              " 0.4654207229614258,\n",
              " 0.4653191566467285,\n",
              " 0.46512100100517273,\n",
              " 0.46532607078552246,\n",
              " 0.4649431109428406,\n",
              " 0.46530431509017944,\n",
              " 0.4649134576320648,\n",
              " 0.4649610221385956,\n",
              " 0.4649243652820587,\n",
              " 0.4648539125919342,\n",
              " 0.46491560339927673,\n",
              " 0.4647483229637146]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wCqfvDZIdzT",
        "outputId": "83b107b7-40e5-4216-9226-fcda43f0323c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "plt.plot(r.history['loss'],label='Adadelta')\n",
        "plt.plot(r1.history['loss'], label='AdaGrad')\n",
        "plt.plot(r2.history['loss'], label='RMSProp')\n",
        "plt.plot(r3.history['loss'], label='Adam')\n",
        "plt.plot(r4.history['loss'], label='SGD',marker='_')\n",
        "plt.xlabel('Iterations over entire Dataset')\n",
        "plt.ylabel('Training Cost')\n",
        "plt.title('Liver Patient Classification')\n",
        "plt.legend()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f9c22d14be0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVl-WPUoJrhJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}